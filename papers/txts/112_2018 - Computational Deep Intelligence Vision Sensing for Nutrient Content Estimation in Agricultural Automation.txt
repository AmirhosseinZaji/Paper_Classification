IEEE TRANSACTIONS ON AUTOMATION SCIENCE AND ENGINEERING, VOL. 15, NO. 3, JULY 2018 1243Computational Deep Intelligence Vision Sensing forNutrient Content Estimation inAgricultural AutomationSusanto B. Sulistyo, Di Wu, Wai Lok Woo,Senior Member ,S .S .D a ,a dB nG o Senior MemberAbstract —This pa pe pr se nts no e c m puta tio na inte lli-gence vision sensing approach to estimate nutrient content inwheat leaves by analyzing color features of the leaves imagescaptured on ﬁeld with various lighting conditions. We propose thedevelopment of deep sparse extreme learning machines (DSELM)fusion and genetic algorithm (GA) to normalize plant images aswell as to reduce color variability due to variation of sunlightintensities. We also apply the DSELM in image segmentation todifferentiate wheat leaves from complex background. In thispaper, four moments of color distribution of the leaves images(mean, variance, skewness, and kurtosis) are extracted andutilized as predictors in the nutrient estimation. We combinean m e ro fD E M sw t hc m i t em c i ea do t m z ethem using the GA to estimate nitrogen content in wheatleaves. The results have shown the superiority of the proposedmethod in the term of quality and processing speed in allsteps, i.e., color normalization, image segmentation, and nutrientprediction, as compared with other existing methods.Note to Practitioners —In order to support precision farmingtechnology and agricultural automation, it is very essential toestimate the nutrient content in plants to prevent over fertilizingthat will harm environment. Furthermore, the existing methodto determine nutrient content in leaves is destructive as wellas time consuming and requires special expertise to operateexpensive devices. number of methods have been developedto estimate nutrient content in leaves nondestructively based onthe color features of the leaves. Most of these methods, however,are conducted in controlled environment with artiﬁcial lighting.Such methods are not practical and need various equipment.We propose low-cost, simple, and accurate technique toestimate nitrogen content in wheat leaves by analyzing RGBcolor of the leaves images. In this paper, we found that thedeveloped DSELMs fusion has enabled better performance innormalizing images and is faster than other neural networktypes, i.e., backpropagation-based multilayer perceptron andoriginal extreme learning machine. In image segmentation step,the established DSELM shows good performance to recognizeand distinguish wheat leaves from other undesired backgroundimages. Furthermore, the developed weighted DSELMs havedemonstrated enhanced ability in estimating nutrient content.Manuscript received December 27, 2016; revised July 1, 2017; acceptedSeptember 10, 2017. Date of publication December 21, 2017; date of currentversion July 2, 2018. This paper was recommended for publication byAssociate Editor H. Qiao and Editor D. Tilbury upon evaluation of thereviewers’ comments. (Corresponding author: Wai Lok Woo.)The authors are with the School of Electrical and ElectronicsEngineering, Newcastle University, Newcastle upon Tyne NE1 7RU,U.K. (e-mail: s.b.sulistyo@ncl.ac.uk; d.wu3@ncl.ac.uk; w.l.woo@ncl.ac.uk;s.s.dlay@ncl.ac.uk; bin.gao@ncl.ac.uk).Color versions of one or more of the ﬁgures in this paper are availableonline at http://ieeexplore.ieee.org.Digital Object Identiﬁer 10.1109/TASE.2017.2770170Index Terms —Ag ic ultur l uto a tio n, o m itte m c hine s,computational intelligence, deep learning, deep neural networks,image processing.I. INTRODUCTIONNUTRIENT status analysis is one of the crucial stagesin precision farming, which has become topical issuein modern agriculture. Precision fertilizing requires farmmachineries with capabilities to detect crop leaves from weedsas well as measure nutrient content in crops nondestructivelyand determine how much nutrient dose should be applied toplants [1]. Therefore, estimatin gn t i n tc n e ti np a t si sthe key factor to determine the fertilizer dose. By deﬁning thefertilizer dose more precisely, such practice will increase cropproductivity as well as reduce production costs and preventenvironment from excessive fertilization.Nitrogen is one of the essential nutrients required by wheatcrops in considerable amounts to ensure their growth sinceit has an important function in photosynthesis. In general,there are four common methods to assess nitrogen content inplants, as reported in [2], i.e., chemical and combustion tests,vegetation index (VI), chlorophyll meter (CM), and leaf colorcharts (LCC). Despite the hig ha c r c ,t ec e i a la dcombustion tests are of destructive methods. The VI and CMmethods are of nondestructive, yet they are expensive to obtainremote sensing images as well as the CM device. In spite ofits simplicity, the LCC results are very subjective dependingon the inspection of human visual.Recently, due to the most recen td v l p e t si nc m u e rvision with rapidity and ease of image data acquisition, exten-sive studies on estimation of nitrogen status in crops have beenconducted by using image-based analysis [3]. Nevertheless,most of these approaches are not practical and time consumingsince they are typically performed in controlled environment,such as in closed image acquisition chamber with artiﬁciallighting systems, as seen in Fig. [4], [5].It is very challenging task to analyze nitrogen contentin crops nondestructively according to the color features ofplant leaves images which are captured in farm under sunlight.Characteristics of illuminant sources are very important in dig-ital image processing systems, especially in image acquisition.Thus, the closed-chamber method cannot be applied to analyzenitrogen status of crops in open ﬁeld as the sunlight intensityis continually changing. This issue, therefore, will causeinconsistent and unreliable image acquisition problems as well1545-5955 2017 EEE. Personal se is perm itted, but republication/redistri bution requires IEEE permission.See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.Authorized licensed use limited to: The University of British Columbia Library. Downloaded on July 15,2020 at 19:13:49 UTC from IEEE Xplore. Restrictions apply. 1244 IEEE TRANSACTIONS ON AUTOMATION SCIENCE AND ENGINEERING, VOL. 15, NO. 3, JULY 2018Fig. 1. Common image acquisition in controlled environment with artiﬁciallighting systems.Fig. 2. Wheat crops images from the same ﬁeld and the same fertilizer levelcaptured on-ﬁeld under various sunlight intensities. (a) Low light intensity.(b) Medium light intensity. (c) High light intensity.as affect the results of nutrient estimation, which motivatethe research focus of this paper. The problem faced in thisresearch is how to automatically normalize images capturedunder various sunlight concentrations. The color normalizationaims to reduce color variability among the images in order toresolve the image acquisition problem.In this paper, we propose low-cost and accurate nonde-structive image-based technique to estimate nitrogen amountin wheat crops on ﬁeld with various sunlight intensities usinga conventional digital camera. As seen in Fig. 2, the intensityof the light source will domin antly affect the appearance ofthe wheat plants images even they are acquired from thesame ﬁeld with the same fertilizing level treatment. Theseimages, therefore, should be normalized prior to subsequentimage processing steps. The color variation of the wheat leavesafter image normalization process is merely inﬂuenced by thedifference of fertilizing concentrations. Generally, the lesserthe nitrogen fertilizer applied to plants, the green color ofthe leaves will be much lighter. In this step, we introduce anovel method for color normalization by using fusion of deepsparse extreme learning machines (DSELMs) with geneticalgorithm (GA) and 24-patch Macbeth color checker as thecolor reference. Extreme lear ning machine has been well-known as one of the recent successful approaches in machinelearning with much faster traini ng speed than the ordinary mul-tilayer perceptron (MLP). The GA is one of the evolutionaryalgorithms which involves selection, crossover, and mutationoperators to make its population more diverse and thus preventthe algorithm to be trapped in local optimum. Theoretically,the diversity will increase the algorithm’s speed to achieveglobal optimum since it will countenance the algorithm toexplore the solution space faster. Macbeth color checker isusually used as reference target for photographic and videoproduction work as well as calibration process [6]. As it hasvarious standard color patches ,i ti sb n ﬁ i lt ou et i schart as color reference to normalize and correct plantimages under various sunlight intensities. Studies on colornormalization conducted by Min et al. [7] and Cheng et al. [8]utilized Macbeth color chart as color reference.The next step is image segmentation and features extraction.In this step, we utilize DSELM to distinguish wheat leaves asthe object of interest from undesired images, such as soil,weeds, dried leaves, stems and stones. After image segmen-tation, 12 statistical features from four types of momentsof each RGB color channel, i.e., ﬁrst moment (mean), sec-ond moment (variance), third moment (skewness), and fourthmoment (kurtosis), are extracted from the segmented images asthe nutrient estimation predi ctors. We propose the utilizationof these statistical features as predictors since they indicatethe color distributions of wheat leaves more signiﬁcantly ratherthan single color channel from certain color model or com-binations of some color channels.In the nutrient estimation step, we combine severalDSELMs with different hidden layer numbers by using com-mittee machine and optimize the results with GA. The estima-tion results of the proposed approach are then compared withother common and existing nutrient estimation methods.This paper proposes an innovative intelligent computationalmachine vision by using DSELMs fusion and GAs to estimatenitrogen status in wheat plants for agricultural automation.Furthermore, the novel contributions of our proposed methodare summarized as follows.1) newly developed DSELM-based MLP is utilizedto normalize the color constancy. Unlike other learn-ing algorithms such as back-propagation-based MLP,DSELM is able to exploit more important informationwith much faster learning speed [9]–[11]. In the mean-while, the utilized norm-1 /lscript1)r g l r z t o ni sa l et ogenerate more sparse representations than other MLPlearning algorithm [9], [12], [13]. Thus, the problem ofcolor variability due to various light intensities are ableto be carried out by developing DSELMs fusion with24-patch Macbeth color checker as the color reference,and its combination with GA for image normalization.Moreover, the developed GA is used to determine thecorrect output weights of each DSELM.2) DSELM is also utilized in the image segmentationprocess to distinguish the desired target from noiseAuthorized licensed use limited to: The University of British Columbia Library. Downloaded on July 15,2020 at 19:13:49 UTC from IEEE Xplore. Restrictions apply. SULISTYO et al. :C M U A I N LD E PI T L I E C EV S O NS N I GF RN T I N TC N E TE T M T O 1 4 5Fig. 3. Flowchart of the entire research to estimate nitrogen status.images as DSELM is easy train ing and capable to extractmore sparse and accurate features layer-by-layer withhigher layers represent more abstract information thanprevious layers.3) In the nitrogen estimation step, committee machine isused to combine the output of DSELMs with varioushidden layer numbers. In addition, the GA is applied tooptimize the estimation results.This paper is organized as follows. Experimental setup isexplained in Section II. In Section III, the proposed DSELMand GA-based color normalization are presented. Section IVdiscusses the DSELM-based image segmentation and statis-tical color features extraction. Nitrogen content estimationusing combined DSELM is proposed in Section . Section VIanalyzes and compares the results of the proposed workwith other methods. Finally, we conclude our research inSection VII.II. XPERIMENTAL SETUP AND DATAACQUISITIONIn general, this research can be divided into three majorworks as depicted in Fig. 3. Each work will be explained inmore detail in Sections II-A–II-D.A. Farm Experimental Materials and DesignAn experiment to ﬁgure out the effect of fertilizer amountto crops growth has been conducted at Nafferton ExperimentalFarm, Newcastle University, from April to June. To pro-duce variations in nitrogen levels, the treatments were setto three different nitrogen amounts, i.e., (N1), 85 (N2),170 (N3) kg/ha of NH 4NO3with each treatment replicatedfour times. Hence, there were 12 plots with each plot was(20×20) m2in dimension. The data collection was performedin three different periods, i.e., one week before fertilizing, twoand four weeks after fertilizing. Therefore, in total 36 sampleswere used in this research.B. Chlorophyll Meter Readings (Minolta SPAD-502)The measurements of chlorophyll content using MinoltaSPAD-502 were conducted on 30 leaf samples in each plot.The value showed on the SPAD meter screen signiﬁes thechlorophyll content of the leaf, which is highly correlated withthe nitrogen amount. To obtain the average value of SPADof the plot, 30 leaves were randomly selected on one plot.Therefore, there were 12 SPAD values for 12 samples in onedata collection time. In total, we have 36 SPAD values usedfor comparison.C. Actual Nitrogen Measurement Using Elementar AnalysisThe actual nitrogen amount was measured using an Elemen-tar Vario Macro Cube. The procedure is as follows. First ofall, around 50–60 wheat leaves per plot were taken as samples.These samples were then dried in cabinet oven dryer atat m e a u eo f8 0° Cf ra o t4 8h .T ed i ds m l swere ground afterward using an electric grinder at speedof 14 000 r/min to pulverize the samples into powder. To mea-sure the actual nitrogen amount, sample of approximately100 mg was weighed into tin foil cup. The cup was thenfolded and squashed into pelle tt oe p lt ea r .T i sa a y i sinvolved the combustion method by burning the sample withac r a na o n to fo y e ni nt ec b .T en t o e ne e e twas then analyzed automatically using special software and apercentage ﬁgure subsequently obtained.D. On-Field Image Data AcquisitionSeveral sample images of wheat leaves were captured ran-domly at ten points on each pl ot. We obtained 360 imagesfor the 12 set plots during three different periods. Theseimage data collections were conducted in an open ﬁeld withlight intensity of the sun during this experiment ranged fromaround to 80 Klux and the data collection time was from10 am to pm. This means that the color of the sunlight wasrelatively white, compared to its color in the morning or inthe evening, when it is relatively reddish or yellowish. Allimages were grabbed from the top of the plants in distance of10–20 cm using common digital camera (Sony DSC-W55).The images were captured at 1632 ×1224 pixels, but then downsampled to 448 ×336 pixels to assist with the effectiveness ofthe image processing.III. EEPSPARSE EXTREME LEARNING MACHINEFUSION AND GENETIC ALGORITHM -BASEDCOLOR NORMALIZATIONSince the changes of light intensity will affect the color ofplant images, the images, therefore, should be normalized asif they are acquired under the same light intensity, in orderto perform consistent and reliable comparison among theimages. In this research, we use 24-patch Macbeth colorchecker with our proposed neural networks fusion-based colornormalization approach. The Macbeth color checker is asquare card that consists of 24 patches of color samples whichrepresent natural objects, chro matic, primary, and grayscalecolors, which are arranged in four rows (Fig. 4).Authorized licensed use limited to: The University of British Columbia Library. Downloaded on July 15,2020 at 19:13:49 UTC from IEEE Xplore. Restrictions apply. 1246 IEEE TRANSACTIONS ON AUTOMATION SCIENCE AND ENGINEERING, VOL. 15, NO. 3, JULY 2018Fig. 4. Macbeth color checker.Neural networks have been extensively used for automationin many applications, such as iron and steel industry [14],ﬁnancial service [15], plastic production [16], and energygeneration prediction [17]. Neural networks are also usedin digital signal processing [18], [19] and nonlinear systemscontrol [20], [21]. However, the training procedure of neuralnetworks with back-propagation algorithm is easy to fallinto local minima and the training speed is generally slow,especially for MLP. To address this problem, we propose theDSELM algorithm to train the MLP. Compared with othermachine learning algorithms, SELM is much faster in train-ing stage and has better generali zation performance [9], [11].Color normalization, also known as color constancy, is acomputational technique to correct color deviations of imagesdue to the differences of lighting conditions. Image colorsof an object are considerably in ﬂuenced by the direction andintensity of the light source, as well as illuminant color [23].Moreover, an extensive research has been done to overcomethe problem of color constancy [24]–[26]. In this paper, ourcolor constancy concept differs from previous works given thatthe images are acquired under unconstrained daylight, as men-tioned in Section II-D. This poses more difﬁcult challengeas plant images captured under various light intensities haveto be normalized to standard image that is captured under astandard light intensity.Our proposed method of combination of DSELMs fusionand GA for image normalizatio ni sd s r b da sf l o s .First of all, the images of the Macbeth color checker werecaptured under sunlight usin gac m o nd g t ls i lc m r .The sunlight intensity, which was measured by using digitallight meter (Fig. 5), ranged between to 82 Klux. The colorchecker images under light intensity of 50 ±1K u xw r econsidered as the standard (target) images while the otherimages were used as the input of the developed DSELM.As for the target images, we captured ﬁve color checkerimages in range of 49–51 Klux. In the meanwhile, 164 colorchecker images under light intensity of 7–48 Klux and52–82 Klux were grabbed to be utilized as input images.To obtain average color values of each patch, each colorchecker image was ﬁrst cropped on each patch with croppingwindow of 95 ×72 pixels. The average RGB color valuesof each patch of the cropped target and input images werethen calculated. This step was done twice and thus we have328(=164×2) RGB color training samples for eachpatch. Since there are 24 patches in the Macbeth color checker,therefore, there are 24 data sets in which each data set containsFig. 5. Photograph of digital light meter.328 RGB training samples. All the data sets are consequentlycombined to produce one large data set for DSELM fusion.This new data set, thus, consists of 7872 (=328×24) RGBcolor samples.To achieve high generalizatio np r o m n ef rc l rc n -stancy, especially for large scales, appropriate representationsare crucial. Single-layer feed forward neural network (SLFN)learning with back-propagation algorithm is an efﬁcientmethod to learn compact featur es. However, the informationlearned from SLFN is not good enough to represent the inputdata, especially for large data set. Thus, multiple layer archi-tecture of neural network is eeded as the features extracted bymultiple layer networks represent more abstract and accurateinformation than those from shallow ones. One of the mostpopular approaches is deep belief networks (DBNs) whichcan be done using stacked restricted Boltzmann machines.It has been shown to yield good performance in various areas;however, the training speed is generally very slow for thereason that all the parameters of the entire network need tobe ﬁne-tuned multiple times to achieve the criterions. Thus,the training of DBNs is too cumbersome and time consuming.To address this problem, we propose the DSELM. Comparedwith DBNs, DSELM has four notably attractive features.First, the hidden nodes can be randomly generated accordingto any continuous probability distribution without any priorknowledge, e.g., the uniform distribution [22]. Second, theonly parameter that needs ob ed t r i e di st eo t u tweight which can be established by searching the path backfrom random space. Third, once the feature of the previoushidden layer is learned, the parameters of current hiddenlayer will be ﬁxed and need not to be ﬁne-tuned [9], thisis the major difference between DSELM and DBNs. Finally,more abstract and sparse hidden information is extracted using/lscript1-regularization. Additionally, extreme learning machine isusually efﬁcient, especially for small data set applications,as found in [47].The DSELM consists of two phases: 1) unsupervised featuremapping and 2) supervised feature regression. In the formerphase, an ELM-based sparse autoencoder is used to extractsparse features of the input layer by layer with higher layersrepresent more abstract and accurate features than that ofprevious layer. In the latter phase, an original ELM is stackedat the top of the learned deep structure to make the ﬁnaldecision. In the following, the overall architecture of DSELMwill be introduced in detail and the description of the trainingprocedure of Sparse ELM (SELM) is also presented as theAuthorized licensed use limited to: The University of British Columbia Library. Downloaded on July 15,2020 at 19:13:49 UTC from IEEE Xplore. Restrictions apply. SULISTYO et al. :C M U A I N LD E PI T L I E C EV S O NS N I GF RN T I N TC N E TE T M T O 1 4 7SELM is the building block which is used to construct thedeep structure of DSELM.In the initial ELM, given set of Ntraining data (X,T)={xj,tj}Nj=1,w e e xj=[ xj1,xj2,..., xjP]∈RPandtj=[tj1,tj2,..., tjQ]∈RQare the training data and thecorresponding target, respectively. The parameters PandQare the dimension of input and target vector, respectively. Theoutput function f(X)of ELM with Khidden nodes fullyconnect the input data to the outputs is represented byf(xj)=K/summationdisplayk=1ψk/parenleftbigwTkxj/parenrightbig·βk,j=1,2,... (1)where ψ(·)is the activation function which we used is thesigmoid functionψ/parenleftbigwTkxj/parenrightbig=11+e−wTkxj. (2)wk∈RPis the randomly generated parameters connectinginput layer and kth hidden node, βk∈RQis the output weightvector connecting the kth hidden layer and the output layer.TheNequations in (1) can be written compactly asF(X)=/Psi1β (3)where β={βk}∈RK×Qis the output weight matrix, /Psi1is theN×Khidden feature mapping matrix with respect to input X.The elements of /Psi1can be described as follows :/Psi1=/bracketleftbigψ1/parenleftbigwT1X/parenrightbig,ψ2/parenleftbigwT2X/parenrightbig,...,ψ K/parenleftbigwTKX/parenrightbig/bracketrightbig=ψ1/parenleftbigwT1x1/parenrightbig··· ψK/parenleftbigwTKx1/parenrightbig.........ψ1/parenleftbigwT1xN/parenrightbig··· ψK/parenleftbigwTKxN/parenrightbigN×K. (4)An ELM learns the parameters in two sequential stages:1) random feature mapping and 2) linear parameter solv-ing. In the ﬁrst stage, with randomly initialized parameters,the input data are projected into an ELM feature space usingthe activation function ψ(·).H a g et al. [27] have provedthat ELM is able to approximate any continuous function withrandomly initialized parameters. Therefore, the only parameterthat needs to be calculated is output weight β.I nt es c n dstage, an ELM aims to reach the smallest training error and thesmallest norm of output weights using the following equationto optimize the output weight β:argminβ∈RK×Q12/bardblβ/bardbl212+C2N/summationdisplayj=1/bardblej/bardbl2s.t./Psi1(xj)β=tj−ej,j=1,2,..., (5)where the ﬁrst term is /lscript2optimization to avoid over ﬁtting andobtain compact hidden information, Cis tradeoff coefﬁcientwhich are chosen experimentally, ej=(tj−f(xj))∈RQisthe error vector with respect to jth input data. Equation (5)can be rewritten as an unconstrained optimization problemargminβ∈RK×Q12/bardblβ/bardbl212+C2/bardbl/Psi1β−T/bardbl2(6)where T=[t1,t2,..., tN]∈RN×Qis the target. As ELMautoencoder is designed to encoded outputs to approximatethe original inputs by minimizing the reconstruction errors,therefore, the target Tis set to original inputs X.I nt em a -while, due to the use of /lscript2regularization, the xtracted featuresof ELM autoencoder may have redundancy and not sparseenough to represent the input data, therefore, more sparsesolution is needed. Compared with /lscript2norm, /lscript1regularizationis able to induce more sparsity in the optimal solution of (6).Also, /lscript1regularization is less sensitive to output. Therefore,/lscript1penalty is applied. Equation (6) can be rewritten asargminβ∈RK×Q/bardblβ/bardbl11+/bardbl/Psi1β−X/bardbl2(7)where /bardblβ/bardbl/lscript1stands for the sum of the absolute values ofthe components of β.E u t o n( )c na s ob ea a t dt osemisupervised and unsupervised learning [48] and solved byag a i n tp o e t o na g r t m .O fw i ht em s tp p -lar methods is the class of Iterative Shrinkage-ThresholdingAlgorithm (ISTA) ,w e ee c hi e a i ni v l e sm t i -vector multiplication involving /Psi1and /Psi1Tfollowed by ashrinkage/soft-threshold step [12], [13]. The general stepofISTA isβi+1=ϒt(βi−2t/Psi1T(/Psi1βi−X)) (8)where tis an appropriate step size and ϒα:Rn−→Rnis theshrinkage operator deﬁned byϒα(βi)=(|βi|−α)+sgn(βi). (9)One of the simplest methods for solving an unconstrainedminimization problem min {p(x):x∈Rn,p:Rn−→Rn}isthe gradient algorithm which generates sequence {xi}viax0∈Rn,xi=xi−1−ti∇p(xi−1) (10)where tiis an appropriate step size. Equation (10) can beviewed as proximal regularization of the linearized functionpatxi−1,t u ,( 0 )c nb er w i t na sxi=argminx/braceleftbiggp(xi−1)+/angbracketleftx−xi−1,∇p(x1−1)/angbracketright+12ti/bardblx−xi−1/bardbl2/bracerightbigg.(11)Rewriting (7) asmin{p(β)+q(β),β∈RK×Q} (12)where p(β)=/bardblX−/Psi1β/bardbl2andq(β)=/bardblβ/bardbl/lscript1.T e e o e βcan be calculated asβi=argminβ/braceleftbiggp/parenleftbigβi−1/parenrightbig+/angbracketleftβ−βi−1,∇p(β1−1)/angbracketright+12ti/vextenddouble/vextenddoubleβ−βi−1/vextenddouble/vextenddouble2+/bardblβ/bardbl11/bracerightbigg.(13)The constant terms can be ignored, thus, (13) can be writtenasβi=argminβ/braceleftbigg12ti/bardblβ−(βi−1−ti∇p(βi−1)/bardbl2+/bardblβ/bardbl11/bracerightbigg.(14)Authorized licensed use limited to: The University of British Columbia Library. Downloaded on July 15,2020 at 19:13:49 UTC from IEEE Xplore. Restrictions apply. 1248 IEEE TRANSACTIONS ON AUTOMATION SCIENCE AND ENGINEERING, VOL. 15, NO. 3, JULY 2018Fig. 6. (a) Layer wise training of DSELM, which is consists of twophases: deep forward learning followed by the original ELM classiﬁcation.(b) Implementation of ﬁrst hidden layer SELM autoencoder. (c) Trainingprocedure of Lth hidden layer SELM autoencoder. (d) Analytically calculatethe output weights of original ELM with labeled target using randomlyinitialized parameters.Let∇p=2/Psi1T(/Psi1β−X)denotes the gradient of pandL:=L(p)=2(/Psi1T/Psi1)is the Lipschitz constant of ∇p.D ﬁ eoperator ϕL:Rn−→Rn,ϕL(β)=ϒt(βi−2t/Psi1T(/Psi1βi−X)),t=1/L(p).T ec m u a i no fo t u tw i h βusingISTA algorithm with constant step size can be represented asfollows:βi=ϕL(βi−1). (15)However, ISTA algorithm shares sublinear global rate ofconvergence O(1/z),w e e zis the iteration times and itappears to be slow method. To improve the complexity result,aFast ISTA (FISTA) is used [12]. FISTA keeps the simplicityof ISTA but shares complexity of O(1/z2)for minimizingsmooth convex problems. It computes βiusing based on thefollowing :βi=ϕL(yi) (16)where yiis new point which is speciﬁc linear combinationof previous two points {βi−1,βi−2}.As the SELM is the building block of DSELM, the learnedoutput βwith respect to the input data is the ﬁrst-layer weightof DSELM. After the output of the ﬁrst hidden layer sparserepresentations are obtained, new SELM autoencoder isstacked at the top to learn the second layer parameters withthe same procedure. In this manner, all parameters of theDSELM can be computed sequentially and all parameters canbe ﬁxed without iteratively ﬁne-tuning. At last, an originalELM classiﬁer is stacked at the top of the deep network tomake the ﬁnal decision.The steps taken in the DSELM, as seen in Fig. 6, can bedescribed as follows.1)Normalize Inputs (X i):RGB input colors should benormalized by dividing their values with the maximumvalue 255. Thus, X1=(R/255),X2=(G/255), X3=(B/255); Xi∈[0,1],i=1,2,3.2)Randomly Initialize the Input Weight w:Set weightconnecting input layers and hidden layer small randomvalues (between −1a d1 .3)Calculate the Hidden Output H:With randomly ini-tialized weights, the kth hidden node output hkcan becalculated as :hk=ψk/parenleftbigwTk·X/parenrightbigwhere Xis input data. The activation function that weuse is sigmoid function.4) Calculate the Lipschitz constant Lof the gradient ofsmooth convex function ∇pL:=L(p)=2(/Psi1T/Psi1). (17)5) Calculate the output weights βiusing SELM.a) Take the initial value y1=β0∈Rn,t1=1.b) for i≥1, computeβi=ϕL(yi)=ϒt(yi−t∇p(yi))=argminβ/braceleftBiggL2/vextenddouble/vextenddouble/vextenddouble/vextenddoubleβ−/parenleftbiggβi−1−1L∇p(βi−1)/parenrightbigg/vextenddouble/vextenddouble/vextenddouble/vextenddouble2+/bardblβ/bardbl11/bracerightbiggti+1=1+/radicalBig1+4t2i2yi+1=βi+/parenleftbiggti−1ti−1/parenrightbigg(βi−βi−1).6) Recompute the hidden output Hwith the learned outputweight βinstead of the randomly initialized weight wH=σ(βT·X).7) Stack new SELM at the top with the input is theprevious hidden layer output H.8) Repeat the above processes (2–7) until the desired deepstructure is achieved.9) Stack an original ELM which is trained with labeleddata at the top of the learned deep structure to makeﬁnal decisions.The next step is combining all the extreme learningmachines into one neural network system. The proposedDSELMs fusion, as shown in Fig. 7, is developed to generatenew RGB outputs. The proposed approach differs from themethod in [28] by altering the conventional backpropagationneural network with DSELM. The ﬁnal output RGB valuesfrom the networks fusion is obtained as follows:Z=α·O=[∝1,∝2,∝3,..., ∝24]·[O1,O2,O3,..., O24]T(18)where αis the weight matrix of each network output, Oisthe output matrix of each network, and Zis the ﬁnal outputmatrix of the neural networks fusion.From (18), it can be seen that matrix αconsists of24 diagonal αmatrices with dimension of ×3. Similar tomatrix α,m t i Oalso has 24 matrices with dimension ofAuthorized licensed use limited to: The University of British Columbia Library. Downloaded on July 15,2020 at 19:13:49 UTC from IEEE Xplore. Restrictions apply. SULISTYO et al. :C M U A I N LD E PI T L I E C EV S O NS N I GF RN T I N TC N E TE T M T O 1 4 9Fig. 7. Proposed DSELMs fusion using Macbeth color checker andGA-based optimization for image color normalization.3×Nfor each matrix Oi,a d Nis the number of trainingsamples.In this paper, the GA is utilized to ﬁnd the optimumvalue for each of the 24 αmatrices (see Fig. 7). The GAis an algorithm based on the Darwin principle of evolution aswell as natural selection and biological systems. It has beenwidely used for optimization in applications involving patientﬂow distribution [29], thin ﬁlm transistor-liquid crystal displaymodule assembly scheduling [30], parallel robotic mechanismsfor ankle rehabilitation treatme nts [31], and semiconductorwafer fabrications scheduling [32]. Basically, GA encompassesap p l t o nw t hac r a nn m e ro fi d v d a s .E c hi d -vidual in population has the po ssibility of being the solutionto the optimization problem. Hence, by applying crossing overand mutation among individuals, new generation is produced.This process is repeated several times until new individualprovides the most appropriate solution for the problem.Based on our experiments, the proposed DSELMs fusioncan be optimized by means of GA with the following steps.1)Deﬁne Fitness Function: The ﬁtness function of thecolor normalization is to minimize the mean squareerror (mse) between the target RGB colors of the Mac-beth color checker T)a dt eﬁ a lo t u tR Bc l r sof the DSELM fusion Z)( e eF g .7 )argminα1N/summationdisplayn(Tn−Zn)2where Nis the number of RGB color samples in thedata set.2)Determine the Initial Population: In this step, we setthe initial population size (S(1)pop)of the developed GAto 500 individuals. These individuals performed as theﬁrst generationS(1)pop=500.3)Encoding and Decoding: Encoding is used to expresseach individual in the popula tion by binary strings of0s and 1s. The α=[ 1,∝2,∝3,..., ∝24]matrixhas dimension of ×72 and each element of thematrix ∝kis expressed by 8-bit string of binarynumbers (0s and 1s). Thus, each individual of matrixαhas 1728 =8×3×72) bits length.Decoding is used to change the encoding binary stringsinto decimal number. The decoded numbers are thencomputed into the deﬁned ﬁtness function.4)Set Boundary Conditions: We set boundary conditionsof each element in the matrix αto be always positivein order to prevent RGB colors of the ﬁnal output Z)have negative values. In particular, the boundary of eachelement of matrix ∝k,i e , ak,ijwith i,j=1,2,3, is setas follows :ifi=jthen ak,ij∈[0,1]elseak,ij=0.Thus, each matrix ∝khas structure as follows:∝k=ak,11 000 ak,22 000 ak,33.5)Reproduce: Reproduce next generations(S(2),S(3),S(4),... by running the selection, crossoverand mutation operators.According to [33], selection operator attempts to give“a pressure” to the population as the same as naturalselection in the biological life. Individuals with betterperformance, or ﬁtter, will be kept to the next genera-tions. Otherwise, they will be wiped out. In crossover,two individuals exchange some bits of the same sectionone another to create two offspring, while mutationturns over bits in chromosome (a to 1 and viceversa ). Furthermore, the existence of mutation dependson the mutation rate or probability of mutation ρ)set in the algorithm and random number given bythe computer ω).I nt i ss e ,t e ρvalue was setto 0.005. According to [34] ,p o a i i yo fm t t o nnormally ranges from 0.001 to 0.01, as found in [35]and [36] in which used ρvalues of 0.003 and 0.01,respectively. In addition, Coley [33] suggested that smallmutation rate will be less disastrous than high one inmost common problems.The mutation operator, thus, can be deﬁned as follows:mutation =/braceleftBigg1(mutates ), ifω≤ρ0(not mutate ),ifω>ρ .6)Repeat: Repeat the selection, crossover, and mutationprocesses until the best individual achieved, which hasmse less than 0.0001.Once the optimum value of matrix αis achieved, the nextstep is applying the developed neural networks fusion andmatrix αto adjust the RGB color of the wheat plants. In thispaper, wheat plant image has dimension of 448 ×336 pixels.Through this developed color adjusting system, each pixelof plant image acquired unde rv r o sl g ti t n i i si stransformed to the equivalent pixel of the image under thestandard light intensity, i.e., 50 Klux.Authorized licensed use limited to: The University of British Columbia Library. Downloaded on July 15,2020 at 19:13:49 UTC from IEEE Xplore. Restrictions apply. 1250 IEEE TRANSACTIONS ON AUTOMATION SCIENCE AND ENGINEERING, VOL. 15, NO. 3, JULY 2018IV DSELM-B ASED IMAGE SEGMENTATION ANDSTATISTICAL COLOR FEATURE EXTRACTIONIn machine vision system, image segmentation plays animportant role since it aims to classify each pixel in animage into certain part. In this research every pixel willbe divided into two segments, i.e., object (wheat leaves)and background (nonleaf images). Commonly, in controlledenvironment (see Fig. 1), an object is laid down on whitepaper background with certain illuminations. In this method,the object of the captured image can easily be distinguishedfrom its background by applying the conventional Otsu algo-rithm with simple threshold value. In this research, however,the problem is more complicat ed. The images of the wheatleaves are captured directly on ﬁeld and contain leaves as theobject and some unwanted parts, such as soil, stones, weeds,and dried and semidried leaves in the background. Many ofthe unwanted parts (especially the weeds and semidried leaves)have similar color to the wheat plant.AD E Mw su e df ri a es g e t t o nt or m v ethe nonleaf images and keep the wheat leaves as the regionof interest. Basically, the developed DSELM for this step issimilar to that for the color normalization process as explainedin Section III. The network has three hidden layers withthree nodes of input layer, which indicate red, green, andblue values (RGB) for each pixel of plant images. However,the output layer has only one unit, which signiﬁes whethereach pixel is part of leaf or not. The output value of thenetwork is equal to if the corresponding pixel is part of aleaf, otherwise the value is 0.In this image segmentation step, we develop data set from7200 samples of RGB color and binary values (0 or 1) as theinput and target values, respectively. The data set was acquiredfrom 24 normalized images. On each image, 150 pixels in theleaf region and 150 pixels in other parts of the region wereselected manually. The RGB color values of the selected pixelswere then used as inputs of the developed DSELM.After image segmentation, some small noises will be pre-sented in the color segmented image. These noises shouldbe removed prior to features extraction. In the majority ofimages, weeds are also presen tw i hn e dt ob ee i i a e dfrom the segmented images, as they can inﬂuence the colorinformation of the wheat leaves. To overcome this obstacle,we use the largest part of the leaves which has the highestnumber of object pixels. This algorithm can be seen in Fig. 8.Some examples of the proposed color normalization and imagesegmentation results can be seen in Fig. 9. As revealed,the proposed color constancy method for image normalizationand the DSELMs-based image segmentation can be used in anautomated manner to normalize the images of the plants andto remove the unwanted parts from the image, as indicated bythe black circles.In the features extraction step, several statistical colorfeatures pertaining to the ﬁnal color segmented images arecalculated. These features are used for nutrient estimation inthe next step. Four moments of statistical data distributionare used in this research, i.e., mean (ﬁrst moment), variance(second moment), skewness (third moment) and kurto-sis (fourth moment). Thus, there are 12 statistical features forFig. 8. Image segmentation algorithm.Fig. 9. Two examples of the proposed color normalization and imagesegmentation results. (a) Original images with some spots of unwanted parts.(b) Normalized images. (c) Segmented images.three color channels (red, green and blue) which represent thecolor distributions related to the segmented images. Accordingto [37], the ﬁrst order (mean), the second order (variance),and the third order (skewne ss) of color moments have beendemonstrated efﬁciently and ffectively to represent colordistribution of images.In addition, in most natural scene images such as in theproposed research, it is found that the pixel intensity followsan n G u s a nd s r b t o .N n G u s a nd s r b t o sa etypically characterized with high order moments. The ﬁrst-and second-order moments (mean and variance) measuresthe mean and average power pixel intensity of the image,respectively. The third-order mo ment (i.e., skewness) enablesthe neural network to distinguish mirror images of other-wise identical images while the fourth-order moment (i.e.,kurtosis) captures the features derived from the pixel inten-sities whose value has large dynamic range. In addition,the fourth-order moment can identify outliers in the imageswhich contain information about the edges of the wheatleaves.Authorized licensed use limited to: The University of British Columbia Library. Downloaded on July 15,2020 at 19:13:49 UTC from IEEE Xplore. Restrictions apply. SULISTYO et al. :C M U A I N LD E PI T L I E C EV S O NS N I GF RN T I N TC N E TE T M T O 1 5 1Fig. 10. Combination of several DSELM with committee machine andGA-based optimization for nitrogen content estimation.The statistical color features can be achieved by using thefollowing formulas :mean =¯y=1nn/summationdisplayi=1yi (19)variance =σ2=1nn/summationdisplayi=1(yi−¯y)2(20)skewness =skew =1n/summationtextni=1(yi−¯y)3σ3(21)kurtosis =kurt=1n/summationtextni=1(yi−¯y)4σ4(22)where yrefers to each color channel (red, green, and blue), nisthe number of object pixels, and σis the standard deviation.V. ITROGEN CONTENT ESTIMATIONUSING WEIGHTED DSELM SIn this section, we will explain further the ﬁnal step of ourproposed method, i.e., nitrogen estimation. Several DSELMsare utilized to perform nutrient estimation by combining theminto committee machine, as seen in Fig. 10. We alsoemploy GA to optimize the estimation results. In this paper,we limit our experiments up to ﬁve different DSELMs withﬁve hidden layer numbers. Each network is repeated 100 timesto eliminate the effect of the random bias numbers and initialweights. Subsequently, number of neural networks whichprovided the minimum mse are chosen to achieve the ﬁnalestimation.Committee machine can yield signiﬁcant improvements inthe estimation since it can minimize the effect of randomcomponent due to data noise in the generalization performanceof single network [38]. Basically, the concept of committeemachine is to combine outputs of several expert systems withthe same input data, with the aim of producing new output.In this paper, we use ensemble averaging as the combinationmethod. Committee machine with ensemble averaging pro-duces the same if not smaller amount of error as compared tosingle neural network. This can be shown as follows. Supposethat there are Pneural network systems to approximate atarget vector T.E c hn u a ln t o kh so t u tv c o Oiand error eiOi=T+ei. (23)Thus, the sum of the squared error for the ith neural networkyiisEi=ξ[(Oi−T)2]=ξ/bracketleftbige2i/bracketrightbig(24)where ξ[·]d n t st es a i t c le p c a i n .T ea e a eerror of each neural network Eave)is thenEave=1PP/summationdisplayi=1Ei=1PP/summationdisplayi=1ξ/bracketleftbige2i/bracketrightbig. (25)In other words, by means of committee machine, the outputvalue Ycan be achieved by simply averaging the outputvector OiY=1PP/summationdisplayi=1Oi. (26)Thus, the squared error of the committee machine ECOM)isECOM =ξ[(Y−T)2]=ξ/parenleftBigg1PP/summationdisplayi=1Oi−T/parenrightBigg2=ξ/parenleftBigg1PP/summationdisplayi=1ei/parenrightBigg2.(27)But sinceξ/parenleftBigg1PP/summationdisplayi=1ei/parenrightBigg2≤1PP/summationdisplayi=1ξ/bracketleftbige2i/bracketrightbig.Hence, we haveECOM ≤Eave. (28)Thus, the calculated error of the committee machine is alwayssmaller than if not equal to that of the single neural network.In this paper, we perform ensemble averaging using theDSELMs combiner to achieve more enhanced generalizationand system performance. The estimated nitrogen amount (Ne)of wheat leaves is calculated by using committee machine withsimple averaging method as the combiner of PDSELMs asNeave=1PP/summationdisplayp=1Op. (29)The simple averaging method as expressed in (28) indicatesthat each DSELM has the same weight to produce newoutput. Concurrently, we also investigate the possibility thateach DSELM has different eight. We apply weightedaveraging method according toNeweigh=P/summationdisplayp=1(wp×Op)s.t.P/summationdisplayp=1wp=1( 0 )where wpandOpare the weight and the output of pth singlenetwork, respectively.AG Ai su i i e dt od s o e rt eo t m mv l eo fthe weights in the developed committee learning. Basically,the procedures of the GA developed in this step are the sameas those in the color normalization. The ﬁtness function used inthis optimization is to minimize mse between the actual (Na)Authorized licensed use limited to: The University of British Columbia Library. Downloaded on July 15,2020 at 19:13:49 UTC from IEEE Xplore. Restrictions apply. 1252 IEEE TRANSACTIONS ON AUTOMATION SCIENCE AND ENGINEERING, VOL. 15, NO. 3, JULY 2018and the estimated nitrogen content (Ne)ofnsamples (seeFig. 10), which can be expressed as follows :argminw1n/summationdisplayi(Nai−Nei)2.In addition, the initial population size S(1)popand the mutationrate are set to 500 individuals and 0.006, respectively. Eachindividual is expressed by 16 =2×8) length of binarynumbers (0s and 1s).The level of the estimation accuracy is measured by cal-culating the error value of the actual and estimated nitrogencontent. In this research, we se the mean absolute percentageerror (MAPE) for the performance assessment. The less theerror is, the superior the prediction is. For comparison,several types of error are also measured, i.e., mean absoluteerror (MAE), mse,r o - e n s u r ee r r( M E ,a ds mof squared error (SSE). The error types used in this researchcan be expressed as follows :MAPE =100%nn/summationdisplayi=1/vextendsingle/vextendsingle/vextendsingle/vextendsingleNai−NeiNai/vextendsingle/vextendsingle/vextendsingle/vextendsingle(31)MAE =1nn/summationdisplayi=1|Nai−Nei| (32)mse=1nn/summationdisplayi=1(Nai−Nei)2(33)RMSE =/radicaltp/radicalvertex/radicalvertex/radicalbt1nn/summationdisplayi=1(Nai−Nei)2 (34)SSE =n/summationdisplayi=1(Nai−Nei)2(35)where nis the number of samples and NaandNeare theactual and the estimated [using either simple (28) or weightedaverage (29)] nitrogen content, respectively.VI. ESULTS AND DISCUSSIONA. Chlorophyll Meter-Based Nitrogen Content EstimationThe CM Minolta SPAD-502 was widely used to deter-mine the chlorophyll content in leaves by measuring theabsorbance of the leaf in two wavelength regions, i.e., redand infrared. After the signal processing steps, the absorbancewas displayed in units range from −9.9 to 199. Moreover,the chlorophyll amount was highly correlated with the nitrogencontent. In many research, SPAD meter value is linearlycorrelated with nitrogen content; however, our paper foundthat the coefﬁcient of determination R2)between them usingnonlinear regression is slightly bigger than that using linearregression.Based on the experiments conducted with 36 samples ofwheat leaves, the R2value of SPAD and nitrogen contentis 0.78 using linear regression and 0.83 using nonlinearregression, as seen in Fig. 11. It means that the relationshipbetween the SPAD and nitrogen amount is fairly strong.The estimated nitrogen amount can then be calculated byusing the regression equation. The error estimation of thisFig. 11. Relationship between the SPAD meter value and actual nitrogencontent.Fig. 12. Fitting plot of the actual and nonlinearly regressed estimated nitrogencontent of SPAD meter-based analysis.method is 8.30%, as seen in Fig. 12. Similar research withrelatively close relationships between the SPAD and nitrogenhave been reported in rice R2=0.89) [39] and oilseed rape(R2=0.74) [40]. The correlation between the SPAD meterreadings and nitrogen percentage in leaves was stronglyaffected by leaf thickness. The variation in leaf thickness caninﬂuence the accuracy of SPAD me ter readings, as this deviceworks based on the leaf’s capacity to absorb red and infraredlights.B. Image Analysis-Based Nitrogen Status Estimation1) DSELMs Fusion-Based Color Normalization: Based onour experiments, the proposed DSELMs fusion-based colorconstancy can be used to normalize wheat plant imagescaptured under various light intensities. After image normal-ization, we can assume that all images are captured under thesame light intensity and compared with each other.In this paper, we also compare our results with other existingmethods, i.e., MLPs fusion [28], gray world assumption [41],white-patch algorithm [42], linear regression model [43], andAuthorized licensed use limited to: The University of British Columbia Library. Downloaded on July 15,2020 at 19:13:49 UTC from IEEE Xplore. Restrictions apply. SULISTYO et al. :C M U A I N LD E PI T L I E C EV S O NS N I GF RN T I N TC N E TE T M T O 1 5 3TABLE ICOMPARISON OF COLOR NORMALIZATION RESULTSFig. 13. /Delta1ERGB of each patch using all methods.single MLP [44]. The parameters used in this comparison areaccuracy level and processing speed. The accuracy level ismeasured by calculating avera ge Euclidean distance of thetarget and the output RGB color of all patches by using thefollowing formula :/Delta1ERGB=/radicalbig(Rt−Re)2+(Gt−Ge)2+(Bt−Be)2(36)while the processing speed is measured by calculating thetime (in seconds) required to process color normalization ineach method. As seen in Table I, our proposed method usingDSELMs fusion is better than the aforementioned methods inboth accuracy and speed. The comparison of /Delta1ERGBof eachpatch by using all methods is also presented in Fig. 13.Basically, in the gray world as well as white patch andlinear model algorithms, color normalization is accomplishedby scaling color value of each pixel with certain constant.It does not require training process as that in neural networks.This is why the processing times of color normalization usingthese methods are very quick. On the other hand, the outputcolors are signiﬁcantly differen tc m a e dt ot et r e .T e ealgorithms, therefore, are not suitable to normalize plantsimages.All the neural network types used in this research has threeinput and output nodes, which represent red, green and bluecolor, respectively. In the MLP, we use one hidden layer with92 nodes, according to the following empirical formula :nh=/parenleftbiggni+no2/parenrightbigg+√np (37)where ni,nh,andnoare the number of input, hidden, andoutput layer nodes, respectively, and npis the number of inputpatterns in the training set (number of training samples).Furthermore, this neural network architecture is also usedin both the MPLs fusion and DSELMs fusion methods. Sincewe fuse 24 MLPs, the process tim e, therefore, is considerablylonger than that of single MLP. The results, however, is quitebetter, as indicated by the /Delta1ERGB value. The challenge toproduce better results and fast training on the color normaliza-tion process has been overcome by applying DSELMs fusion(see Table I). The color normalization error is less thanthat of MLPs fusion with processing speed 70 timesfaster.In this proposed method, we utilize the GA to optimize24αvalues as the output weights of each DSELM. Theseαmatrices are then applied to adjust wheat plant images byusing the developed DSELMs fusion method. An example oftheαmatrices used to obtain new image is as follows :Z=0.039 000 .069 000 .007·O1+0.053 000 .025 000 .005·O2+0.047 000 .014 000 .065·O3+...+0.064 000 .015 000 .008·O24.By applying the developed DSELMs fusion-based coloradjusting system and the optimized αmatrices, wheat cropimages with variation of light intensities will be transformedto that with standard light intensity (50 Klux). In this research,aw e tp a ti a eh sad m n i no f4 8 ×336 pixels.The parameter used for measuring the effectiveness of colornormalization is color variability of the images. This parametercan be measured by calculating standard deviation of the orig-inal images and the corrected images. The smaller the standarddeviation of image colors, the smaller the color variability ofthe images. As an example, from 30 plants images from thesame ﬁeld and the same fertilizer level, the standard deviationsof the original leaves images are 23.61, 14.54, and 28.52 forred, green, and blue, respectiv ely, while that of the correctedimages are 5.28, 4.15, and 6.32, respectively. This exampleshows that the proposed method can be used to lower thecolor variability of wheat plants images captured on ﬁeld withvarious light intensity.Authorized licensed use limited to: The University of British Columbia Library. Downloaded on July 15,2020 at 19:13:49 UTC from IEEE Xplore. Restrictions apply. 1254 IEEE TRANSACTIONS ON AUTOMATION SCIENCE AND ENGINEERING, VOL. 15, NO. 3, JULY 2018Fig. 14. Comparison of some threshold-based segmentation and thedeveloped DSELM-based image segmentation.TABLE IICOMPARISON OF IMAGE SEGMENTATION RESULTS2) DSELM-Based Image Segmentation and Feature Extrac-tion: After image correction using the developed DSELMsfusion, the next step is image segmentation. In Fig. 14,we show the comparison of image segmentation. The DSELM-based image segmentation, as described in Section IV hassuccessfully distinguished wheat leaves from other parts,such as weeds, soil, stones, and dried leaves. The proposedsegmentation method is superior to the conventional Otsualgorithm (threshold-based segmentation) and standard neuralnetwork learning algorithms such as MLP and ELM. Thedatabase pertaining to the color of leaves and nonleavesprovides sufﬁcient data to train the plant images. Therefore,the DSELM can precisely classify whether pixel belongs tothe leaves or nonleaves region.Furthermore, the devel oped DSELM method can accom-plish image segmentation process much faster than the stan-dard MLP and ELM, as shown in Table II. Table II showsthe obtained accuracy and time taken for these methodswhich indicated that the developed DSELM can preciselyclassify leaves or nonleaves region within less than one second.The image segmentation results using three different neuralnetwork types are all good as indicated by the accuracylevel. However, the developed DSELM can perform the imagesegmentation times faster than the MLP and slightly fasterthan the original ELM. Once all images have been seg-mented, 12 statistical color features as described previouslyTABLE IIICOMPARISON OF NITROGEN AMOUNT ESTIMATION ERRORSTABLE IVCOMPARISON OF ESTIMATION ERRORS USING COLORFEATURES AND THE PROPOSED METHODin Section IV are then extracted to be utilized as predictors inthe developed nitrogen estimation.3) DSELM and Committee Machine-Based Image NutrientEstimation: In this step, several DSELMs with various num-bers of hidden layers are combined and then trained todetermine which gives the best results. We establish thatthe combination of four DSELMs results in the minimumgeneralization error of netwo rks performance compared toother possible combinations. The ﬁrst combination used in thisstep is simple average. The estimated nitrogen amount is thencalculated, as follows :Yave=144/summationdisplayi=1Oi. (38)The best result relates to the ﬁrst type of committeemachine, i.e., simple average, ss b e u n l yc m a e dt ot a tof the second type combiner, i.e., weighted average, whichis optimized by the GA. By using this method, the weightsof the output of the network system are 0.127, 0.385, 0.193,and 0.295, respectively, for the ﬁrst until the fourth DSELM.The estimated nitrogen content can, therefore, be expressed asfollows:YGA=(0.127×O1)+(0.385×O2)+(0.193×O3)+(0.295×O4).(39)Table III shows the results on nitrogen estimation usingthe DSELM and the SPAD meter under various criteriasuch as MAPE, MAE, MSE, RMSE, and SSE. The SPADAuthorized licensed use limited to: The University of British Columbia Library. Downloaded on July 15,2020 at 19:13:49 UTC from IEEE Xplore. Restrictions apply. SULISTYO et al. :C M U A I N LD E PI T L I E C EV S O NS N I GF RN T I N TC N E TE T M T O 1 5 5meter is the current method used to determine the nitrogencontent of plant leave. Our results suggest that the proposedDSELM which extracts statisti cal features from the imageshas led to improved performance over the SPAD meter in allcriterions.Moreover, from Table III, we can perceive that by using asimple average combiner, the combination of four DSELMsprovides the best results comp ared to other network combina-tions. The MAPE of this combination is around 3%. However,the weighted average combiner with GA optimization offersenhanced results. As seen in Table III, the MAPE of theGA-based committee machine with four DSELMs is smallerthan the simple average method, i.e., 2.78%. It means thatthe deviation of the estimated nitrogen using this methodis approximately 2.78% of the actual nitrogen content. Forinstance, if the actual nitrogen content is 3%, then the esti-mated nitrogen is between 2.917% and 3.083%. Thus, the errornoted is relatively small.We also investigated the relationship between nitrogencontent and each color channel as well as number ofcombinations of them. research has been established thatthere are signiﬁcant correlations between chlorophyll contentin the maize leaf and the averages of the and components,as well as 2G-R-B of the linear transformation [4]. We alsoestimated the nitrogen content using the greenness indexdeveloped by Pagola et al. [45] Ikaw).Ikawis deﬁned asfollows :Ikaw=R−BR+B. (40)Based on the Ikawformula, Pagola et al. [46] modiﬁed thegreenness index to estimate nitrogen content in barley leavesand use the principal component analysis (PCA) to produce anew greenness index IPCA),a sf l o s :IPCA=0.7582 |R−B|−0.1168 |R−G|+0.6414 |G−B|.(41)According to our investigation, single color features andtheir combinations, including IPCAandIkaw,a en ts i a l efor nitrogen estimation. The estimation errors of those analysesare too high, compared to our proposed method, as seenin Table IV. The RGB values in those analyses are onlyobtained from the mean value of the observed leaves color.This value is not sufﬁcient to represent the color distributionof leaves color. In the propos ed method, we utilize not onlymean value, but also variance, skewness, and kurtosis of theobserved leaves color. The use of these statistical features ismore effective to describe the color distribution of leaves color.As seen in Table IV our proposed method is superior to all thediscussed methods, as it provides an estimation error of 2.78%.VII. ONCLUSIONAn v lc m u a i n li t l i e c ev s o ns n i gh sb e nproposed to acquire plant images and estimate nutrient contentin wheat leaves based on color features of plant imagescaptured on ﬁeld with signiﬁcant variation of sunlight inten-sities. The developed algorithm focuses on the developmentof DSELM and GA to overcome the problems on wide colorvariability due to different ligh ting conditions, image segmen-tation to distinguish crop leaves from complex background,and optimization of the nutrient estimation. The proposedmethod has been successfully demonstrated to normalizeimages as well as lower the color deviation and performimage segmentation much faster than other neural networkmethods. Furthermore, the combination of DSELMs withcommittee machine and GA has shown very promising resultsin estimating nitrogen content nw e tl a e sc m a e dw t hexisting methods.REFERENCES[1] . He, F. Liu, and D. Wu, “Nutrition management and automation,” inAgricultural Automation: Fundamentals and Practices .B c aR t n ,F ,USA: CRC Press, 2013, pp. 231–262.[2] P. Auearunyawat, T. Kasetkaem, A. Wongmaneeroj, A. Nishihara, andR. Keinprasit, “An automatic nitrogen estimation method in sugarcaneleaves using image processing techniques,” in Proc. Int. Conf. Agricult.Environ. Biol. Sci. (ICAEBS) ,2 1 ,p .3 – 2 .[3] X. Yao, W. Du, S. Feng, and J. Zou, “Image-based plant nutrient statusanalysis: An overview,” in Proc. IEEE Int. Conf. Intell. Comput. Intell.Syst. (ICIS) ,O t .2 1 ,p .2 9 – 4 5 .[4] Y. Xu, X. Wang, H. Sun, H. Wang, and Y. Zhan, “Study of mon-itoring maize leaf nutrition based on image processing and spectralanalysis,” in Proc. IEEE World Autom. Congr. (WAC) ,S p .2 1 ,pp. 465–468.[5] X. Yao, W. Luo, and Z. Yuan, “An adaptive and quantitative rubbernutrient status analyzing system by digital foliar images,” in Proc. IEEEInt. Congr. Image Signal Process. (CISP) ,O t .2 1 ,p .2 9 – 4 5 .[6] D. Pascale. (2006). The BabelColor Company .A c s e :2 1 .[ n i e .Available: http://www.babelcolor.com[7] H. Min, C. H. Jin, and Y. Sang-H ee, “A neural network approach tocolor constancy,” in Proc. 11th Int. Conf. Control, Autom. Syst. (ICCAS) ,Oct. 2011, pp. 1678–1681.[8] D. Cheng, B. Price, S. Cohen, and M. S. Brown, “Beyond white: Groundtruth colors for color constancy correction,” in Proc. IEEE Int. Conf.Comput. Vis. (ICCV) ,D c .2 1 ,p .2 8 3 6 .[9] J. Tang, C. Deng, and G.-B. Huang, “Extreme learning machine formultilayer perceptron,” IEEE Trans. Neural Netw. Learn. Syst. ,v l .2 ,no. 4, pp. 809–821, Apr. 2016.[10] L. L. C. Kasun, H. Zhou, G.-B. Huang, and C. M. Vong, “Representa-tional learning with extreme lear ning machine for big data,” IEEE Intell.Syst.,v l .2 ,n .6 ,p .3 – 4 ,N v .2 1 .[11] E. Cambria et al. ,“ x r m el a n n gm c i e s[ r n s&C n r v r -sies],” IEEE Intell. Syst. ,v l .2 ,n .6 ,p .3 – 9 ,N v / e .2 1 .[12] A. Beck and M. Teboulle, “A fast iterative shrinkage-thresholdingalgorithm for linear inverse problems,” SIAM J. Imag. Sci. ,v l .2 ,n .1 ,pp. 183–202, 2009.[13] A. Beck and M. Teboulle, “A fast iterative Shrinkage–Thresholdingalgorithm with application to wavelet-based image deblurring,” inProc. IEEE Int. Conf. Acoust., Speech, Sign. Process. ,A r .2 0 ,pp. 693–696.[14] H. X. Tian and Z. Z. Mao, “An ensemble ELM based on modiﬁedAdaBoost.RT algorithm for predicting the temperature of molten steelin ladle furnace,” IEEE Trans. Autom. Sci. Eng. ,v l .7 ,n .1 ,p .7 – 0 ,Jan. 2010.[15] D. Niu, Y. Sun, and F. Wang, “Op timization of advertising budget allo-cation over time based on LS-SVMR and DE,” IEEE Trans. Autom. Sci.Eng.,v l .1 ,n .4 ,p .1 7 – 0 2 ,O t .2 1 .[16] Y. Liu, F.-L. Wang, Y.-Q. Chang, and C. Li, “A SNCCDBAGG-basedNN ensemble approach for quality prediction in injection moldingprocess,” IEEE Trans. Autom. Sci. Eng. ,v l .8 ,n .2 ,p .4 4 4 7 ,Apr. 2011.[17] Z. Y. A. Ang, W. L. Woo, and E. Mes bahi, “Artiﬁcial neural networkbased prediction of energy generation from thermoelectric generatorwith environmental parameters,” J. Clean Energy Technol. ,v l .5 ,n .6 ,pp. 458–463, 2017.[18] C. Wei, W. L. Woo, and S. S. Dla y, “Nonlinear underdetermined blindsignal separation using Bayesian neural network approach,” Digit. SignalProcess. ,v l .1 ,n .1 ,p .5 – 8 ,2 0 .[19] W. L. Woo and S. S. Dlay, “Neural network approach to blind signalseparation of mono-nonlinearly mixed sources,” IEEE Trans. CircuitsSyst. I, Reg. Papers ,v l .5 ,n .6 ,p .1 3 – 2 7 ,J n .2 0 .Authorized licensed use limited to: The University of British Columbia Library. Downloaded on July 15,2020 at 19:13:49 UTC from IEEE Xplore. Restrictions apply. 1256 IEEE TRANSACTIONS ON AUTOMATION SCIENCE AND ENGINEERING, VOL. 15, NO. 3, JULY 2018[20] D. Liu, D. Wang, D. Zhao, Q. Wei, and N. Jin, “Neural-network-basedoptimal control for class of unknown discrete-time nonlinear systemsusing globalized dual heuristic programming,” IEEE Trans. Autom. Sci.Eng.,v l .9 ,n .3 ,p .6 8 6 4 ,J l .2 1 .[21] H. Zhang, C. Qin, and Y. Luo, “Neu ral-network-based constrainedoptimal control scheme for discre te-time switched nonlinear systemusing dual heuristic programming,” IEEE Trans. Autom. Sci. Eng. ,vol. 11, no. 3, pp. 839–849, Jul. 2014.[22] T. T. Teo, T. Logenthiran, and W. L. Woo, “Forecasting of photo-voltaic power using extreme learning machine,” in Proc. IEEE Innov.Smart Grid Technol.-Asia (ISGT Asia) ,B n k k ,T a l n ,N v .2 1 ,pp. 1–5.[23] S. B. Sulistyo, W. L. Woo, and S. S. Dlay, “Regularized neural networksfusion and genetic algorithm based on-ﬁeld nitrogen status estimation ofwheat plants,” IEEE Trans. Ind. Informat. ,v l .1 ,n .1 ,p .1 3 1 4 ,Feb. 2016.[24] A. Gijsenij, T. Gevers, and J. va nd eW i e ,“ o p t t o a lc l rconstancy: Survey and experiments,” IEEE Trans. Image Process. ,vol. 20, no. 9, pp. 2475–2489, Sep. 2011.[25] S. Bianco, G. Ciocca, C. Cusano, and R. Schettini, “Improving colorconstancy using indoor–outdoor image classiﬁcation,” IEEE Trans.Image Process. ,v l .1 ,n .1 ,p .2 8 – 3 2 ,D c .2 0 .[26] K. Barnard, V. Cardei, and B. unt, “A comparison of computationalcolor constancy algorithms—Part I: Methodology and experimentswith synthesized data,” IEEE Trans. Image Process. ,v l .1 ,n .9 ,pp. 972–983, Sep. 2002.[27] G.-B. Huang, L. Chen, and C.-K. Siew, “Universal approximation usingincremental constructive feedforward networks with random hiddennodes,” IEEE Trans. Neural Netw. ,v l .1 ,n .4 ,p .8 9 8 2 ,J l .2 0 .[28] S. B. Sulistyo, W. L. Woo, and S. S. Dlay, “Computational intelli-gent color normalization for wheat plant images to support precisionfarming,” in Proc. IEEE Int. Conf. Adv. Comput. Intell. ,F b .2 1 ,pp. 130–135.[29] J. Song, Y. Qiu, and Z. Liu, “Integrating optimal simulation bud-get allocation and genetic algorithm to ﬁnd the approximate Paretopatient ﬂow distribution,” IEEE Trans. Autom. Sci. Eng. ,v l .1 ,n .1 ,pp. 149–159, Jan. 2016.[30] C.-W. Chou, C.-F. Chien, and M. Gen, “A multiobjective hybrid geneticalgorithm for TFT-LCD module assembly scheduling,” IEEE Trans.Autom. Sci. Eng. ,v l .1 ,n .3 ,p .6 2 7 5 ,2 1 .[31] P. K. Jamwal, S. Hussain, and S. Q. Xie, “Three-stage design analysisand multicriteria optimization fap r l e la k er h b l t t o nr b tusing genetic algorithm,” IEEE Trans. Autom. Sci. Eng. ,v l .1 ,n .4 ,pp. 1433–1446, Oct. 2015.[32] F. Qiao, Y. M. Ma, L. Li, and H. X. Yu, “A Petri net and extendedgenetic algorithm combined schedulin gm t o df rw f rf b i a i n ”IEEE Trans. Autom. Sci. Eng. ,v l .1 ,n .1 ,p .1 7 2 4 ,J n .2 1 .[33] D. A. Coley, An Introduction to Genetic Algorithms for Scientists andEngineers .S n a o e :W r dS i n i c ,1 9 .[34] N. Mohamad, M. K. A. Arifﬁn, .A i ,F .M s a h ,a dI .M .S l e ,“Development of genetic algorithm toolbox using MATLAB in cuttingtool path optimization,” Sci. Res. Essays ,v l .8 ,n .3 ,p .1 4 – 8 7 ,2013.[35] A. Dacal-Nieto, E. Vázquez-Fernández, A. Formella, F. Martin,S. Torres-Guijarro, and H. González-Jorge, “A genetic algorithmapproach for feature selection in potatoes classiﬁcation by computervision,” in Proc. IEEE 35th Annu. Conf. Ind. Electron. ,N v .2 0 ,pp. 1955–1960.[36] F. J. Lin, P. K. Huang, and W. D. Chou, “Recurrent-fuzzy-neural-network-controlled linear induction motor servo drive using geneticalgorithms,” IEEE Trans. Ind. Electron. ,v l .5 ,n .3 ,p .1 4 – 4 1 ,Jun. 2007.[37] Q. K. Man, C. H. Zheng, X. F. Wang, and F. . Lin, “Recognitionof plant leaves using support vector machine,” in Advanced IntelligentComputing Theories and Applications. With Aspects of ContemporaryIntelligent Computing Techniques (Communications in Computer andInformation Science), vol. 15, D. S. Huang, D. C. Wunsch, D.S. Levine,and K. H. Jo, Eds. Berlin, Germany: Springer, 2008, pp. 192–199.[38] S. B. Sulistyo, W. L. Woo, and S. S. Dlay, “Ensemble neural net-works and image analysis for on-site estimation of nitrogen content inplants,” in Proc. SAI Intell. Syst. Conf. (Intellisys) ,L n o ,U K ,2 1 ,pp. 103–118.[39] H. Yang, J. Yang, . Lu, and J. He, “SPAD values and nitrogen nutritionindex for the evaluation of Rice nitrogen status,” Plant Prod. Sci. ,vol. 17, no. 1, pp. 81–92, 2014.[40] H.-Y. Song, Z.-L. Guo, Y. He, H. Fang, and Z.-Y. Zhu, “Non-destructiveestimation oilseed rape nitrogen status using chlorophyll meter,” in Proc.IEEE Int. Conf. Mach. Learn. Cybern. ,A g .2 0 ,p .4 5 – 2 6 .[41] M. T. T. Nguyen, C. L. D. A. Mai, and N. M. Kwok, “Estimating imageilluminant color based on gray world assumption,” in Proc. IEEE Int.Congr. Image Signal Process. ,O t .2 1 ,p .9 9 9 3 .[42] J. Y. Cepeda-Negrete and R. E. Sanchez-Yanez, “Color constancyalgorithms in practice,” in Proc. Robot. Summer Meet. (ROSSUM) ,2 1 ,pp. 78–79.[43] Y. A. Sari, R. V. H. Ginardi, and N. Suciati, “Color correction usingimproved linear regression algorithm,” in Proc. IEEE Conf. Inform.Commun. Technol. Syst. (ICIS) ,S p .2 1 ,p .7 – 8 .[44] C. Shengxian, D. Bangkui, S. Jiawei, L. Fan, Y. Shanrang, andX. Zhiming, “A colour constancy algorithm based on neural networkand application,” in Proc. IEEE World Congr. Intell. Control Autom. ,Jul. 2010, pp. 3100–3103.[45] S. Kawashima and M. Nakatani, An algorithm for estimating chloro-phyll content in leaves using video camera,” Ann. Botany ,v l .8 ,no. 1, pp. 49–54, 1998.[46] M. Pagola et al. ,“ e wm t o dt oa s s sb r e yn t o e nn t i i ns a u sbased on image colour analysis: Comparison with SPAD-502,” Comput.Electron. Agricult. ,v l .6 ,n .2 ,p .2 3 2 8 ,2 0 .[47] Y. Chen, H. Yu, C. Miao, B. Chen, X. Yang, and C. Leung, “Usingmotor patterns for stroke detection,” Sci. Adv. Comput. Psychophysiol. ,vol. 350, no. 6256, pp. 12–14, 2015.[48] G. Huang, S. Song, J. N. D. Gupta, and C. Wu, “Semi-supervised andunsupervised extreme learning machines,” IEEE Trans. Cybern. ,v l .4 ,no. 12, pp. 2405–2417, Dec. 2014.Susanto B. Sulistyo received the B.Sc. (Hons.)degree in agricultural technology and the M.Sc.degree in agricultural engineering sciences fromBogor Agricultural University, Bogor, Indonesia,in 2003 and 2008, respectively. He is currently pur-suing the Ph.D. degree with Newcastle University,Newcastle upon Tyne, U.K.His research interests include image processingand artiﬁcial intelligence pplications in agriculturalsystems.Di Wu received the B.S. degree from the MinzuUniversity of China, Beijing, China, and the M.Sc.degree in communications and signal processingfrom Newcastle University, Newcastle upon Tyne,U.K., in 2010 and 2012, respectively, where he iscurrently pursuing the Ph.D. degree.His research interests include deep learning, audioand image processing, source separation, and objectrecognition.Wai Lok Woo (M’09–SM’11) received the B.Eng.degree in electrical and electronics engineeringand the Ph.D. degree from Newcastle University,Newcastle upon Tyne, U.K.He is currently Reader in Intelligent SignalProcessing and the Director of Operations for theinternational branch of he university in Singapore.His major research is in mathematical theory andalgorithms for machine learning and multidimen-sional signal processing.Dr. Woo is member of the Institution EngineeringTechnology. He was recipient of the IEE Prize and the British Scholarship.Currently, he serves on the editorial board of the several international signalprocessing journals.Authorized licensed use limited to: The University of British Columbia Library. Downloaded on July 15,2020 at 19:13:49 UTC from IEEE Xplore. Restrictions apply. SULISTYO et al. :C M U A I N LD E PI T L I E C EV S O NS N I GF RN T I N TC N E TE T M T O 1 5 7S. S. Dlay received the B.Sc. (Hons.) degree inelectrical and electronic engineering and the Ph.D.degree in VLSI design from Newcastle University,Newcastle upon Tyne, U.K.In 1984, he was Lecturer with the Depart-ment of Electronic Systems Engineering, Univer-sity of Essex, Colchester, U.K. In 1986, he joinedNewcastle University as Lecturer, and thenin 2006, he became Personal Chair in SignalProcessing Analysis.Prof. Dlay is College Member of the Engineer-ing and Physical Science Research Council (EPSRC). He was recipientof Scholarship from the Engineer ing and Physical Science ResearchCouncil (EPSRC) and the Charles Hertzmann Award.Bin Gao (M’12–SM’14) received the B.S. degreein communications and signal processing fromSouthwest Jiao Tong University, Chengdu, China,in 2005, and the M.Sc. degree (Hons.) in communi-cations and signal processing and the Ph.D. degreefrom Newcastle University, Newcastle upon Tyne,U.K., in 2007 and 2011, respectively.He is currently Professor with the School ofAutomation Engineering, University of ElectronicScience and Technology of China, Chengdu. Hisresearch interests include sensor signal processing,machine learning, nondestructive testing and evaluation.Authorized licensed use limited to: The University of British Columbia Library. Downloaded on July 15,2020 at 19:13:49 UTC from IEEE Xplore. Restrictions apply.