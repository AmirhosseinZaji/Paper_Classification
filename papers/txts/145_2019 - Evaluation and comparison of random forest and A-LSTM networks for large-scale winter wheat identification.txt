remote sensing ArticleEvaluation and Comparison of Random Forest andA-LSTM Networks for Large-scale WinterWheat IdentiﬁcationTianle He1,2, Chuanjie Xie1,*, Qingsheng Liu1, Shiying Guan1,3and Gaohuan Liu11State Key Laboratory of Resources and Environmental Information System, Institute of Geographic Sciencesand Natural Resources Research, Chinese Academy of Sciences, Beijing 100101, China2University of Chinese Academy of Sciences, Beijing 100049, China3Henan Polytechnic University, Jiaozuo 454000, China*Correspondence: xiecj@lreis.ac.cn; Tel.:+86-136-8149-8766Received: 29 May 2019; Accepted: July 2019; Published: 12 July 2019/gid00030/gid00035/gid00032/gid00030/gid00038/gid00001/gid00033/gid00042/gid00045/gid00001/gid00048/gid00043/gid00031/gid00028/gid00047/gid00032/gid00046Abstract:Machine learning comprises group of powerful state-of-the-art techniques for land coverclassiﬁcation and cropland identiﬁcation. In this paper, we proposed and evaluated two modelsbased on random forest (RF) and attention-based long short-term memory (A-LSTM) networks thatcan learn directly from the raw surface reﬂectance of remote sensing (RS) images for large-scalewinter wheat identiﬁcation in Huanghuaihai Region (North-Central China). We used time series ofModerate Resolution Imaging Spectroradiometer (MODIS) images over one growing season and thecorresponding winter wheat distribution map for the experiments. Each training sample was derivedfrom the raw surface reﬂectance of MODIS time-series images. Both models achieved state-of-the-artperformance in identifying winter wheat, and the F1 scores of RF and A-LSTM were 0.72 and 0.71,respectively. We also analyzed the impact of the pixel-mixing e↵ect. Training with pure-mixed-pixelsamples (the training set consists of pure and mixed cells and thus retains the original distribution ofdata) was more precise than training with only pure-pixel samples (the entire pixel area belongs toone class). We also analyzed the variable importance along the temporal series, and the data acquiredin March or April contributed more than the data acquired at other times. Both models could predictwinter wheat coverage in past years or in other regions with similar winter wheat growing seasons.The experiments in this paper showed the e↵ectiveness and signiﬁcance of our methods.Keywords:winter wheat identiﬁcation; random forest; A-LSTM; pixel-mixing e↵ect; variableimportance analysis1. IntroductionFor many years, remote sensing (RS) systems have been widely applied for agricultural monitoringand crop identiﬁcation [1–4], and these systems provide many surface reﬂectance images that can beutilized to derive hidden patterns of vegetation coverage. In crop identiﬁcation tasks, the informationof growing dynamics or sequential relationships derived from time-series images is used to performclassiﬁcation. Although high-spatial-resolution datasets such as Landsat have clear advantages forcapturing the ﬁne spatial details of the land surface, such datasets typically do not have high temporalcoverage frequency over large regions and are often badly a↵ected by extensive cloud cover. However,coarse-resolution sensors such as the Moderate Resolution Imaging Spectroradiometer (MODIS)provide data at near-daily observational coverage frequency and over large areas [5]. While MODISdata are not proper option for resolving smaller ﬁeld sizes, they do provide valuable balancebetween high temporal frequency and high spatial resolution [6].Remote Sens.2019,11, 1665; doi:10.3390/rs11141665www.mdpi.com/journal/remotesensingRemote Sens. 2019,11, 1665 of 21Many methods for crop identiﬁcation or vegetation classiﬁcation using MODIS time series havebeen examined and implemented in the academic world 5–7]. common approach for treatingmultitemporal data is to retrieve temporal features or phonological metrics from vegetation index seriesobtained by band calculations. According to phenology and simple statistics, several key phenologymetrics, such as the base level, maximum level, amplitude, start date of the season, end date of theseason, and length of the season, extracted from time-series RS images are used as classiﬁcation featuresthat are su cient for accurate crop identiﬁcation. For example, Cornelius Senf et al. 5] mappedrubber plantations and natural forests in Xishuangbanna (Southwest China) using multispectralphenological metrics from MODIS time series, which achieved an overall accuracy of 0.735. Theyshowed that the key phenological metrics discriminating rubber plantations and natural forestswere the timing of seasonal events in the shortwaved infrared (SWIR) reﬂectance time series andthe Enhanced Vegetation Index (EVI) or SWIR reﬂectance during the dry season. Pittman et al. 6]estimated the global cropland extent and used the normalized di ↵erence vegetation index (NDVI) andthermal data to depict cropland phenology over the study period. Subpixel training datasets wereused to generate set of global classiﬁcation tree models using bagging methodology, resulting ina global per-pixel cropland probability layer. Tuanmu et al. 7] used phenology metrics generatedfrom MODIS time series to characterize the phenological features of forests with understory bamboo.Using maximum entropy modeling together with these phenology metrics, they successfully mappedthe spatial distribution of understory bamboo. To address image noise such as pseudo-lows andpseudo-hikes caused by shadows, clouds, weather or sensors, many studies have used mathematicalfunctions or complex models to smooth the vegetation index time series before feature extraction.Toshihiro Sakamoto et al. 8] adopted wavelet and Fourier transforms for ﬁltering time-series EVI data.Zhang et al. 9] used series of piecewise logistic functions ﬁt to remotely sensed vegetation indexdata to represent intra-annual vegetation dynamics. Furthermore, weighted linear regression 10],asymmetric Gaussian smoothing 11,12], Whittaker smoothing 13], and Savitzky-Golay ﬁltering 14]have also been widely used for the same reason. Yang Shao et al. 15] compared the Savitzky-Golay,asymmetric Gaussian, double-logistic, Whittaker, and discrete Fourier transformation smoothingalgorithms (noise reduction) and applied them to MODIS NDVI time-series data to provide continuousphenology data for land cover classiﬁcations across the Laurentian Great Lakes Basin, proving that theapplication of smoothing algorithm signiﬁcantly reduced image noise compared to the raw data.Although temporal feature extraction-based approaches have exhibited good performance incrop identiﬁcation tasks, they have some weaknesses. First, general temporal features or phenologicalcharacteristics may not be appropriate for the speciﬁc task. Expert experience and domain knowledgeare highly needed to design proper features and feature extraction pipeline. Second, the featuresextracted from the time series cannot always fully utilize all the data, and information loss is inevitable.These types of feature extraction processes usually come with limitations in terms of automation andﬂexibility when considering large-scale classiﬁcation tasks 16].Intelligent algorithms such as random forest (RF) and deep neural networks (DNNs) can learndirectly from the original values of MODIS data. They can apply all the values of time series as inputand do not need well-designed feature extractors, which could prevent the information loss that oftenoccurs in temporal feature extraction. These algorithms are convenient for large-scale implementationand application, and there are many processing frameworks based on RF or DNNs that are beingimplemented for cropland identiﬁcation. Related works will be introduced in the next paragraphs.Recently, RF classiﬁers have been widely used for RS images due to their explicit and explainabledecision-making process, and these classiﬁers are easily implemented in parallel structure forcomputing acceleration. Rodriguez-Galiano et al. 17] explored the performance of an RF classiﬁerin classifying 14 di ↵erent land categories in the south of Spain. Results show that the RF algorithmyields accurate land cover classiﬁcations and is robust to the reduction of the training set size andnoise compared to the classiﬁcation trees. Charlotte Pelletier et al. 18] assessed the robustness of usingRF to map land cover and compared the algorithm with support vector machine (SVM) algorithm.Remote Sens. 2019,11, 1665 of 21RF achieved an overall accuracy of 0.833, while SVM achieved an accuracy of 0.771. Works basedon RF usually use set of decision trees trained by di ↵erent subsets of samples to make predictionscollaboratively 19]. However, the splitting nodes still used well-designed features with randomselection, and this procedure might be complex and ine cient for the classiﬁcation of large-scale areas.In this paper, we proposed an RF-based model that directly learns from the original values of theMODIS time series for large-scale crop identiﬁcation in the Huanghuaihai Region to address the taskin an cient manner.Considering the successful applications of deep learning (DL) in computer vision, deep modelshave also been evaluated for time-series image classiﬁcation 16,20,21]. Researchers usually usepretrained baseline architectures of convolutional neural networks (CNNs), such as AlexNet 22],GoogLeNet 23] and ResNet 24], and ﬁne-tuning to automatically obtain advanced representationsof data, which are usually followed by softmax layer or SVM to adapt to speciﬁc RS classiﬁcationtasks. For times series scenarios, recurrent neural networks (RNNs) and long short-term memory(LSTM) networks are often used to analyze RS images due to their ability to capture long-termdependencies. Marc Rußwurm et al. 20] employed LSTM networks to extract temporal characteristicsfrom sequence of SENTINEL 2A observations and compared the performance with SVM baselinearchitectures. Zhong et al. 16] designed two types of DNN models for multitemporal crop classiﬁcation:one was based on LSTM networks, and the other was based on one-dimensional convolutional (Conv1D)layers. Three widely used classiﬁers were also tested and compared, including gradient boostingmachine (XGBoost), RF, and SVM classiﬁers. Although LSTM is widely used for sequential datarepresentation, Zhong et al. 16] revealed that its accuracy was the lowest among all the classiﬁers.Considering that the identiﬁcation of crop types is highly dependent on few temporal images ofkey growth stages such as the green-returning and jointing stages of winter wheat, it is importantfor the model to have the ability to pay attention to the critical images of the times series. In earlystudies, attention-based LSTM models were used to address sequence-to-sequence language translationtasks 25], which could generate proper word each time according to the speciﬁc input word and thecontext. Inspired by the machine translation community and crop growth cycle intuition, we proposedan attention-based LSTM model (A-LSTM) to identify winter wheat areas. The LSTM part of themodel transforms original values to advanced representations and then follows an attention layer thatencodes the sequence to one ﬁxed-length vector that is used to decode the output at each timestep.A ﬁnal softmax layer is then used to make prediction.In this study, we proposed two models, RF and A-LSTM, that can be ciently used for large-scalewinter wheat identiﬁcation throughout the Huanghuaihai Region, by building an automatic datapreprocessing pipeline that transforms time-series MODIS tiles into training samples that can be directlyfed into the models. As this study is the ﬁrst to apply an attention mechanism-based LSTM model tothe classiﬁcation of time-series images, comparison with RF and an evaluation of the performancewere also conducted. In addition, we analyzed the impacts of the pixel-mixing ↵ect with two di ↵erenttraining strategies in this paper. Furthermore, with the intuition that there is some di ↵erence in wheatsowing and harvesting time from north to south, we also evaluated the generalizability of the modelsto di ↵erent areas. Finally, our models were used to identify the distribution of winter wheat overthe past year, and we evaluated the performance via visual interpretation. Finally, we discussed theadvantages and disadvantages of our models.2. Materials2.1. Study AreaThe Huanghuaihai Region, located in the north-central region of China, surrounds the capital cityof Beijing, which is shown in Figure 1. It consists of seven provinces or municipality cities (i.e., Beijing,Tianjin, Hebei, Shandong, Henan, Anhui, and Jiangsu) stretching over an area of 778.9 thousand squarekilometers. Most of the Huanghuaihai Region lies within the North China Plain, which is formed byRemote Sens. 2019,11, 1665 of 21deposits from the Yellow River, Huai River, Hai River and their hundreds of branches. This region isbordered to the north by the Yanshan Mountains, to the west by the Taihang Mountains, to the southby the Dabie Mountains and the Yangtze River, and to the east by the East China Sea 26]. This regionhas typical continental temperate and monsoonal climate with four distinct seasons, including coldand dry winters and hot and humid summers. The Huanghuaihai Region is one of the most importantagricultural granaries in China, and the chief cereal crops include winter wheat, corn, millet, andpotatoes. Winter wheat is usually planted from September to October and harvested in late May orJune of the following year. Winter wheat is highly dependent on the water conditions, and artiﬁcialirrigation is supplied in this area 27].Remote Sens. 2019, 11, FOR PEER REVIEW of 22 Mountains, to the south by the Dabie Mountains and the Yangtze River, and to the east by the East China Sea [26]. This region has typical continental temperate and monsoonal climate with four distinct seasons, including cold and dry winters and hot and humid summers. The Huanghuaihai Region is one of the most important agricultural granaries in China, and the chief cereal crops include winter wheat, corn, millet, and potatoes. Winter wheat is usually planted from September to October and harvested in late May or June of the following year. Winter wheat is highly dependent on the water conditions, and artificial irrigation is supplied in this area [27]. Figure 1. Location of the study area. 2.2. Materials Description 2.2.1. MODIS Data In this section, we described the time-series images and reference data used for winter wheat identification in our paper. We downloaded 110 MODIS product images, specifically the MODIS/Terra vegetation indices 16-Day L3 Global 250-meter SIN Grid (MOD13Q1, Collection 6), from NASA Level-1 and Atmosphere Archive Distribution System Distributed Active Archive Center (LAADS DAAC). The product has four reflectance bands, i.e., blue, red, near-infrared and middle-infrared, which are centered at 469 nm, 645 nm, 858 nm, and 3.5 µm, respectively, and two vegetation index bands, NDVI and EVI, which can be used to maintain sensitivity over dense vegetation conditions [28]. The two vegetation indices, NDVI and EVI, are computed from atmospherically corrected bidirectional surface reflectance data that are masked for water, clouds, heavy aerosols, and cloud shadows. Specifically, the NDVI is computed from the near-infrared and red reflectance, while the EVI is computed from near-infrared, red, and blue reflectance. The detailed equations are as follows: ܫܸܦܰ ൌఘಿೃିఘೃఘಿೃାఘೃ (1)ܫܸܧ ൌఘಿೃିఘೃଵାఘಿೃାൈఘಿೃିǤହൈఘಳೠ (2)Figure 1. Location of the study area.2.2. Materials Description2.2.1. MODIS DataIn this section, we described the time-series images and reference data used for winter wheatidentiﬁcation in our paper. We downloaded 110 MODIS product images, speciﬁcally the MODIS /Terravegetation indices 16-Day L3 Global 250-m SIN Grid (MOD13Q1, Collection 6), from NASA Level-1and Atmosphere Archive Distribution System Distributed Active Archive Center (LAADS DAAC).The product has four reﬂectance bands, i.e., blue, red, near-infrared and middle-infrared, which arecentered at 469 nm, 645 nm, 858 nm, and 3.5 µm, respectively, and two vegetation index bands, NDVIand EVI, which can be used to maintain sensitivity over dense vegetation conditions 28]. The twovegetation indices, NDVI and EVI, are computed from atmospherically corrected bidirectional surfacereﬂectance data that are masked for water, clouds, heavy aerosols, and cloud shadows. Speciﬁcally,the NDVI is computed from the near-infrared and red reﬂectance, while the EVI is computed fromnear-infrared, red, and blue reﬂectance. The detailed equations are as follows:NDVI =⇢NIR⇢Red⇢NIR+⇢Red(1)Remote Sens. 2019,11, 1665 of 21EVI=⇢NIR⇢Red1+⇢NIR+6⇥⇢NIR7.5⇥⇢Blue(2)where ⇢NIR,⇢Redand⇢Bluerepresent near-infrared, red and blue reﬂectance, respectively. GlobalMOD13Q1 data are provided every 16 days at 250-m spatial resolution as gridded level-3 productin the sinusoidal projection. Cloud-free global coverage is achieved by replacing clouds with thehistorical MODIS time-series climatology record. Vegetation indices are used for global monitoring ofvegetation conditions and in products that exhibit land cover and land cover changes. The 110 imagesdownloaded in this study span the period from October 2017 to July 2018 with 16-day interval,resulting in 22 timesteps. Each timestep contains ﬁve tiles that can entirely cover the HuanghuaihaiRegion. We selected all six bands of each tile in the experiments, and the models could fully capturethe reﬂectance information, which would be ↵ective for crop identiﬁcation.To evaluate the generalizability of the models on historical data, we collected the same MOD13Q1product data for the 2016–2017 growing season for additional experiments.2.2.2. Reference DataIt is very challenging to collect reference data. Fortunately, we acquired crop map of the winterwheat distribution for the 2017–2018 growing season in the Huanghuaihai Region from the ChineseAcademy of Agricultural Sciences. The wheat map has spatial resolution of 16 and is in the Albersequal-area conic projection. Each pixel in the map is assigned value of or 1, which represent winterwheat or no winter wheat growth. Since we were not provided any details regarding how the map wascompleted or the reliability of the data, we simply reassessed the map by manually collecting samples.Speciﬁcally, we randomly selected 1000 pixels in the map and interpreted the pixels visually based onimages acquired from the Planet Explorer API https: //www.planet.com /explorer /). We acquired twohigh-resolution images in March 2018 and June 2018 from the Planet Explorer API, which are shown inFigure 2. First, it is easy to distinguish non-vegetation areas such as water, residential areas and bareland using images acquired in the two stages via visual interpretation. Practically, most vegetation inthe Huanghuaihai Region is deciduous forest, which is gray and still not germinated in March, whilewinter wheat has entered the green-returning stage. The few evergreen forests, such as pines andcypresses, will not turn yellow like mature wheat in June. To the best of our knowledge, the main cropduring the period from October 2017 to June 2018 was winter wheat, and there were no other crops orvegetation with growing stages similar to those of winter wheat in March and June. According to theimages acquired from the two critical growing periods of winter wheat, pixel was assumed to bewinter wheat when it appeared green in March and yellow in June. The evaluation results show thatthe overall accuracy of the crop map is 0.95, the precision of winter wheat is 0.89, the recall of winterwheat is 0.83 and the F1 score is 0.86 (The detailed explanations of overall accuracy, precision, recalland F1 score are shown in Section 4.3).Remote Sens. 2019, 11, FOR PEER REVIEW of 22 where ɏ୍ୖ, ɏୖୣୢ n ɏ୪୳ୣ represent near-infrared, red and blue reflectance, respectively. Global MOD13Q1 data are provided every 16 days at 250-meter spatial resolution as gridded level-3 product in the sinusoidal projection. Cloud-free global coverage is achieved by replacing clouds with the historical MODIS time-series climatology record. Vegetation indices are used for global monitoring of vegetation conditions and in products that exhibit land cover and land cover changes. The 110 images downloaded in this study span the period from October 2017 to July 2018 with 16-day interval, resulting in 22 timesteps. Each timestep contains five tiles that can entirely cover the Huanghuaihai Region. We selected all six bands of each tile in the experiments, and the models could fully capture the reflectance information, which would be effective for crop identification. To evaluate the generalizability of the models n i t r c l a a w c l e t d h s m MOD13Q1 product data for the 2016–2017 growing season for additional experiments. 2.2.2. Reference Data It is very challenging to collect reference data. Fortunately, we acquired crop map of the winter wheat distribution for the 2017–2018 growing season in the Huanghuaihai Region from the Chinese Academy of Agricultural Sciences. The wheat map has spatial resolution of 16 meters and is in the Albers equal-area conic projection. Each pixel in the map is assigned value of or 1, which represent winter wheat or no winter wheat growth. Since we were not provided any details regarding how the map was completed or the reliability of the data, we simply reassessed the map by manually collecting samples. Specifically, we randomly selected 1000 pixels in the map and interpreted the pixels visually based on images acquired from the Planet Explorer API (https://www.planet.com/explorer/). e c u r d w h g - e o u tion images in March 2018 and June 2018 from the Planet Explorer API, which are shown in Figure 2. First, it is easy to distinguish non-vegetation areas such as water, residential areas and bare land using images acquired in the two stages via visual interpretation. Practically, most vegetation in the Huanghuaihai Region is deciduous forest, which is gray and still not germinated in March, while winter wheat has entered the green-returning stage. The few evergreen forests, such as pines and cypresses, will not turn yellow like mature wheat in June. To the best of our knowledge, the main crop during the period from October 2017 to June 2018 was winter wheat, and there were no other crops or vegetation with growing stages similar to those of winter wheat in March and June. According to the images acquired from the two critical growing periods of winter wheat, pixel was assumed to be winter wheat when it appeared green in March and yellow in June. The evaluation results show that the overall accuracy of the crop map is 0.95, the precision of winter wheat is 0.89, the recall of winter wheat is 0.83 and the F1 score is 0.86 (The detailed explanations of overall accuracy, precision, recall and F1 score are shown in section 4.3). Similarly, we visually interpreted 1000 pixels at the same locations during the 2016–2017 growing season from the Planet Explorer API in the same manner to form our historical testing dataset. These collected samples were used to evaluate the accuracy of the prediction map informed by the trained models using historical (2016–2017) MODIS data. (a) Figure 2. Cont.Remote Sens. 2019,11, 1665 of 21Remote Sens. 2019, 11, FOR PEER REVIEW of 22 (b) Figure 2. Two images of the same parcel acquired in March 2018 (a) and June 2018 (b) from the Planet Explorer API. In March, winter wheat enters the green-returning stage, while most of the other vegetation is still not germinated. In June, winter wheat enters maturation stage and turns yellow, while other vegetation is green. Therefore, it is easy to distinguish wheat areas and other land cover types using images acquired in the two stages via visual interpretation. 2.3. Data Preprocessing In this study, we built data preprocessing pipeline to extract training samples from the MODIS time series. First, image mosaics were applied to the five image tiles at each timestep. Then, mosaic images were projected to the Albers equal-area conic coordinate system, which was coincident with the reference data, thus stably maintained the area of each cell. Next, mask of the Huanghuaihai Region was used to extract the data within the study boundary. Since the spatial resolution of MODIS data was 250 meters, we resampled the 250-meter-spatial-resolution MODIS data to spatial resolution of 224 meters with the nearest neighbor resampling method and aligned them with the reference data, which have 16-meter spatial resolution. Therefore, 196 pixels of the reference map were aligned using 0-1 annotation within single MODIS cell. Furthermore, we counted the quantities of 0s and 1s in each MODIS cell, which were used to distinguish pure cells that were completely filled with or values from mixed cells that were filled with both and values. Some crop map pixels within the MODIS cells inside the border had no values, and we simply removed these incomplete data. To extract training samples, each pure MODIS cell was annotated with or 1, which represented winter wheat or no winter wheat growth, respectively. For mixed MODIS cells, threshold was selected to determine whether the cell should be labeled as positive or negative, and these cells were labeled as ͳି m x d i e w e t o Ͳି (mixed pixel no-wheat). The following inequality shows the labeling process. where d n t s h l b l f M D S e l ܿ e o e t e u n i i s f h a p x l o r f r n e map within one MODIS cell, and ǫǫ is the threshold which is used to determine the label of mixed MODIS cell. We simply set ǫǫ to 98. As mentioned in Section 2.2.1, each timestep of MODIS image has bands, which are blue, red, near-infrared, middle-infrared, NDVI and EVI. We took the digital value from each MODIS cell throughout the 22 timesteps and the corresponding labels as the training samples; each sample has 132 variables and one class annotation. Throughout the Huanghuaihai ݕൌە۔ۓͳǡሺܿൌͳ ሻͳିǡሺܿߠሻͲିǡሺܿ൏ߠሻͲǡሺܿൌͲሻ (3) Figure 2. Two images of the same parcel acquired in March 2018 a) and June 2018 b) from thePlanet Explorer API. In March, winter wheat enters the green-returning stage, while most of the othervegetation is still not germinated. In June, winter wheat enters maturation stage and turns yellow,while other vegetation is green. Therefore, it is easy to distinguish wheat areas and other land covertypes using images acquired in the two stages via visual interpretation.Similarly, we visually interpreted 1000 pixels at the same locations during the 2016–2017 growingseason from the Planet Explorer API in the same manner to form our historical testing dataset. Thesecollected samples were used to evaluate the accuracy of the prediction map informed by the trainedmodels using historical (2016–2017) MODIS data.2.3. Data PreprocessingIn this study, we built data preprocessing pipeline to extract training samples from the MODIStime series. First, image mosaics were applied to the ﬁve image tiles at each timestep. Then, mosaicimages were projected to the Albers equal-area conic coordinate system, which was coincident with thereference data, thus stably maintained the area of each cell. Next, mask of the Huanghuaihai Regionwas used to extract the data within the study boundary. Since the spatial resolution of MODIS data was250 m, we resampled the 250-m-spatial-resolution MODIS data to spatial resolution of 224 withthe nearest neighbor resampling method and aligned them with the reference data, which have 16-mspatial resolution. Therefore, 196 pixels of the reference map were aligned using 0-1 annotationwithin single MODIS cell. Furthermore, we counted the quantities of 0s and 1s in each MODIS cell,which were used to distinguish pure cells that were completely ﬁlled with or values from mixedcells that were ﬁlled with both and values. Some crop map pixels within the MODIS cells inside theborder had no values, and we simply removed these incomplete data. To extract training samples,each pure MODIS cell was annotated with or 1, which represented winter wheat or no winter wheatgrowth, respectively. For mixed MODIS cells, threshold was selected to determine whether the cellshould be labeled as positive or negative, and these cells were labeled as 1_(mixed pixel wheat) or 0_(mixed pixel no-wheat). The following inequality shows the labeling process.y=8>>>>>><>>>>>>:1,(c=196)1_,(c✓)0_,(c<✓)0,(c=0)(3)where ydenotes the label of MODIS cell, cdenotes the quantities of wheat pixels of reference mapwithin one MODIS cell, and ✓is the threshold which is used to determine the label of mixed MODIScell. We simply set ✓to 98. As mentioned in Section 2.2.1, each timestep of MODIS image has bands,Remote Sens. 2019,11, 1665 of 21which are blue, red, near-infrared, middle-infrared, NDVI and EVI. We took the digital value fromeach MODIS cell throughout the 22 timesteps and the corresponding labels as the training samples;each sample has 132 variables and one class annotation. Throughout the Huanghuaihai Region, weacquired approximately 13 million samples, and the distribution of samples is shown in Table 1.Table 1. Data samples extracted from Moderate Resolution Imaging Spectroradiometer (MODIS) images.Pure Wheat(1)PureNo-wheat (0)Mixed PixelsWheat (1 _)Mixed PixelsNo-Wheat (0 _)Total620287 6338524 2679611 3566889 132053112.4. Dataset PartitionTo train and evaluate our model, the datasets must be partitioned into training sets and testingsets. As the MODIS data have cell size of 250 m, the spatial correlation might be nonsigniﬁcant.We assume that each MODIS cell is independent of the others. The total dataset was partitioned in thefollowing manner:•Pure-mixed pixel set. The entire dataset was ﬁrst randomly partitioned into training set andtesting set with ratio of 4:1. Both the training set and testing set consist of pure-pixel samplesand mixed-pixel samples. We call this type of training set pure-mixed pixel set.•Pure pixel set. Then, we further selected all the pure-pixel samples (the entire MODIS cell is eithercovered with winter wheat or there is no winter wheat) from the pure-mixed pixel set as the newtraining dataset, which was called the pure pixel set, with the intuition that pure-pixel samplesmight be representative of the characteristics of wheat areas, while mixed-pixel samples mightinclude noise. We kept the testing dataset unchanged but trained models using the pure-mixedpixel set and pure pixel set for further studies.2.5. North-South PartitionTo evaluate the generalizability of our model to di ↵erent areas, we also divided our dataset intoseveral parts according to the pixel location from north to south and utilized three parts for trainingand the rest parts for testing. As shown in Figure 3, the dataset was equally partitioned into eight partsaccording to latitude. The number of samples in each part is reported in Table 2. As the numbers ofsamples in Part and Part were small, we combined part 1, part and part to form the trainingset and testing set with the ratio of 4:1, and used part 4, part 5, part 6, part and part to evaluatethe generalizability.Table 2. The number of samples in each geographically partitioned dataset.Quantity Part Part Part Part Part Part Part Part 8Pure Pos 1069 34154 159010 117132 135805 158393 14014 710Pure Neg 1313370 773568 816377 829138 736828 924470 685303 259470Mixed 82532 339855 1034789 785234 1568533 1802182 565074 68301Total 1396971 1147577 2010176 1731504 2441166 2885045 1264391 328481Remote Sens. 2019,11, 1665 of 21Remote Sens. 2019, 11, FOR PEER REVIEW of 22 Figure 3. Geographical partitioning strategy. The whole region was partitioned into eight regions from north to south. Table 2. The number of samples in each geographically partitioned dataset. QuantityPart Part Part Part Part Part Part Part Pure Pos 1069 34154 159010 117132 135805 158393 14014 710 Pure Neg 1313370 773568 816377 829138 736828 924470 685303 259470 Mixed 82532 339855 1034789 785234 1568533 1802182 565074 68301 Total 1396971 1147577 2010176 1731504 2441166 2885045 1264391 328481 3. Methods 3.1. RF Method for Crop Identification The RF method is an ensemble learning algorithm that consists of many decision trees that are combined to create prediction. Each tree in the ensemble is trained using bootstrap sampling strategy (sample drawn with replacement), in which the training dataset of an individual tree is subset randomly picked from the whole dataset [19]. In addition, when splitting node during the construction of the tree, the split point that is chosen is the best split among random subset of the features.The final output is the average of all the trees, thus decreasing the variance of the results. Although the bias of the forest usually increases slightly due to the randomness in the tree, this increase is less than the increase in bias required to compensate for the decrease in variance. As result, the method performs better. As shown in section 2.2.1, our datasets are composed of 22 timesteps, and each timestep includes four raw reflectance bands and two vegetation index bands; thus, each sample contains 132 variables with an annotated label. RF operates by constructing multiple random classification trees, and each tree randomly selects several variables to make decision rules. In our experiment, a d d n t the number of trees and the number of selected a i b e , e p c i e y T e u b r f r e ݊ represents the complexity and ability of RF to learn patterns from the data. Therefore, needs to be Figure 3. Geographical partitioning strategy. The whole region was partitioned into eight regions fromnorth to south.3. Methods3.1. RF Method for Crop IdentiﬁcationThe RF method is an ensemble learning algorithm that consists of many decision trees that arecombined to create prediction. Each tree in the ensemble is trained using bootstrap samplingstrategy (sample drawn with replacement), in which the training dataset of an individual tree isa subset randomly picked from the whole dataset 19]. In addition, when splitting node during theconstruction of the tree, the split point that is chosen is the best split among random subset of thefeatures. The ﬁnal output is the average of all the trees, thus decreasing the variance of the results.Although the bias of the forest usually increases slightly due to the randomness in the tree, this increaseis less than the increase in bias required to compensate for the decrease in variance. As result, themethod performs better.As shown in Section 2.2.1, our datasets are composed of 22 timesteps, and each timestep includesfour raw reﬂectance bands and two vegetation index bands; thus, each sample contains 132 variableswith an annotated label. RF operates by constructing multiple random classiﬁcation trees, and eachtree randomly selects several variables to make decision rules. In our experiment, nandkdenote thenumber of trees and the number of selected variables, respectively. The number of trees nrepresentsthe complexity and ability of RF to learn patterns from the data. Therefore, nneeds to be large enoughin case some samples or variables are selected only once or even missed in all subspaces. As nincreases,the performance of RF tends to remain unchanged, however, the computing resource needs to increase.An increase in the selected variables kgenerally improves the performance of an individual tree, butthe variance of an individual tree decreases, and the computing resources required for the individualtree increase. Hence, we need to strike balance and ﬁnd the two optimal parameters nandk. To do so,we built many RF models with nincreasing from 100 to 1000 and kincreasing from to 132. The overallaccuracy was used to evaluate the performance of the model. In addition, the minimum number ofsamples required to split node was set to 2, while the minimum number of samples of leaf nodewas set to 1. The maximum tree depth was not ﬁxed, and the nodes were expanded until all leavesRemote Sens. 2019,11, 1665 of 21were pure or until all leaves contained less than the minimum number of samples. For each individualtree, Gini impurity was used to measure the quality of split. When making an inference, RF combinesall the equally weighted tree classiﬁers by averaging their probabilistic predictions instead of lettingeach classiﬁer vote for single class. The predicted class is the one with the highest probability.3.2. A-LSTM Architecture for Crop IdentiﬁcationLSTM is kind of special RNN architecture that is designed for long-term dependency problems.Both the standard RNN and LSTM have repeated neural units that can be thought of multiple copies ofthe same network and have the form of chain of repeating modules in neural network. In standardRNNs, the repeating module will have very simple structure, such as single tanh layer, as shown inFigure 4. LSTMs also utilize this chain structure, but the repeating module has di ↵erent structure.Instead of having single neural network layer, there are four gates, which are the forget gate, inputgate, modulation gate, and output gate, as shown in Equation (4)–(7), respectively, and these gatesinteract in speciﬁc manner 20].ft=f⇣Wfdataxt+Wfstateht1+bf⌘, (4)it=i⇣Widataxt+Wistateht1+bi⌘, (5)gt=g⇣Wgdatagt+Wgstateht1+bg⌘, (6)ot=o⇣Wodataxt+Wostateht1+bo⌘, (7)These gates inﬂuence the ability of LSTM cells to discard old information, gain new informationand use that information to create an output vector. The cell state vector ctstores the internal memoryand is then updated using the Hadamard operator which performs elementwise multiplication,while the layerwise hidden state vector is further derived from the LSTM output gate vector ot[20].ct=ftct1+itgt, (8)ht=oth(ct), (9)Remote Sens. 2019, 11, FOR PEER REVIEW of 22 large enough in case some samples or variables are selected only once or even missed in all subspaces. As i c e s s t e e f r a c o R t n s o e ain unchanged, however, the computing resource needs to increase. An increase in the selected variables generally improves the performance of an individual tree, but the variance of an individual tree decreases, and the computing resources required for the individual tree increase. Hence, we need to strike balance and find the two optimal parameters a d .To do so, we built many RF models with i c e s n f o 1 0 o 0 0 n ݇ increasing from to 132. The overall accuracy was used to evaluate the performance of the model. In addition, the minimum number of samples required to split node was set to 2, while the minimum number of samples of leaf node was set to 1. The maximum tree depth was not fixed, and the nodes were expanded until all leaves were pure or until all leaves contained less than the minimum number of samples. For each individual tree, Gini impurity was used to measure the quality of split. When making an inference, RF combines all the equally weighted tree classifiers by averaging their probabilistic predictions instead of letting each classifier vote for single class. The predicted class is the one with the highest probability.3.2. A-LSTM Architecture for Crop Identification LSTM is kind of special RNN architecture that is designed for long-term dependency problems. Both the standard RNN and LSTM have repeated neural units that can be thought of multiple copies of the same network and have the form of chain of repeating modules in neural network. In standard RNNs, the repeating module will have very simple structure, such as single tanh layer, as shown in Figure 4. LSTMs also utilize this chain structure, but the repeating module has different structure. Instead of having single neural network layer, there are four gates, which are the forget gate, input gate, modulation gate, and output gate, as shown in Equation (4), Equation (5), Equation (6), and Equation (7), respectively, and these gates interact in specific manner [20]. These gates influence the ability of LSTM cells to discard old information, gain new information and use that information to create an output vector. The cell state vector ܿ௧ stores the internal memory and is then updated using the Hadamard operator Ĵ, which performs elementwise multiplication, while the layerwise hidden state vector is further derived from the LSTM output gate vector [ 0 . (a) (b) ݂௧ൌߪሺܹௗ௧ݔ௧ܹ௦௧௧݄௧ିଵܾሻǡ (4) ݅௧ൌߪሺܹௗ௧ݔ௧ܹ௦௧௧݄௧ିଵܾሻǡ (5) ݃௧ൌߪ൫ܹௗ௧݃௧ܹ௦௧௧݄௧ିଵܾ൯ǡ(6) ௧ൌߪሺܹௗ௧ݔ௧ܹ௦௧௧݄௧ିଵܾሻǡ(7) ܿ௧ൌ݂௧ٖܿ௧ିଵ݅௧ٖ݃௧ǡ (8) ݄௧ൌ௧ߪٖሺܿ௧ሻǡ (9) Remote Sens. 2019, 11, FOR PEER REVIEW 10 of 22 (c) Figure 4. (a) The simple recurrent neural network (RNN) architecture, (b) the attention-based long short-term memory (A-LSTM) architecture, (c) the unrolled chain-type RNN structure. To address the original crop identification problem with time-series MODIS images, we proposed an end-to-end encoder-decoder architecture, which is shown in Figure 5. The encoder consists of three bidirectional LSTM layers that are stacked together with the full sequence returned. The input sequence ,which is shown in Equation (10), has 22 timesteps and six variables in each step, which is coincident with our time-series data: ൌሺଵǡǥǡ୧ǡǥǡ୲ሻǡ୧א୩ (10) where is the length of input sequence and is the dimensionality of data. In the encoder, each LSTM layer has 128 hidden units and returns the full sequence to the next layer. The output of the three-layer encoder, which is shown in Equation (11), is sequence of hidden states: ൌሺଵǡǥǡ୧ǡǥǡ୲ሻǡ୧א୩ (11) ݄ൌ݂ሺݔǡ݄ିଵሻ (12) where r p e e t t e i d n t t a t m i and is nonlinear function. In the decoder section, considering that it is difficult for the network to address long sequences, we included an attention mechanism in our network [25]. This mechanism looks at the complete encoded sequence to determine which encoded steps to weight highly and generates context vector for each class. Each encoded step i c u e t e n o m t o o t he whole input sequence due to the recurrent layers, and it has strong focus on the parts surrounding the i-th step of the input sequence. The context vector i c m u e b t e e g t d u o t e e n o a i n ݄: ୨ൌσȽ୨୧୧୲୧ୀଵ (13) where the weight Ƚ୨୧ o e c ݄ s o p t d y Ƚ୨୧ൌୣ୶୮ሺୣౠሻσୣ୶୮ሺୣౠሻ౪సభ (14) where i t e e g h f h e c d d e u n e n ݁ s n l g m n m d l w i h s h w Equation (15), represents how well the output at position a d h h d e a n t t o ݄ a c . ݁ൌ݃ ݏǡ݄ሻ (15) ݕൌ ݏ (16) where i t e i d n e r n f h o t u a p s t o ݆ n ݕ represents the probability distribution of wheat and no-wheat. Figure 4. (a) The simple recurrent neural network (RNN) architecture, b) the attention-based longshort-term memory (A-LSTM) architecture, c) the unrolled chain-type RNN structure.To address the original crop identiﬁcation problem with time-series MODIS images, we proposedan end-to-end encoder-decoder architecture, which is shown in Figure 5. The encoder consists ofthree bidirectional LSTM layers that are stacked together with the full sequence returned. The inputRemote Sens. 2019,11, 1665 10 of 21sequence x, which is shown in Equation (10), has 22 timesteps and six variables in each step, which iscoincident with our time-series data:x=(x1,...,xi,...,xt),xi2Rk(10)where tis the length of input sequence and is the dimensionality of data.Remote Sens. 2019, 11, FOR PEER REVIEW 11 of 22 Figure 5. Overview of the A-LSTM architecture. The attention mechanism looks at the complete encoded sequence to determine the encoded steps to weigh highly and generates context vector. The decoder network uses these context vectors to make prediction. 3.3. Comparison and Evaluation of the Model Performance In this paper, we used four metrics to evaluate the performance in the context of the binary classification problem. The precision, recall, overall accuracy, and F1 score were derived from the confusion matrix charted by the predicted and actual classification results [29]. The confusion matrix is shown in Table 3. In the table, positive and negative represent winter wheat and no-wheat, respectively. TP and FP refer to the number of predicted positives that were correct and incorrect, and TN and FN refer to the number of predicted negatives that were correct and incorrect. The four metrics are defined in Equations (17)–(20), respectively. Specifically, the precision denotes the proportion of predicted positives that are actual positives, while the recall denotes the proportion of actual positives that are correctly predicted positives. The overall accuracy is the proportion of the total cases that are correctly predicted, while the F1 score represents the harmonic mean of the recall and precision. Table 3. Confusion matrix charted by the predicted and actual classification. o i i e p e i t d Negative (predicted) Positive (actual) True positives (TP) False negatives (FN) Negative (actual) False positives (FP) True negatives (TN) First, the two models were trained with the pure-mixed pixel set consisting of pure pixel samples and mixed pixel samples. Considering that pure-pixel samples are representative of the characteristics of wheat areas, while mixed-pixel samples might include noises, we also used the pure ݊݅ݏ݅ܿ݁ݎ ൌܲܶܲܶ ܲܨ (17) ݈݈ܽܿ݁ݎ ൌܲܶܲܶ ܰܨ (18) ݕܿܽݎݑ݈݈ܿܿܽܽݎ݁ݒ ൌܲܶ ܰܶܲܶ ܲܨܰܨܰܶ(19) ݂ͳ݁ݎܿݏ ʹൈ݊݅ݏ݅ܿ݁ݎൈ݈݈ܽܿ݁ݎ݊݅ݏ݅ܿ݁ݎ݈݈ܽܿ݁ݎ (20) Figure 5. Overview of the A-LSTM architecture. The attention mechanism looks at the completeencoded sequence to determine the encoded steps to weigh highly and generates context vector. Thedecoder network uses these context vectors to make prediction.In the encoder, each LSTM layer has 128 hidden units and returns the full sequence to the next layer.The output of the three-layer encoder, which is shown in Equation (11), is sequence of hidden states:h=(h1,...,hi,...,ht),hi2Rk(11)hi=f(xi,hi1) (12)where hirepresents the hidden state at time iand fis nonlinear function.In the decoder section, considering that it is di cult for the network to address long sequences,we included an attention mechanism in our network 25]. This mechanism looks at the completeencoded sequence to determine which encoded steps to weight highly and generates context vectorcjfor each class. Each encoded step hiincludes the information of the whole input sequence due to therecurrent layers, and it has strong focus on the parts surrounding the i-thstep of the input sequence.The context vector cjis computed by the weighted sum of these annotations hi:cj=tXi=1↵jihi (13)where the weight ↵jifor each hiis computed by↵ji=exp⇣eji⌘Pti=1exp⇣eji⌘ (14)where tis the length of the encoded sequence and ejiis an alignment model, which is shown Equation(15), represents how well the output at position jand the hidden annotation himatch.eji=g⇣sj,hi⌘(15)Remote Sens. 2019,11, 1665 11 of 21y=softmax (s) (16)where sjis the hidden neuron of the output at position jandyrepresents the probability distributionof wheat and no-wheat.3.3. Comparison and Evaluation of the Model PerformanceIn this paper, we used four metrics to evaluate the performance in the context of the binaryclassiﬁcation problem. The precision, recall, overall accuracy, and F1 score were derived from theconfusion matrix charted by the predicted and actual classiﬁcation results 29]. The confusion matrix isshown in Table 3. In the table, positive and negative represent winter wheat and no-wheat, respectively.TP and FP refer to the number of predicted positives that were correct and incorrect, and TN and FNrefer to the number of predicted negatives that were correct and incorrect. The four metrics are deﬁnedin Equations (17)–(20), respectively. Speciﬁcally, the precision denotes the proportion of predictedpositives that are actual positives, while the recall denotes the proportion of actual positives that arecorrectly predicted positives. The overall accuracy is the proportion of the total cases that are correctlypredicted, while the F1 score represents the harmonic mean of the recall and precision.precision =TPTP+FP(17)recall =TPTP+FN(18)overallaccuracy =TP+TNTP+FP+FN+TN(19)f1score =2⇥precision ⇥recallprecision +recall(20)Table 3. Confusion matrix charted by the predicted and actual classiﬁcation.Positive (predicted) Negative (predicted)Positive (actual) True positives (TP) False negatives (FN)Negative (actual) False positives (FP) True negatives (TN)First, the two models were trained with the pure-mixed pixel set consisting of pure pixel samplesand mixed pixel samples. Considering that pure-pixel samples are representative of the characteristicsof wheat areas, while mixed-pixel samples might include noises, we also used the pure pixel set to trainthe two models. We kept the testing set unchanged to evaluate the performances of the two modelstrained with the two di ↵erent datasets. Moreover, we evaluated the generalizability of the models viathe north-south dataset partitioning strategy. In practice, our models could also be used to identifycroplands in historical datasets. Field-collected reference data were used for analysis and evaluation.More details about the experimental results and analysis are provided in the next section.4. Experiments and Results Analysis4.1. RF Fine-TuningWe used the Python Scikit-learn 30] package to implement our RF experiments following theinstructions in Section 3.1. Hundreds of RF models were built to ﬁne-tune the RF parameters n(numberof trees) and k(number of selected variables) with di ↵erent combinations, which are shown in Figure 6.We used the overall accuracy score to measure the performance of each model. To balance performanceand the cost of computation, the parameter combination with the highest score was chosen. Figure 6shows the changes in model performance with nvalues from 100 to 1000 and kvalues from to 132.Remote Sens. 2019,11, 1665 12 of 21When equals 500 and kequals 40, the performance of the RF method remains stable; thus, we selectedthis combination for the following experiments.Remote Sens. 2019, 11, FOR PEER REVIEW 12 of 22 pixel set to train the two models. We kept the testing set unchanged to evaluate the performances of the two models trained with the two different datasets. Moreover, we evaluated the generalizability of the models via the north-south dataset partitioning strategy. In practice, our models could also be used to identify croplands in historical datasets. Field-collected reference data were used for analysis and evaluation. More details about the experimental results and analysis are provided in the next section. 4. Experiments and Results Analysis 4.1. RF Fine-Tuning We used the Python Scikit-learn [30] package to implement our RF experiments following the instructions in Section 3.1. Hundreds of RF models were built to fine-tune the RF parameters (number of trees) and ݇( u b r f e e t d a i b e ) i h i f r n c m i a i n , h c a e shown in Figure 6. We used the overall accuracy score to measure the performance of each model. To balance performance and the cost of computation, the parameter combination with the highest score was chosen. Figure shows the changes in model performance with v l e f o 1 0 o 0 0 n ݇ a u s r m t 1 2 W e n q a s 0 a d equals 40, the performance of the RF method remains stable; thus, we selected this combination for the following experiments. (a) b Figure 6. Fine-tuning of the parameters and of the random forest (RF) model, (a) the overall accuracy of the RF trained on pure-mixed pixel set, (b) the overall accuracy of the RF trained on Pure pixel set. When equals 500 and equals 40, the performances of RF models converge; thus, we selected this combination for further experiments. 4.2. A-LSTM Training and Evaluation For the A-LSTM method, we used Python TensorFlow [31] and the Keras [32] package to implement our model. The cross-entropy loss was calculated, and the RMSprop (Root Mean Square Prop) algorithm was used to optimize the model [33]. During training, we used the mini-batch strategy and set the batch size to 128. We used an NVIDIA TESLA V100 graphics card to train the model, and after 500 epochs (an epoch is an iteration over the entire dataset), the model converged to the global optimum. Figure shows the training procedure and validation results with each step iteration. Finally, our LSTM model achieved an overall accuracy score of 0.85 on the pure-mixed pixel set and 0.82 on the pure pixel set. We will discuss the performance thoroughly below. Figure 6. Fine-tuning of the parameters and of the random forest (RF) model, a) the overallaccuracy of the RF trained on pure-mixed pixel set ,(b) the overall accuracy of the RF trained on Pure pixelset. When equals 500 and equals 40, the performances of RF models converge; thus, we selected thiscombination for further experiments.4.2. A-LSTM Training and EvaluationFor the A-LSTM method, we used Python TensorFlow 31] and the Keras 32] package toimplement our model. The cross-entropy loss was calculated, and the RMSprop (Root Mean SquareProp) algorithm was used to optimize the model 33]. During training, we used the mini-batch strategyand set the batch size to 128. We used an NVIDIA TESLA V100 graphics card to train the model,and after 500 epochs (an epoch is an iteration over the entire dataset), the model converged to theglobal optimum. Figure 7shows the training procedure and validation results with each step iteration.Finally, our LSTM model achieved an overall accuracy score of 0.85 on the pure-mixed pixel set and0.82 on the pure pixel set. We will discuss the performance thoroughly below.Remote Sens. 2019, 11, FOR PEER REVIEW 13 of 22 (a) (b) Figure 7. Training logs for the A-LSTM model, (a) model trained on mixed dataset, (b) model trained on pure dataset. 4.3. Identification Metrics The overall accuracy of the RF trained on the pure-mixed pixel set was 0.87 (±0.01), and the overall accuracy of the RF trained on the pure pixel set was 0.85 (±0.01), while the overall accuracies of the A-LSTM trained on these two datasets were 0.85 (±0.01) and 0.82 (±0.01), respectively. The overall accuracy scores were high because the no-wheat class accounts for approximately 85 percent of the dataset. Thus, the accuracy scores were dominated by the majority class. However, the F1 score is the weighted average of the precision and recall, which is better metric for such an uneven dataset. Specifically, the F1 scores of RF and A-LSTM trained on the pure-mixed pixel set were 0.72 and 0.71, while the scores of the two models trained on the pure pixel set were 0.68 and 0.66. More details regarding the performance score are shown in Table 3. In general, the two models behaved better when they were trained on the pure-mixed pixel set. For comparison, when the pure pixel set was utilized, the precision of the two models improved, while the recall worsened. In total, the two models trained with the pure-mixed pixel set were more stable, traded precision for recall and achieved high F1 scores and overall accuracy, which are highly recommended in practical applications. This result occurred because the data distribution of the test dataset was the same as that of the pure-mixed pixel set. This phenomenon might cause severe overfitting problems when the models are trained on only pure-pixel samples. In some classification cases that require large amounts of manually collected training data, whether the selected samples include mixed pixels needs to be reconsidered, and the impact of including these cells needs to be evaluated. The classified wheat map resulting from the RF and A-LSTM models trained with the pure-mixed set is shown in Figure 8a,b, while the reference wheat map is shown in Figure 8c. The numbers of wheat pixels in the three maps were 3296256, 3327509, and 3269754. According to the map, most of the crop areas were correctly predicted in the plain area, while there were extensive differences between the prediction and reference data in the border between wheat areas and no-wheat areas or some isolated wheat areas. Thus, the many mixed cells that might include crops, buildings, and mountains result in irregular spectral reflectance. In addition, although the numbers of wheat pixels in the prediction map and reference map were similar, there was slight visual difference. In Figure 9a,b, wheat pixels are more likely to be clustered together, while there are many isolated wheat areas in the reference map. Generally, wheat areas among continuous no-wheat areas or no-wheat areas among continuous wheat areas were very likely to be misclassified. Figure 7. Training logs for the A-LSTM model, a) model trained on mixed dataset, b) model trainedon pure dataset.4.3. Identiﬁcation MetricsThe overall accuracy of the RF trained on the pure-mixed pixel set was 0.87 ±0.01), and the overallaccuracy of the RF trained on the pure pixel set was 0.85 ±0.01), while the overall accuracies of theA-LSTM trained on these two datasets were 0.85 ±0.01) and 0.82 ±0.01), respectively. The overallRemote Sens. 2019,11, 1665 13 of 21accuracy scores were high because the no-wheat class accounts for approximately 85 percent of thedataset. Thus, the accuracy scores were dominated by the majority class. However, the F1 score isthe weighted average of the precision and recall, which is better metric for such an uneven dataset.Speciﬁcally, the F1 scores of RF and A-LSTM trained on the pure-mixed pixel set were 0.72 and 0.71,while the scores of the two models trained on the pure pixel set were 0.68 and 0.66. More detailsregarding the performance score are shown in Table 4.Table 4. Precision, recall, overall accuracy and F1 scores for the two models trained on di ↵erent datasets.Pure Pixel Set Pure-Mixed Pixel SetRF A-LSTM RF A-LSTMPrecision 0.75 0.74 0.72 0.71Recall 0.62 0.60 0.71 0.70Overall Accuracy 0.85 ±0.01) 0.82 ±0.01) 0.87 ±0.01) 0.85 ±0.01)F1 score 0.68 ±0.01) 0.66 ±0.01) 0.72 ±0.01) 0.71 ±0.01)In general, the two models behaved better when they were trained on the pure-mixed pixel set. Forcomparison, when the pure pixel set was utilized, the precision of the two models improved, while therecall worsened. In total, the two models trained with the pure-mixed pixel set were more stable, tradedprecision for recall and achieved high F1 scores and overall accuracy, which are highly recommendedin practical applications. This result occurred because the data distribution of the test dataset was thesame as that of the pure-mixed pixel set. This phenomenon might cause severe overﬁtting problemswhen the models are trained on only pure-pixel samples. In some classiﬁcation cases that require largeamounts of manually collected training data, whether the selected samples include mixed pixels needsto be reconsidered, and the impact of including these cells needs to be evaluated.The classiﬁed wheat map resulting from the RF and A-LSTM models trained with the pure-mixedset is shown in Figure 8a,b, while the reference wheat map is shown in Figure 8c. The numbers ofwheat pixels in the three maps were 3296256, 3327509, and 3269754. According to the map, mostof the crop areas were correctly predicted in the plain area, while there were extensive di ↵erencesbetween the prediction and reference data in the border between wheat areas and no-wheat areasor some isolated wheat areas. Thus, the many mixed cells that might include crops, buildings, andmountains result in irregular spectral reﬂectance. In addition, although the numbers of wheat pixels inthe prediction map and reference map were similar, there was slight visual di ↵erence. In Figure 9a,b,wheat pixels are more likely to be clustered together, while there are many isolated wheat areas in thereference map. Generally, wheat areas among continuous no-wheat areas or no-wheat areas amongcontinuous wheat areas were very likely to be misclassiﬁed.Remote Sens. 2019, 11, FOR PEER REVIEW 14 of 22 Table 3. Precision, recall, overall accuracy and F1 scores for the two models trained on different datasets. 澔澔Pure Pixel Set澔Pure-Mixed Pixel Set澔RF澔A-LSTM澔RF澔A-LSTM澔Precision澔0.75 0.74 0.72 0.71 Recall澔0.62 0.60 0.71 0.70 Overall Accuracy 0.85 (+0.01) 0.82 (+0.01) 0.87 (+0.01) 0.85 (+0.01) F1 score澔0.68 (+0.01) 0.66 (+0.01) 0.72 (+0.01) 0.71 (+0.01) (a) (b) (c) Figure 8. (a) The prediction map informed by the RF model, (b) the prediction map informed by the A-LSTM model, (c) ground truth winter wheat distribution map. 4.4. Feature Importance The relative depth of feature used as decision node in tree can be used to assess the relative importance of that feature with respect to the predictability of the target variable. Features used at the top of the tree contribute to the final prediction of large fraction of the input samples. The expected fraction of samples that these features contribute to can thus be used as an estimate of the relative importance of the features. In the Scikit-learn package, the fraction of samples feature contributes to is combined with the decrease in impurity from splitting them to create normalized estimate of the predictive power of that feature. By averaging the estimates of predictive ability over several randomized trees, one can reduce the variance in such an estimate and use it for feature selection. This process is known as the mean decrease in impurity [30]. In this paper, we visualized the feature importance of 132 variables in RF, which is shown in Figure 9a. The importance scores were the mean scores of all individual trees. The top 10 variables are shown in Table 4; these variables are 2018081_EVI, 2018081_NDVI, 2018097_EVI, 2018081_NIR, 2018097_NIR, 2018161_NDVI, 2018097_NDVI, 2018113_EVI, 2018065_EVI and 2018245_NDVI, where the first part of each variable represents the day of the year, and the last part represents the band. Furthermore, we summed six importance scores per timestep and 22 importance scores per band, which are shown in Figure 9b,c. Generally, variables in March or April 2018 were more important than others. Moreover, EVI and NDVI had higher importance scores than raw reflectance bands. The differences of feature importance among variables could be explained by several points. According to the typical growing cycles of winter wheat, wheat enters the green-returning stage in late February or early March, while most other vegetation in the Huanghuaihai Region is deciduous forest, which is gray and still not germinated; this phenomenon leads to higher importance of data captured in March or April, such as 2018081_EVI, 2018081_NDVI, 2018097_EVI. For the comparison between vegetation index bands and spectral reflectance bands, vegetation indices are more sensitive over dense vegetation conditions and have high importance scores. Figure 8. (a) The prediction map informed by the RF model, b) the prediction map informed by theA-LSTM model, c) ground truth winter wheat distribution map.Remote Sens. 2019,11, 1665 14 of 21Remote Sens. 2019, 11, FOR PEER REVIEW 15 of 22 (a) (b) (c) Figure 9. (a) Importance scores of 132 variables with the hierarchy indexed by timestep and band, (b) Accumulated importance score per timestep, (c) Accumulated importance score per band. Table 4. Top 10 variables in order of decreasing importance in the RF model. The first column lists the index in the 132-variable sequence. The second column represents the feature name, which consists of the day of the year and the band name. The third column represents the importance score. Index Band/Feature name Importance 79 2018081_EVI 0.029 81 2018081_NDVI 0.024 85 2018097_EVI 0.023 82 2018081_NIR 0.023 88 2018097_NIR 0.022 111 2018161_NDVI 0.020 87 2018097_NDVI 0.020 91 2018113_EVI 0.018 73 2018065_EVI 0.015 105 2018245_NDVI 0.014 For the A-LSTM model, the context vector of output class determines which encoded steps to weigh highly and is calculated as the weighted sum of these encoded steps. As shown in Section 3.2, the weight Ƚ୨୧ a b c n i e e t e r b b l t t a t e j-th class is aligned to the i-th step of the encoded sequence. Since different samples have different weight distributions and the weight distribution of single sample is usually noisy or not sufficiently representative of the alignment pattern, we simply used the mean of the weight i t i u i n f h w o e e t a a e f r visualization. As shown in Figure 10, the two curves represent the weight distribution along the encoded sequence for the two classes, and the integral of each curve is equal to 1. According to the figure, the wheat class is highly l g e w t t e 6 h t p f h e c d d e u n e w i h a acquired in April 2018 (the 113th day of the year 2018). Thus, there is very high probability that the wheat class is aligned with the 16th step of the encoded sequence, which contains all the information of the input sequence, with strong focus on the parts surrounding the 16th step of the input sequence. Compared to the variable importance scores of RF, they both show that sequence data acquired in April are more important for the winter wheat identification problem using time-series data. Figure 9. (a) Importance scores of 132 variables with the hierarchy indexed by timestep and band,(b) Accumulated importance score per timestep, c) Accumulated importance score per band.4.4. Feature ImportanceThe relative depth of feature used as decision node in tree can be used to assess the relativeimportance of that feature with respect to the predictability of the target variable. Features used at thetop of the tree contribute to the ﬁnal prediction of large fraction of the input samples. The expectedfraction of samples that these features contribute to can thus be used as an estimate of the relativeimportance of the features. In the Scikit-learn package, the fraction of samples feature contributesto is combined with the decrease in impurity from splitting them to create normalized estimate ofthe predictive power of that feature. By averaging the estimates of predictive ability over severalrandomized trees, one can reduce the variance in such an estimate and use it for feature selection. Thisprocess is known as the mean decrease in impurity 30].In this paper, we visualized the feature importance of 132 variables in RF, which is shown inFigure 9a. The importance scores were the mean scores of all individual trees. The top 10 variablesare shown in Table 5; these variables are 2018081_EVI, 2018081_NDVI, 2018097_EVI, 2018081_NIR,2018097_NIR, 2018161_NDVI, 2018097_NDVI, 2018113_EVI, 2018065_EVI and 2018245_NDVI, wherethe ﬁrst part of each variable represents the day of the year, and the last part represents the band.Furthermore, we summed six importance scores per timestep and 22 importance scores per band,which are shown in Figure 9b,c. Generally, variables in March or April 2018 were more important thanothers. Moreover, EVI and NDVI had higher importance scores than raw reﬂectance bands.Table 5. Top 10 variables in order of decreasing importance in the RF model. The ﬁrst column lists theindex in the 132-variable sequence. The second column represents the feature name, which consists ofthe day of the year and the band name. The third column represents the importance score.Index Band /Feature name Importance79 2018081_EVI 0.02981 2018081_NDVI 0.02485 2018097_EVI 0.02382 2018081_NIR 0.02388 2018097_NIR 0.022111 2018161_NDVI 0.02087 2018097_NDVI 0.02091 2018113_EVI 0.01873 2018065_EVI 0.015105 2018245_NDVI 0.014The di ↵erences of feature importance among variables could be explained by several points.According to the typical growing cycles of winter wheat, wheat enters the green-returning stage inlate February or early March, while most other vegetation in the Huanghuaihai Region is deciduousforest, which is gray and still not germinated; this phenomenon leads to higher importance of datacaptured in March or April, such as 2018081_EVI, 2018081_NDVI, 2018097_EVI. For the comparisonRemote Sens. 2019,11, 1665 15 of 21between vegetation index bands and spectral reﬂectance bands, vegetation indices are more sensitiveover dense vegetation conditions and have high importance scores.For the A-LSTM model, the context vector cjof output class jdetermines which encoded steps toweigh highly and is calculated as the weighted sum of these encoded steps. As shown in Section 3.2, theweight ↵jican be considered the probability that the j-thclass is aligned to the i-thstep of the encodedsequence. Since di ↵erent samples have di ↵erent weight distributions and the weight distribution ofa single sample is usually noisy or not su ciently representative of the alignment pattern, we simplyused the mean of the weight distribution of the whole test dataset for visualization. As shown inFigure 10, the two curves represent the weight distribution along the encoded sequence for the twoclasses, and the integral of each curve is equal to 1. According to the ﬁgure, the wheat class is highlyaligned with the 16th step of the encoded sequence, which was acquired in April 2018 (the 113th day ofthe year 2018). Thus, there is very high probability that the wheat class is aligned with the 16th stepof the encoded sequence, which contains all the information of the input sequence, with strong focuson the parts surrounding the 16th step of the input sequence. Compared to the variable importancescores of RF, they both show that sequence data acquired in April are more important for the winterwheat identiﬁcation problem using time-series data.Remote Sens. 2019, 11, FOR PEER REVIEW 16 of 22 Figure 10. The mean probability distribution that the target class is aligned with the encoded sequence. 4.5. Generalizability in Different Areas To evaluate the generalizability in different areas, we divided the entire dataset into eight parts from north to south, the details of which are presented in Section 2.5. The evaluation results are reported in Table 5. None of the precision, recall, and accuracy metrics exhibited significant patterns except for the F1 score. Specifically, the F1 score of the RF model decreased as the evaluation dataset moved away from the training set. Since the F1 score represents the harmonic mean of the recall and precision, it is appropriate to use it to represent the generalizability of the model. According to the experiments, the model achieved the best performance when the testing set and training set were in the same part, because they had the same data distribution. When the trained model was required to perform prediction in other areas, the performance worsened. The main reason for this difference is that the winter wheat growing season in the Huanghuaihai Region changes slightly from north to south. We divided the growing season into six growth stages: sowing, overwintering, green-returning, jointing, flowering, and maturation. The maps of the starting times of the six growth stages are shown in Figure 11. Each raster pixel represents the day of the year when winter wheat entered the corresponding stage. The first two maps show the growing times in 2017, and the other maps show the growing times in 2018. Contour lines are also shown on the maps. The six raster maps were interpolated from data recorded from 82 agricultural stations distributed in the Huanghuaihai Region. The time interval of the same growing stage from south to north was 30 or 40 days at most. Therefore, to obtain the best model performance, the growing season in the predicting area must be as close as possible to that of the training area, and new model should be retrained in the prediction area for practical applications if necessary. Table 5. Generalization performance scores of the RF model. Metrics Testing Generalization evaluation Fold Fold Fold Fold Fold Precision 0.752 0.724 0.660 0.746 0.747 0.602 Recall 0.682 0.664 0.682 0.603 0.410 0.073 Total accuracy 0.906 0.845 0.759 0.786 0.913 0.972 F1 score 0.715 0.693 0.671 0.667 0.529 0.130 Figure 10. The mean probability distribution that the target class is aligned with the encoded sequence.4.5. Generalizability in Di ↵erent AreasTo evaluate the generalizability in di ↵erent areas, we divided the entire dataset into eight partsfrom north to south, the details of which are presented in Section 2.5. The evaluation results arereported in Table 6. None of the precision, recall, and accuracy metrics exhibited signiﬁcant patternsexcept for the F1 score. Speciﬁcally, the F1 score of the RF model decreased as the evaluation datasetmoved away from the training set. Since the F1 score represents the harmonic mean of the recall andprecision, it is appropriate to use it to represent the generalizability of the model. According to theexperiments, the model achieved the best performance when the testing set and training set were inthe same part, because they had the same data distribution. When the trained model was requiredto perform prediction in other areas, the performance worsened. The main reason for this di ↵erenceis that the winter wheat growing season in the Huanghuaihai Region changes slightly from north tosouth. We divided the growing season into six growth stages: sowing, overwintering, green-returning,jointing, ﬂowering, and maturation. The maps of the starting times of the six growth stages areshown in Figure 11. Each raster pixel represents the day of the year when winter wheat entered thecorresponding stage. The ﬁrst two maps show the growing times in 2017, and the other maps showthe growing times in 2018. Contour lines are also shown on the maps. The six raster maps wereinterpolated from data recorded from 82 agricultural stations distributed in the Huanghuaihai Region.The time interval of the same growing stage from south to north was 30 or 40 days at most. Therefore,to obtain the best model performance, the growing season in the predicting area must be as close asRemote Sens. 2019,11, 1665 16 of 21possible to that of the training area, and new model should be retrained in the prediction area forpractical applications if necessary.Remote Sens. 2019, 11, FOR PEER REVIEW 17 of 22 a ( ) c ( ) e ( ) Figure 11. The winter wheat growing season in the Huanghuaihai Region, (a) sowing; (b) overwintering; (c) green-returning; (d) jointing; (e) flowering; (f) maturation. The cell values of the raster map represent the day of the year on which winter wheat enters the growing stage. Contour lines are shown on the map. The first two maps show the growing times in 2017, and the others show the growing times in 2018. 4.6. Inference on Historical Data To determine the historical winter wheat distribution, we also applied the two models to historical MODIS data from the Huanghuaihai Region. Specifically, we collected time-series data for the 2016–2017 growing season, which were processed by the same data preprocessing pipeline. Using the two models trained on Pure-mixed pixel set, which is described in Section 2.4, we obtained two historical winter wheat distribution maps of the Huanghuaihai Region, which are shown in Figure 12a,b. To evaluate the accuracy of the two prediction maps, we randomly selected 1000 cells from the Huanghuaihai Region and interpreted them visually via the Planet Explorer API, which was introduced in Section 2.2.2. The distribution of the 1000 cells is shown in Figure 12c. Similarly, we used the annotation strategy described in Section 2.2.2. Then, two confusion matrices with the predicted and reference samples were generated. They are reported in Tables and 7, respectively. For the winter wheat class, the recall, precision and F1 score predicted by the RF model were 0.720, 0.739 and 0.729, while these values for the A-LSTM model were 0.703, 0.741 and 0.721, respectively. Generally, the two models achieved comparative performance in the 2016–2017 growing season, which proved our concept. Figure 11. The winter wheat growing season in the Huanghuaihai Region, a) sowing; b) overwintering;(c) green-returning; d) jointing; e) ﬂowering; f) maturation. The cell values of the raster map representthe day of the year on which winter wheat enters the growing stage. Contour lines are shown on themap. The ﬁrst two maps show the growing times in 2017, and the others show the growing timesin 2018.Table 6. Generalization performance scores of the RF model.Metrics TestingGeneralization EvaluationFold Fold Fold Fold Fold 8Precision 0.752 0.724 0.660 0.746 0.747 0.602Recall 0.682 0.664 0.682 0.603 0.410 0.073Total accuracy 0.906 0.845 0.759 0.786 0.913 0.972F1 score 0.715 0.693 0.671 0.667 0.529 0.1304.6. Inference on Historical DataTo determine the historical winter wheat distribution, we also applied the two models to historicalMODIS data from the Huanghuaihai Region. Speciﬁcally, we collected time-series data for the 2016–2017growing season, which were processed by the same data preprocessing pipeline. Using the two modelstrained on Pure-mixed pixel set which is described in Section 2.4, we obtained two historical winterwheat distribution maps of the Huanghuaihai Region, which are shown in Figure 12a,b. To evaluate theaccuracy of the two prediction maps, we randomly selected 1000 cells from the Huanghuaihai Regionand interpreted them visually via the Planet Explorer API, which was introduced in Section 2.2.2.Remote Sens. 2019,11, 1665 17 of 21The distribution of the 1000 cells is shown in Figure 12c. Similarly, we used the annotation strategydescribed in Section 2.2.2. Then, two confusion matrices with the predicted and reference sampleswere generated. They are reported in Tables 7and8, respectively. For the winter wheat class, therecall, precision and F1 score predicted by the RF model were 0.720, 0.739 and 0.729, while these valuesfor the A-LSTM model were 0.703, 0.741 and 0.721, respectively. Generally, the two models achievedcomparative performance in the 2016–2017 growing season, which proved our concept.Remote Sens. 2019, 11, FOR PEER REVIEW 18 of 22 (a) (b) (c) Figure 12. Historical winter wheat distribution map (2016–2017 growing season) informed by (a) RF and (b) A-LSTM, (c) the distribution of manually collected v l a i n a p e f o t e l n t Explorer API. Table 6. Confusion matrix of the prediction map informed by RF. Reference Prediction Winter wheat No-wheat Recall Winter wheat 85 33 0.720 No-wheat 30 852 0.966 Precision 0.739 0.963 Table 7. Confusion matrix of the prediction map informed by A-LSTM. Reference Prediction Winter wheat No-wheat Recall Winter wheat 83 35 0.703 No-wheat 29 853 0.967 Precision 0.741 0.961 5. Discussion Our two models achieved F1 scores of 0.72 and 0.71 for identifying the winter wheat distribution in the Huanghuaihai Region. Previous works such as Senf et al. [5], Tuanmu et al. [7], Rodriguez-Galiano et al. [17], Charlotte Pelletier et al. [18], and Marc Rußwurm et al. [20] regarding land cover classification or crop identification usually focused on only small area, such as county or city, which resulted in classification map that was more detailed than ours. However, our trained models could also easily recognize the approximate winter wheat distribution, but in large-scale area, and these models could be especially used in some close areas or historical cropland area identification. All the procedures are very simple to implement, and the results can be rapidly obtained. Although the RF and A-LSTM methods achieved comparable performance according to our experiments, the computation costs are different. As the score tables above show, the overall accuracy and F1 score of RF is slightly higher than that of A-LSTM, but the computation time required to train an RF model is much greater than that required to train an A-LSTM model. As there are many samples throughout the study area, RF needs to traverse almost all samples and find the optimal split orders and split points to build decision tree each time. In addition, it required almost hours to train complete RF model on our 24-core working station with parallel computation. For A-LSTM, high-performance graphics card could be used to accelerate the computation, and an early stop strategy [34] (automatically stop training when the model converges) could be employed in practical Figure 12. Historical winter wheat distribution map (2016–2017 growing season) informed by a) RF and(b) A-LSTM, c) the distribution of manually collected evaluation samples from the Planet Explorer API.Table 7. Confusion matrix of the prediction map informed by RF.ReferencePredictionWinter Wheat No-Wheat RecallWinter Wheat 85 33 0.720No-Wheat 30 852 0.966Precision 0.739 0.963Table 8. Confusion matrix of the prediction map informed by A-LSTM.ReferencePredictionWinter Wheat No-Wheat RecallWinter wheat 83 35 0.703No-wheat 29 853 0.967Precision 0.741 0.9615. DiscussionOur two models achieved F1 scores of 0.72 and 0.71 for identifying the winter wheat distribution inthe Huanghuaihai Region. Previous works such as Senf et al. 5], Tuanmu et al. 7], Rodriguez-Galianoet al. 17], Charlotte Pelletier et al. 18], and Marc Rußwurm et al. 20] regarding land cover classiﬁcationor crop identiﬁcation usually focused on only small area, such as county or city, which resulted ina classiﬁcation map that was more detailed than ours. However, our trained models could also easilyrecognize the approximate winter wheat distribution, but in large-scale area, and these models couldbe especially used in some close areas or historical cropland area identiﬁcation. All the procedures arevery simple to implement, and the results can be rapidly obtained.Although the RF and A-LSTM methods achieved comparable performance according to ourexperiments, the computation costs are di ↵erent. As the score tables above show, the overall accuracyand F1 score of RF is slightly higher than that of A-LSTM, but the computation time required toRemote Sens. 2019,11, 1665 18 of 21train an RF model is much greater than that required to train an A-LSTM model. As there are manysamples throughout the study area, RF needs to traverse almost all samples and ﬁnd the optimalsplit orders and split points to build decision tree each time. In addition, it required almost h totrain complete RF model on our 24-core working station with parallel computation. For A-LSTM,a high-performance graphics card could be used to accelerate the computation, and an early stopstrategy 34] (automatically stop training when the model converges) could be employed in practicalapplications. In this manner, approximately 50 min are required to train an A-LSTM model with TeslaV100 GPU card.Furthermore, the overall accuracies of our two models were 0.87 and 0.85. However, the precisionand recall were approximately 0.70, which is not su ciently precise for the detailed mapping ofwinter wheat. This result is mainly due to three phenomena. (1) the cell size of MODIS data is 250 m,and cell might contain multiple land cover types, thus making the reﬂectance spectra unstableand unpredictable. (2) Our ground truth map, which was provided by the Chinese Academy ofAgricultural Sciences, was assumed to be totally accurate in each cell. Since we did not receive anyinstructions regarding how to complete the map or information on the data accuracy, we reassessedthe data via manually collected ﬁeld data, as described in Section 2.2.2. The results indicated thatthe overall accuracy of the ground truth map was 0.95, the precision of winter wheat was 0.89, andthe recall was 0.83, which might result in noise in the training sample labels. (3) Although manyworks have demonstrated the ↵ectiveness of RF and DNNs, they still have limitations in learning thecharacteristics of such large and complex area. Using more complex RF or A-LSTM (a larger numberof trees with RF or deeper network with A-LSTM) could increase the inference ability. However,this usually causes severe overﬁtting problems, and experiments have shown that the validation scoreremains almost unchanged when the models reach saturation.In this paper, we also visualized the feature importance of RF. Generally, the features derivedfrom March or April had high importance scores. In early March, the ﬁrst joint emerges above the soilline. This joint provides visual evidence that the plants have initiated their reproduction 35]. Then,winter wheat enters fast-growing period until maturation. Thus, features in this period tend to besigniﬁcant. For the feature importance of di ↵erent bands, vegetation indices such as NDVI or EVIrepresent the reﬂectance di ↵erences between vegetation and soil in the visible and NIR bands. Greenvegetation usually exhibits large spectral di ↵erence between the red and NIR bands, thus making thevegetation index more important than single band. In our study, features were derived from the sixbands provided by the MOD13Q1, Collection product. Future work could add additional bands inthe models, which might provide better results.When the trained models are used to make predictions in other areas, close areas usually havereliable results. The main reason behind this result is that the winter wheat growing season varies byarea. Speciﬁcally, in the Huanghuaihai Region, winter wheat crops at the same latitudes likely havesimilar growing seasons. In addition, the experiments above support our point of view. Practically,there must be other reasons that result in the poor performance, such as the terrain, elevation, climate,crop species or di ↵erent land cover compositions of the negative samples. Thus, the MODIS datadistribution in the prediction area varies compared to that in the training areas. Our future workwill focus on revealing the detailed mechanisms underlying this di ↵erence. Fortunately, when weapplied our model to historical MODIS data, the performance was stable, as described in Section 4.6.However, exceptions sometimes exist that result in noise in the prediction, such as improved winterwheat species, climate changes, and land cover changes. Regrettably, we did not conduct additionalexperiments over more past years because of the extensive labor required to collect validation data.6. ConclusionsIn this paper, we developed two models for large-scale winter wheat identiﬁcation in theHuanghuaihai Region. To the best of our knowledge, this study was the ﬁrst to use raw digitalnumbers derived from time-series MODIS images to implement classiﬁcation pipelines and makeRemote Sens. 2019,11, 1665 19 of 21predictions over large-scale land area. According to our experiments, we can draw the followinggeneral conclusions. (1) Both the RF and A-LSTM models were cient for identifying winter wheatareas, with F1 scores of 0.72 and 0.71, respectively. (2) The comparison of the two models indicates thatRF achieved slightly better score than A-LSTM, while A-LSTM is much faster with GPU acceleration.(3) For time-series winter wheat identiﬁcation, the data acquired in March or April are more importantand contribute more than the data acquired at other times. Vegetation indices such as EVI and NDVIare more helpful than single reﬂectance bands. (4) Predicting in local or nearby areas is more likelyto yield reliable results. (5) The models are also capable of ciently identifying historical winterwheat areas.Our models were applied to only winter wheat identiﬁcation due to the limitations of the cropdistribution data, but they could potentially solve multiclass problems. Further research regardingmultiple crop types or other land cover types over large regions could be more meaningful anduseful. Moreover, due to the scarcity and acquisition di culties of high-spatiotemporal-resolutionimages, the cell size of each training sample was 250 m, which is too large to avoid the mixed-pixelproblem. We believe that using time-series images with ﬁner scales could help improve the accuracyand generalizability of our models. Obviously, it is easy to determine how predictions are determinedin RF models, but this information is di cult to determine in the A-LSTM model. Future research willlikely devote more attention to the inference mechanisms of DNNs.Author Contributions: T.H. performed the research, analyzed the data and wrote the manuscript; C.X. providedideas and reviewed the experiments and the manuscript. S.G. acquired the data. G.L. reviewed the research andprovided funding support.Funding: This research was ﬁnancially supported by the National Key Research and Development Program ofChina (No. 2017YFD0300403) and the Laboratory Independent Innovation Project of State Key Laboratory ofResources and Environment Information System.Acknowledgments: We thank the Chinese Academy of Agricultural Sciences for providing the winter wheatdistribution map and growing season data for 2017–2018. We thank the NASA Goddard Space Flight Center forproviding the MODIS data.Conﬂicts of Interest: The authors declare no conﬂicts of interest.References1. Becker-Reshef, I.; Justice, C.; Sullivan, M.; Vermote, E.; Tucker, C.; Anyamba, A.; Small, J.; Pak, E.; Masuoka, E.;Schmaltz, J.; et al. Monitoring Global Croplands with Coarse Resolution Earth Observations: The GlobalAgriculture Monitoring (GLAM) Project. Remote Sens. 2010,2, 1589–1609. CrossRef ]2. Eerens, H.; Haesen, D.; Rembold, F.; Urbano, F.; Tote, C.; Bydekerke, L. Image time series processing foragriculture monitoring. Environ. Model. Softw. 2014,53, 154–162. CrossRef ]3. Atzberger, C. Advances in Remote Sensing of Agriculture: Context Description, Existing OperationalMonitoring Systems and Major Information Needs. Remote Sens. 2013,5, 949–981. CrossRef ]4. Beeri, O.; Peled, A. Geographical model for precise agriculture monitoring with real-time remote sensing.ISPRS J. Photogramm. Remote Sens. 2009,64, 47–54. CrossRef ]5. Senf, C.; Pﬂugmacher, D.; Van Der Linden, S.; Hostert, P. Mapping rubber plantations and natural forestsin Xishuangbanna (Southwest China) using multi-spectral phenological metrics from MODIS time series.Remote Sens. 2013,5, 2795–2812. CrossRef ]6. Pittman, K.; Hansen, M.C.; Becker-Reshef, I.; Potapov, P.V.; Justice, C.O. Estimating Global Cropland Extentwith Multi-year MODIS Data. Remote Sens. 2010,2, 1844–1863. CrossRef ]7. Tuanmu, M.N.; Viña, A.; Bearer, S.; Xu, W.; Ouyang, Z.; Zhang, H.; Liu, J. Mapping understory vegetationusing phenological characteristics derived from remotely sensed data. Remote Sens. Environ. 2010,114,1833–1844. CrossRef ]8. Sakamoto, T.; Yokozawa, M.; Toritani, H.; Shibayama, M.; Ishitsuka, N.; Ohno, H. crop phenology detectionmethod using time-series MODIS data. Remote Sens. Environ. 2005,96, 366–374. CrossRef ]9. Zhang, X.; Friedl, M.A.; Schaaf, C.B.; Strahler, A.H.; Hodges, J.C.; Gao, F.; Reed, B.C.; Huete, A. Monitoringvegetation phenology using MODIS. Remote Sens. Environ. 2003,84, 471–475. CrossRef ]Remote Sens. 2019,11, 1665 20 of 2110. Funk, C.; Budde, M.E. Phenologically-tuned MODIS NDVI-based production anomaly estimates forZimbabwe. Remote Sens. Environ. 2009,113, 115–125. CrossRef ]11. Jönsson, P.; Eklundh, L. Seasonality extraction by function ﬁtting to time-series of satellite sensor data.Geosci. Remote Sens. IEEE Trans. 2002,40, 1824–1832. CrossRef ]12. Jönsson, P.; Eklundh, L. TIMESAT—A program for analyzing time-series of satellite sensor data.Comput. Geosci. 2004,30, 833–845. CrossRef ]13. Atzberger, C.; Eilers, P.H.C. time series for monitoring vegetation activity and phenology at 10-dailytimesteps covering large parts of South America. Int. J. Digit. Earth 2011,4, 365–386. CrossRef ]14. Chen, J.; Jönsson, P.; Tamura, M.; Gu, Z.; Matsushita, B.; Eklundh, L. simple method for reconstructinga high-quality NDVI time-series data set based on the Savitzky-Golay ﬁlter. Remote Sens. Environ. 2004,91,332–344. CrossRef ]15. Shao, Y.; Lunetta, R.S.; Wheeler, B.; Iiames, J.S.; Campbell, J.B. An evaluation of time-series smoothingalgorithms for land-cover classiﬁcations using MODIS-NDVI multi-temporal data. Remote Sens. Environ.2016,174, 258–265. CrossRef ]16. Zhong, L.; Hu, L.; Zhou, H. Deep learning based multi-temporal crop classiﬁcation. Remote Sens. Environ.2019,221, 430–443. CrossRef ]17. Rodriguez-Galiano, V.F.; Ghimire, B.; Rogan, J.; Chica-Olmo, M.; Rigol-Sanchez, J.P. An assessment of thee↵ectiveness of random forest classiﬁer for land-cover classiﬁcation. ISPRS J. Photogramm. Remote Sens.2012,67, 93–104. CrossRef ]18. Pelletier, C.; Valero, S.; Inglada, J.; Champion, N.; Dedieu, G. Assessing the robustness of Random Forests tomap land cover with high resolution satellite image time series over large areas. Remote Sens. Environ. 2016,187, 156–168. CrossRef ]19. Breiman, L. Random forests. Mach. Learn. 2001,45, 5–32. CrossRef ]20. Rußwurm, M.; Korner, M. Temporal vegetation modelling using long short-term memory networks for cropidentiﬁcation from medium-resolution multi-spectral satellite images. In Proceedings of the IEEE Conferenceon Computer Vision and Pattern Recognition Workshops, Honolulu, HI, USA, 21–26 July 2017; pp. 11–19.21. Rußwurm, M.; Körner, M. Multi-temporal land cover classiﬁcation with sequential recurrent encoders.ISPRS Int. J. Geo-Inf. 2018,7, 129. CrossRef ]22. Krizhevsky, A.; Sutskever, I.; Hinton, G.E. Imagenet classiﬁcation with deep convolutional neural networks.In Proceedings of the 25th International Conference on Neural Information Processing Systems (NIPS’12),Lake Tahoe, NV, USA, 3–6 December 2012; pp. 1097–1105.23. Szegedy, C.; Liu, W.; Jia, Y.; Sermanet, P.; Reed, S.; Anguelov, D.; Erhan, D.; Vanhoucke, V.; Rabinovich, A.Going deeper with convolutions. In Proceedings of the 2015 IEEE conference on computer vision and patternrecognition, Boston, MA, USA, 7–12 June 2015; pp. 1–9.24. He, K.; Zhang, X.; Ren, S.; Sun, J. Deep residual learning for image recognition. In Proceedings of the2016 IEEE Conference on Computer Vision and Pattern Recognition, Las Vegas, NV, USA, 27–30 June 2016;pp. 770–778.25. Bahdanau, D.; Cho, K.; Bengio, Y. Neural machine translation by jointly learning to align and translate.arXiv 2014, arXiv:1409.0473.26. Long, H.; Yi, Q. Land Use Transitions and Land Management: Mutual Feedback Perspective. Land UsePolicy 2018,74, 111–120. CrossRef ]27. Zhang, J.; Sun, J.; Duan, A.; Wang, J.; Shen, X.; Liu, X. ↵ects of di ↵erent planting patterns on water use andyield performance of winter wheat in the Huang-Huai-Hai plain of China. Agric. Water Manag. 2007,92,41–47. CrossRef ]28. Huete, A.R.; Didan, K.; Miura, T.; Rodriguez, E.P.; Gao, X.; Ferreira, L.G. Overview of the radiometricand biophysical performance of the MODIS vegetation indices. Remote Sens. Environ. 2002,83, 195–213.[CrossRef ]29. Powers, D.M.W. Evaluation: From Precision, Recall and F-Measure to ROC, Informedness, Markedness &Correlation. J. Mach. Learn. Technol. 2011,2, 37–63.30. Scikit-Learn. Available online: https: //scikit-learn.org /(accessed on March 2019).31. Tensorﬂow. Available online: https: //www.tensorﬂow.org /(accessed on March 2019).32. Keras. Available online: https: //keras.io /(accessed on March 2019).Remote Sens. 2019,11, 1665 21 of 2133. Sebastian, R. An Overview of Gradient Descent Optimization Algorithms. Available online: https: //arxiv.org/pdf/1609.04747.pdf (accessed on January 2019).34. Yao, Y.; Rosasco, L.; Caponnetto, A. On Early Stopping in Gradient Descent Learning. Constr. Approx. 2007,26, 289–315. CrossRef ]35. Li, Z.-C. Hyperspectral Features of Winter Wheat after Frost Stress at Jointing Stage: Hyperspectral Featuresof Winter Wheat after Frost Stress at Jointing Stage. Acta Agron. Sin. 2008,34, 831–837. CrossRef ]©2019 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open accessarticle distributed under the terms and conditions of the Creative Commons Attribution(CC BY) license http: //creativecommons.org /licenses /by/4.0/).