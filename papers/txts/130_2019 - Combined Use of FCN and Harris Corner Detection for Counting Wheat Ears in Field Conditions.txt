Received November 25, 2019, accepted December 3, 2019, date of publication December 10, 2019,date of current version December 23, 2019.Digital Object Identifier 10.1 109/ACCESS.2019.2958831Combined Use of FCN and Harris CornerDetection for Counting Wheat Ears in FieldConditionsDAOYONG WANG1,2, YUANYUAN FU1, GUIJUN YANG1, XIAODONG YANG1,DONG LIANG2, CHENGQUAN ZHOU3, NING ZHANG1, HONGYA WU4,AND DONGYAN ZHANG21Key Laboratory of Quantitative Remote Sensing in Agriculture of Ministry of Agriculture, Beijing Research Center for Information Technology in Agriculture,Beijing Academy of Agriculture and Forestry Sciences, Beijing 100097, China2National Engineering Research Center for Agro-Ecological Big Data Analysis and Application, Anhui University, Hefei 230601, China3Institute of Agricultural Equipment, Zhejiang Academy of Agricultural Sciences (ZAAS), Hangzhou 310021, China4Institute of Agricultural Sciences of Lixiahe District, Yangzhou 225100, ChinaCorresponding authors: Xiaodong Yang (yangxd7@hotmail.com) and Dongyan Zhang (zhangdy@ahu.edu.cn)This work was supported in part by the Natural Science Foundation of China under Grant 41771469, Grant 41801225, and Grant41771463, and in part by the Project of the Beijing Postdoctoral Research Foundation under Grant 2018-ZZ-066.ABSTRACT Accurate counting of wheat ears in ﬁeld conditions is vital to predict yield and for cropbreeding. To quickly and accurately obtain the number of wheat ears in ﬁeld, we propose herein methodto count wheat ears based on fully convolutional network (FCN) and Harris corner detection. The technicalprocedure consists essentially of 1) constructing dataset of wheat-ear images from acquired red-green-blue (RGB) images; 2) training FCN as the wheat-ear segmentation model by using the constructedimage dataset; 3) preparing testing images and inputting them into the segmentation model to get theinitial segmentation results; 4) binarizing the initial segmentation by using the Otsu algorithm (to facilitatesubsequent processing); and 5) applying Harris corner detection after extracting the wheat-ear skeleton toobtain the number of wheat ears in the images. The segmentation results show that the proposed FCN-based segmentation model segments wheat ears with an average accuracy of 0.984 and at low computationalcost. An average of only 0.033 is required to segment 256 ⇥256-pixel wheat-ear image. Moreover, thesegmentation result is improved by nearly 10% compared with the previous segmentation methods underconditions of wheat-ear occlusion, leaf occlusion, uneven illumination, and soil disturbance. Subsequently,the proposed counting method achieves good results, with an average accuracy of 0.974, coefﬁcient ofdetermination (R2) of 0.983, and root mean square error (RMSE) of 14.043. These metrics are all improvedby 10% compared with the previous methods. These results show that the proposed method accurately countswheat ears even under conditions of wheat-ear adhesion. Furthermore, the results provide an importanttechnique for studying wheat phenotyping.INDEX TERMS Wheat-ear counting, fully convolutional network, wheat-ear adhesion, Harris cornerdetection, ﬁeld conditions.I. INTRODUCTIONWheat is an important primary grain [1], and its yield iscrucial for national food security [2]. Wheat is in highdemand by most of the world’s population [3], so researchinto predicting wheat yield has attracted signiﬁcant atten-tion [4]. The number of wheat ears per unit area is inti-mately linked to wheat yield and breeding [5], and twoThe associate editor coordinating the review of this manuscript andapproving it for publication was Jingchang Huang.methods are available to obtain the number of wheat earsper unit area: manual ﬁeld counting and image-based count-ing of wheat ears. Because conventional manual count-ing is time consuming and subjective, image-processingtechnology has recently gained widely acceptance for count-ing wheat ears [6]–[8] because of its strong universalityand high efﬁciency [9]. Generally, image-based countingof wheat ears is confronted with two main problems:the accurate segmentation of wheat ears and wheat-earadhesion [10].178930This work is licensed under Creative Commons Attribution 4.0 License. For more information, see http://creativecommons.org/licenses/by/4.0/VOLUME 7, 2019D. Wang et al. Combined Use of FCN and Harris Corner Detection for Counting Wheat Ears in Field ConditionsCurrently, two main methods exist for object segmentation:color-information-based and classiﬁer-based segmentation.Fanet al. enhanced the contrast between image colors byfusing color saliency maps with brightness saliency mapsand then used the color information to segment simpledermoscopy image [11]. Ganesan et al. used the CIELABcolor space to quantify visual differences in an image, whichenabled them to segment images with signiﬁcant color differ-ences [12]. Color-information-based segmentation methodsrely excessively on color information and cannot effectivelysegment images with small color differences [13]. Classiﬁer-based segmentation methods segment objects by learning thecharacteristics of target. Li et al. combined the texturefeatures of wheat ears with neural network to effectivelyidentify wheat ears in laboratory environment with white-board background [14]. Zhou et al. combined multi-featureoptimization with twin-support vector machine to identifywheat ears in ﬁeld conditions; however this method wasgreatly affected by soil background [13]. Classiﬁer-basedsegmentation methods need to extract target features andthen input them into classiﬁers to achieve segmentation.The quality of the features chosen for segmentation playsan important role in segmentation. Normally, it is difﬁcultto design feature-extraction algorithm to fully mine theexclusive characteristics of targets in complex conditions. In abid to overcome this difﬁculty, deep learning has recentlybecome widely used in image segmentation because it canextract complex hierarchy of features from images by self-learning [15]. For example, Bargoti et al. used convolutionalneural networks to segment fruit in an orchard environment[16]. In deep learning, semantic segmentation based onFCN has been widely used in image segmentation undercomplex conditions [17]. For example, Martin-Abadal et al.obtained high-precision semantic segmentation of the Posi-donia Oceanica meadows in sea-ﬂoor images that was morereliable than manual marking of images [18]. In other work,Baiet al. proposed deep learning method to semanticallysegment remote-sensing images on complex backgrounds byusing U-Net to map the damage after tsunami disaster. Thismethod greatly improved upon the practice of using applica-tion values to respond to operational disaster [19]. Jiang et al.proposed an end-to-end personal segmentation network struc-ture that fuses person-detection network with FCN, whichallowed them to accurately segment person in naturalscene [20]. As result, because of its high segmentationaccuracy and low computational cost, semantic segmentationhas become widely used in complex conditions [21].After segmenting wheat ears, the adhesion of wheat earsbecomes particularly important. Fang et al. used watershedsegmentation to deal with adhesion in plant disease recog-nition, but this method over-segments in multiple-adhesionsituations [22]. Ning et al. effectively segmented images ofadhesive ores based on pit matching. The adhesion situationin their study was relatively simple [23]. The methods men-tioned above for dealing with adhesion introduce segmenta-tion errors and cannot cope with the complicated adhesionof wheat ears in ﬁeld conditions. Corner detection can effec-tively identify point features of image-edge contour intersec-tion, giving it the potential to solve multi-target adhesion [24].Yan et al. used Shi-Tomasi corner detection to effectivelysolve the problem of adhesive vehicles [25]. Wang et al.used the curvature scale space corner detection method tosuccessfully separate overlapped cells [26]. Therefore, cornerdetection might be one way to solve adhesion problems in thecounting of wheat ears.The main objectives of this study are (1) to explore theability of FCN to segment wheat ears in ﬁeld conditions; and(2) demonstrate whether corner detection can solve adhesionproblems in wheat-ear counting. This paper ﬁrst marks andcuts the acquired RGB images to train the wheat-ear segmen-tation model. The trained model is then used to segment theinput image. Next, the wheat ears are binarized by using theOtsu algorithm to highlight the area of wheat ears. Finally,the wheat-ear skeletons are extracted, and the number ofwheat ears is obtained by using Harris corner detection [27].The rest of this paper is arranged as follows: Section IIintroduces the study area and the process used to generatewheat-ear image datasets for segmentation model trainingand testing. Section III outlines the proposed method to countwheat ears, and Sec. IV presents the experimental results forcounting wheat ears in ﬁeld conditions. Section discussesthe effectiveness of the method, and Sec. VI gives the mainconclusions.II. STUDY AREA AND PREPARATION OF EXPERIMENTALDATAA. STUDY AREA AND DATA ACQUISITIONThe experiment ﬁeld was located at the wheat breeding baseof Agricultural Science of the Lixiahe District (Yangzhou,China, 3225018.9700latitude North, 11931025.6600longitudeEast). The experiment was conducted under clear windlessweather from 12 a.m. to p.m. on May 9, 2018, so thepossibility of image distortion due to weather conditionswas eliminated. total of 180 wheat images were acquiredby using Panasonic DC-GF9 digital camera (resolution:4592 ⇥3448 pixels, aperture: f/6.3, exposure time: 1/250 s)at 2.0 above the vertical canopy, and with 3 ⇥2.25 mview (Figure 1). Concurrently, the number of wheat ears wascounted manually in the same view ﬁeld.B. WHEAT-EAR IMAGE DATASET FOR TRAINING ANDTESTING SEGMENTATION MODELTo train the proposed segmentation model, we selected120 original wheat-ﬁeld images to construct wheat-ear imagedatasets. The wheat ears in these images were annotated byfour graduate students in 19 days. First, the wheat-ear con-tours were traced in red (R:225, G:0, B:0). Next, the contourof each wheat ear was ﬁlled by hole ﬁlling [28] to markthe entire wheat ear. The manually marked wheat ears in theoriginal image were then used as the ground truth duringtraining and testing of the segmentation model.VOLUME 7, 2019 178931D. Wang et al. Combined Use of FCN and Harris Corner Detection for Counting Wheat Ears in Field ConditionsFIGURE 1. Schematic diagram of study area and data collection.FIGURE 2. Generation of wheat-ear image dataset: (a) original image, (b)manually annotated sub-image, (c) resampled and gray-scaled sub-image.The red box represents 768 ⇥768-pixel sliding window.The original image was large and not conducive to train-ing the segmentation model, so it was cut into sub-images.To ensure that wheat ears and background were as visibleas possible, 768 ⇥768-pixel sliding window was slid overthe original image with step of 0.5 ⇥768 pixels to obtain atotal of 6500 sub-images. The sub-images were resampled to256⇥256 pixels by using bilinear interpolation [29], and thenthe resampled sub-images were gray-scaled [30] for trainingsegmentation models (Figure 2).The input images were slightly processed to better testthem. First, the input image was resampled to (6 ⇥768)⇥(5⇥768) pixels by bilinear interpolation. Next, by slid-ing 768 ⇥768-pixel window over an input image with astep of 768, total of 30 sub-images were obtained. Thesub-images were resampled to 256 ⇥256 pixels by bilin-ear interpolation, and then the resampled sub-images weregray-scaled to serve as test images.III. METHODSTo properly segment wheat ears in complex conditions,we trained the segmentation model based on FCN. Basedon the segmentation results, the images are binarized byapplying the Otsu algorithm to highlight the wheat-ear inthe images, following which the wheat-ear skeletons areextracted. Finally, Harris corner detection was used to countthe wheat ears. The critical steps of the method are as follows(Figure 3):1) Train the wheat-ear segmentation model based on theconstructed dataset of wheat-ear images.2) Use the wheat-ear segmentation model to segment thetest images. Next, stitch the segmented sub-imagesFIGURE 3. Flowchart of proposed wheat-ear counting method.in sequence, and resample the spliced image to4592 ⇥3448 pixels by using the bilinear interpolationmethod. Finally, apply the Otsu algorithm to the resam-pled image to obtain the binary image.3) Use Zhang’s fast parallel algorithm [31] to identify thewheat-ear skeletons in the binary image.4) Use Harris corner detection to detect and then realizethe counting of wheat-ear.A. CONSTRUCTION OF WHEAT-EAR SEGMENTATIONMODEL BASED ON FULLY CONVOLUTION NETWORKThe ﬁeld wheat-ear segmentation model is realized by usinga ﬁne-tuned U-Net network, which semantically segmentswheat ears in the ﬁeld. The U-Net network is built on thearchitecture of FCN [32]. In the feature-extraction module,the deep features of the target are learned by the successiveconvolution layer. The output of the feature-extraction mod-ule is then merged in the up-sampling module. The feature-extraction part consists of ten ⇥3 convolution layers andfour ⇥2 maximum pooling layers, and the up-sampling partcontains eight ⇥3 convolution layers, 1 ⇥1 convolutionlayer, and four ⇥2 deconvolution layers.The network function is powerful and suited for multi-scalesegmentation of large images in complex conditions. In thispaper, the input to the network is 256 ⇥256-pixel grayscaleimage. The output is 256 ⇥256-pixel segmented grayscaleimage of wheat ears in the ﬁeld. Using the rectiﬁed linear unitnonlinearity (ReLU) as activation function. The convolutionresult of each convolution layer is ﬁlled with zeros to ensurethat the input and output size remains unchanged to avoidcropping when up-sampling the output part of the featureextraction. Figure shows the ﬁeld wheat-ear segmentationnetwork.The wheat-ear segmentation model is trained by theconstructed wheat-ear image dataset, which contains 4550training sets and 1950 veriﬁcation sets. The speciﬁc param-eters are (i) learning rate =0.001, (ii) batch size =20, (iii) epochs =30, and (iv) steps_per_epoch =1000.178932 VOLUME 7, 2019D. Wang et al. Combined Use of FCN and Harris Corner Detection for Counting Wheat Ears in Field ConditionsFIGURE 4. Field wheat-ear segmentation network. The red dotted frame shows the feature-extraction part of the network, and the green dotted frameshows the up-sampling part of the network.The learning rate determines how fast the parameter movesto the optimal value, the batch size indicates the number ofsamples taken from the training set for each training batch,the epoch indicates the number of rounds used for training,and the steps_per_epoch indicates the number of batches sentto be trained in an epoch. The training time is 10.06 hours,the segmentation accuracy is 0.984, the loss is 0.038, andthe segmentation of 256 ⇥256 image takes 0.033 s. Thesegmentation model can be well used for the segmentationof wheat ears in the ﬁeld.B. IMAGE BINARIZATION USING OTSU ALGORITHMThe output of the above segmentation model is probabilitydistribution map, which is grayscale image. Therefore,threshold processing must be applied to the probability-distribution image to highlight the regions that are probablywheat ears. The resulting binary image of the wheat earsis more convenient for counting. The maximum inter-groupvariance method was proposed by Otsu [33], which is anadaptive threshold-determination method and is called theOtsu algorithm. This algorithm divides the image into twoparts, background and target, by looking for the thresholdTbased on the grayscale characteristics of the image. Thesegmentation threshold of image foreground and backgroundis denoted T. The fraction of foreground pixel points in thewhole image is w0, and its average grayscale is µ0. Thefraction of background pixel points in the whole image is w1,and its average grayscale is µ1.Tis calculated as follows:T=w0⇥w1⇥(µ1µ0)⇥(µ0µ1) (1)C. HARRIS-CORNER-DETECTION–BASED WHEAT-EARCOUNTINGCounting wheat ears requires ﬁrst identifying the wheat-ear skeletons, which is done by progressively scanning thebinary wheat-ear image to determine boundary points. Allboundary-point pixels are added to the boundary-point series.FIGURE 5. Harris corner detection of wheat ears: (1) single wheat ear,(2) two adhered wheat ears, (3) three adhered wheat ears. Panels (a), (c),and (e) show RGB images of adhered wheat ears. Panels (b), (d), and (f)show corner-detection images of adhered wheat ears. The figure showsexamples of various adhesion conditions. White is the wheat-ear area,gray is the wheat-ear skeleton, and red points are corner points.Next, Zhang’s fast parallel algorithm is used to judge whetherthe boundary point can be deleted: If so, the point is directlydeleted; if not, the point is retained. After scanning, the imageis reﬁned. Next, Harris corner detection is used to count thenumber of adhesive wheat ears. As shown in Figure 5, singlewheat ear has no corner point; two adhered wheat ears haveone corner point; three adhered wheat ears have two cornerpoints, etc. Thus, ncorner points in single connected regionindicate n+1 wheat ears. In this way, the number of cornerpoints in the image is counted to obtain the number of wheatears in the image.D. CRITERIA FOR EVALUATION ALGORITHMFour metrics: SSIM, Precision, Recall, and F-measure, wereused to evaluate segmentation quality [34], [35]. SSIMdescribes the similarity between the segmented image and thereal image: the higher its value, the more the two images aresimilar. Precision measures the accuracy of the segmentationalgorithm, and Recall measures the integrity of the segmen-tation image. Finally, F-measure is used to balance PrecisionVOLUME 7, 2019 178933D. Wang et al. Combined Use of FCN and Harris Corner Detection for Counting Wheat Ears in Field ConditionsFIGURE 6. Wheat-ear segmentation.and Recall. higher F-measure is indicative of better seg-mentation. The segmentation time is used to evaluate theefﬁciency of the algorithm. These metrics can be calculatedas follows:SSIM (x,y)=(2µxµy+c1)(2xy+c2)(µ2x+µ2y+c1)(2x+2y+c2)(2)Precision =TPTP+FP(3)Recall =TPTP+FN(4)Fmeasure =2⇥Precision ⇥RecallPrecision +Recall⇥100% .(5)The accuracy, average accuracy (Acc), R2, and RMSE areused as metrics to evaluate the counting performance [8].Accuracy, Acc, and R2values closer to unity indicate betterperformance, as do smaller RMSE values:Accuray =|zici|zi⇥100% (6)Acc=1nnX1|zici|zi⇥100% (7)R2=1nP1(zici)2nP1(zi¯zi)2(8)RMSE =vuuutnP1(zici)2n(9)where xandyrefer to the two images being compared, µx(µy) is the mean of image x(y),2x(2y) is the variance ofimage x(y),2xyis the covariance of image xandy, and c1=k21L2,c2=k22L2are constants that keeps things stable, withLbeing the dynamic range of pixel values, and k1=0.01,k2=0.03.TPis the predicted number of wheat ears, andthe corresponding real results are all wheat-ear pixels. FP(false positive) is the number of pixels classiﬁed as wheat-earpixels, but the real results of these pixels are the background.FN(false negative) is the number of pixels that belongs to thereal results but are not correctly identiﬁed. Finally, nis thenumber of images in the testing set, ziis the number of wheatears counted in image i,¯ziis the average number of wheatears per image, and ciis the predicted number of wheat earsin image i.IV. RESULTSThe proposed method is tested by comparing its resultsto the number of wheat ears counted on the ground. Thewheat-ear segmentation model was developed and codedin PyCharm 2017 (Python 3.5.4, OS: Ubuntu 18.04 64-bit,CPU: Intel i7-6800K 3.40GHz, GPU: Nvidia GeForce GTX1080Ti, RAM: 16 GB). The wheat-ear counting algorithmwas developed in Matlab R2017a (Windows 10, CPU: Inteli7-6800K 3.40GHz, GPU: Nvidia GeForce GTX 1080Ti,RAM: 16 GB).A. RESULTS OF WHEAT-EAR SEGMENTATIONThe testing images were input into the segmentation model,and the segmentation result was spliced and resampled to4592 ⇥3448 pixels. The Otsu algorithm was applied to bina-rize the image (Figure 6).178934 VOLUME 7, 2019D. Wang et al. Combined Use of FCN and Harris Corner Detection for Counting Wheat Ears in Field ConditionsFIGURE 7. Example of field wheat-ear segmentation: (a) original image,(b) ground truth of original image, (c) segmentation result of method ofZhou et al., (d) segmentation result of method in this paper. The redelliptical regions indicate the segmentation errors.This work uses the segmentation method proposed byZhou et al. [13] to analyze the advantages and disadvantagesof the proposed segmentation method. Zhou et al. comparedand analyzed variety of segmentation methods, and theirresults were better than those of the other methods. Thus, wecompare the results of the proposed method only with thoseof the method of Zhou et al. Figure shows the segmentationresults of the proposed method.As shown in Figure 7, both the segmentation method pro-posed in this paper and the segmentation method of Zhouet al. produce certain segmentation error when segment-ing wheat ears. To better evaluate the segmentation results,the SSIM, Precision, Recall, and F-measure are used to eval-uate the 60 image-segmentation results. In addition, the seg-mentation time is also used to evaluate the efﬁciency of theproposed algorithm [36]. The results are shown in Figure 8.As shown in Figure 8, the SSIM, Precision, Recall,F-measure, and average segmentation time of the proposedmethod are 0.890, 0.999, 0.878, 0.935, and 0.984 s, respec-tively. The proposed segmentation method thus performs bet-ter than the method of Zhou et al. for segmenting wheat earsin the ﬁeld. Compared with the method of Zhou et al. there ismore than 10% improvement in each evaluation index. Theproposed segmentation method has little up-down deviationand good stability, which allows efﬁcient segmentation ofwheat ears in ﬁeld conditions.B. RESULTS OF WHEAT-EAR COUNTINGBased on the binary image of the segmentation results, thewheat-ear skeletons are identiﬁed. The number of wheat earsis then counted by using Harris corner detection (Figure 9).As shown in Figure 9, Harris corner detection can effec-tively detect the adhered wheat ears and thereby properlycount the number of wheat ears. Sixty wheat-ear images areused to compare the performance of the proposed methodFIGURE 8. Evaluation of segmentation results of each method. Eachcolumn represents the mean, and the error bars represent the standarddeviation in the testing data.with that of Zhou et al. [13]. Table presents the resultsof counting, and Figure 10 combines the results of manualstatistics, R2, and the RMSE of each method.Table and Figure 10 show that the highest accuracy of thecounting method in this work is unity, and the minimum accu-racy is 0.924. Furthermore, Acc, R2, and RMSE are 0.974,0.983, and 14.043, respectively. For all images, the manualcounting result is positively and strongly correlated withand automated counting result. Moreover, compared with themethod of Zhou et al. various metrics are improved uponusing the proposed method.V. DISCUSSIONA. ACCURACY AND ANTI-INTERFERENCE ANALYSIS OFWHEAT-EAR SEGMENTATION MODEL IN FIELDWe now discuss how to better evaluate the segmentationaccuracy and anti-interference of the model. Figure 11 ana-lyzes the performance of the segmentation model undercomplex conditions, such as wheat-ear occlusion, leaf occlu-sion, uneven illumination, and soil interference. The green,blue, brown, purple, and yellow frames indicate occlusionsof wheat, uneven illumination, leaf occlusion, soil inﬂu-ence, and areas of segmentation error, respectively. Redframes indicate incorrect segmentations that affect the count.Because many segmentation errors appear in the ﬁgure,some are not marked. We used the proposed segmentationmodel and the method of Zhou et al. to segment 30 imageswith these interference factors. The segmentation results (seeFigure 12) are then evaluated by SSIM, Precision, Recall, andF-measure.According to Figure 11, the wheat-ear segmentation modelproposed herein effectively segments the wheat ears and hasa certain degree of anti-interference. Although some errorsappear, the model basically segments each wheat ear. Facedwith these interfering factors, the method of Zhou et al.produces large segmentation errors. As shown in Figure 12,the segmentation results of the proposed method are betterthan those of the method of Zhou et al. as per SSIM, Pre-cision, Recall, and F-measure. The proposed segmentationmodel obtains SSIM =0.983, indicating that the segmenta-tion results are basically similar to the ground truth.VOLUME 7, 2019 178935D. Wang et al. Combined Use of FCN and Harris Corner Detection for Counting Wheat Ears in Field ConditionsFIGURE 9. Wheat ears count results. (a) binary image of segmentation results, (b) wheat ears skeleton, (c) Harris corner.FIGURE 10. Each method counts R2and RMSE of the results. Each color dot represents each method.FIGURE 11. Accuracy and anti-interference analysis of wheat-ear segmentation model in field conditions. The images in theleft column are with interference factors, the ground truth binary images are in the second column, the grayscale imagesoutput by the proposed segmentation model are in the third column, and the grayscale images output by the method of Zhouet al. are in the fourth column. The green, blue, brown, purple, and yellow frames indicate the areas where the wheat isoccluded, uneven illumination areas, occlusion of leaves, soil-influence areas, and areas of segmentation error, respectively.The red frames indicate incorrect segmentations that affect the count.Because deep learning uses deep neural networks and alarge number of training designs, it can better learn and minethe deep features of images [37]. Compared with traditionalmachine learning methods, it has signiﬁcant advantages interms of target recognition. Therefore, deep learning is usedto segment wheat ears based on leveraging large number178936 VOLUME 7, 2019D. Wang et al. Combined Use of FCN and Harris Corner Detection for Counting Wheat Ears in Field ConditionsFIGURE 12. Anti-interference analysis of each method. Each column indicates mean, and the error barsindicate the up-down deviation.of manually labeled datasets. Its segmentation accuracy andanti-interference capability are better than those of traditionalmachine learning methods. However, Precision, Recall, andF-measure are poor, indicating that there are lot of errors inthe segmentation results compared with the ground truth.The model segmentation error for the proposed methodmay be related to network or dataset selection. The errormay be due to the relatively simple network structure andthe fact that wheat-ear depth features cannot be fully mined,leading to the error of the network extraction of wheat-earfeatures. Further study should use more complex networksuch as Mask r-cnn [38] or DeepLab v3 [39]. In addition,the dataset does not adequately reﬂect the wheat ears in theﬁeld environment. Therefore, the dataset should be expandedto learn the characteristics of wheat ears in the ﬁeld.B. ANALYSIS OF WHEAT-EAR COUNTTable gives the count for each image is displayed. Becausethe segmentation model accurately segments the wheat earsin the ﬁeld, the counts obtained by the proposed method areclose to the ground truth, and the accuracy exceeds that of themethod of Zhou et al.In this work, most of the image counts obtained by usingthe proposed method are higher than the ground truth, whichmay be because leaves split complete wheat ears and increasethe connected region, leading to counts that exceed theground truth. Most of the image counts are lower than theground truth. This may be due to occlusions and to largeshadows of wheat ears, leading to segmentation error andresulting in slightly lower counts.As shown in Figure 13, wheat-ear occlusion may causeunder-segmentation of adhered wheat ears, leading to count-ing error. Shadows may also cause segmentation errors,FIGURE 13. Analysis of counting results for each image. The left columnshows images with interference factors, the second column showsground truth binary images, the third column shows the grayscale imagefrom the proposed segmentation model, and the fourth column showswheat-ear skeletons and Harris corner detection. The green rectanglesshow occluded wheat ears and shadows that affect larger part of theimage, and the red ovals show the segmentation of wheat earseparated by leaf.causing more under-segmentation of the wheat-ear portionof an image. In Figure 13, these effects caused under-segmentation of the wheat ears, resulting in lower count.The wheat ear occluded by the leaf may split in two singleconnected area, resulting in multiple counts.C. EFFECT OF DIFFERENT FIELD OF VIEW ONRECOGNITION ACCURACYTo study how ﬁeld size affects the recognition accuracy,we determine the center points of 60 images. The side lengthof the square area is determined using 0.6 to 2.2 inter-vals. The number of wheat ears in each area is counted.The inﬂuence of the ﬁeld size on recognition accuracy isdetermined from the counts obtained by the proposed method.VOLUME 7, 2019 178937D. Wang et al. Combined Use of FCN and Harris Corner Detection for Counting Wheat Ears in Field ConditionsTABLE 1. Wheat ears count results of each image.As shown in Figure 14, the maximum R2and RMSE are0.912 and 22.841 when the ﬁeld of view is 2.2 ⇥2.2 m.As shown in Figure 15, the R2signiﬁcantly increases whenthe view increases from 0.8 to 1.0 m, from 1.6 to 1.8 m, andfrom 2.0 to 2.2 m. The RMSE increases signiﬁcantly whenthe view increases from 0.6 to 0.8 and from 1.0 to 2.0 m.It is concluded that the ﬁeld of view is more reasonable at1.0 and 2.2 m, and the ﬁeld of view is optimal at 2.2 m.Because the ﬁeld of view in this paper is limited to 0.6 to2.2 m, we cannot discuss the counts for other ﬁelds of view.However, the results for R2and RMSE with the ﬁeld ofview between 0.6 and 2.2 indicate that R2and RMSE mayincrease with larger ﬁeld of view. However, the trend maychange; for example, larger ﬁeld of view may result in alarger segmentation error and therefore worse result. Theseresults provide certain point of reference for studying theoptimal result within the ﬁeld of view.D. COMPARISON WITH OTHER COUNTING TECHNIQUETable compares our results with those of the MCNNmethod [40], where MCNN has 4450 training sets and 1950178938 VOLUME 7, 2019D. Wang et al. Combined Use of FCN and Harris Corner Detection for Counting Wheat Ears in Field ConditionsFIGURE 14. R2and RMSE for different field-of-view sizes.TABLE 2. Wheat-ear counting from proposed method compared withmcnn method.validation sets during training, with the parameters learn-ing rate =0.001, each patch =10, epochs =10. MCNNis designed to solve counting problems in cluster environ-ments or dense populations by density regression. BecauseMCNN is based on density and differs from the processingused herein, we compare and analyze only the ﬁnal countingresults.As shown in Table 2, MCNN provides good countingresults for wheat ears, but the results are inferior to those ofthe proposed method. Because the training data used hereinis sub-image obtained by cropping, the wheat density in thesub-image is small and may not be applicable to the MCNN.Second, MCNN may have fewer training sessions, and thelearning rate may not be optimal, which impacts the ﬁnalcounting results. In this experiment, MCNN counts the wheatears in the sub-image and adds the count results of the 30 sub-images to obtain the ﬁnal count result. Since large numberof the same wheat ears are cropped into the two sub-imageswhen the original image is cropped, the ﬁnal counting resultis increased to cause large counting error.The proposed method divides wheat-ear counting into twoprocesses. Considering the efﬁciency and accuracy of thedetection, the two processes can be combined into one deeplearning model. For example, Yu et al. proposed deep con-volutional neural network that supports region of interest; itcombines the region of interest subnet and the classiﬁed sub-net into single deep learning model to effectively identifyapple leaf disease [41]. Inspired by this method, wheat-earcounting and image segmentation can be combined into onemodel and then trained in an end-to-end manner. However,to properly merge the two subnets, the loss function settingis important, and signiﬁcant experimentation is required todetermine the best loss function.This type of thinking guides our next experiment, whichis designed to determine whether the subnet of the wheat-earcount can be realized by deleting the classiﬁcation layer ofthe VGG subnet and then adding the regression layer. Thenumber of wheat ears can be entered into the regression layerto provide the true value on the ground. loss function is alsodesigned to merge the two subnets and achieve more accuratecounts.VI. CONCLUSIONThis research investigates wheat-ear counting in ﬁeldenvironment and proposes an efﬁcient automated countingmethod that uses RGB images. First, we constructed datasetof 120 wheat-ear images manually marked. Next, wheat-ear segmentation model was established based on FCN.The model offers high segmentation accuracy and good anti-interference capacity for wheat-ear segmentation under acomplex environment. The wheat ears are counted by apply-ing Harris corner detection to wheat-ear skeletons. This workcompares the proposed wheat-ear segmentation model withprevious machine learning methods. The results show that theproposed segmentation model offers signiﬁcant advantagefor segmenting wheat ears. The proposed method providesaccurate counts and robust anti-interference capacity, whichprovides effective data support for estimating crop yield andfor breeding wheat varieties.This study demonstrates that FCN can be effectivelyapplied to wheat-ear segmentation under ﬁeld conditions, andthat the wheat-ear count can be detected by using Harris cor-ner detection. In addition, the method has low implementationcosts. Provided the wheat-ear image data acquired in the ﬁeldare collected by digital camera, the corresponding numberof wheat ears can be obtained. The results of this study alsosupport wheat phenotype and breeding research.ACKNOWLEDGMENTD. Wang analyzed the data and drafted the article. Y. Fu,G. Yang, D. Zhang, C. Zhou, and X. Yang reviewed andedited the article. D. Liang and X. Yang designed the exper-iments. N. Zhang and H. Wu collected experimental data.All authors gave ﬁnal approval for publication. The fundershad no role in choosing the study design or in the collection,analysis, and interpretation of the data, in the writing of thereport, or in the decision to submit the article for publication.REFERENCES[1] T. Curtis and N. G. Halford, ‘‘Food security: The challenge of increasingwheat yield and the importance of not compromising food safety,’’ Ann.Appl. Biol. vol. 164, no. 3, pp. 354–372, May 2014.[2] S. Ayas, H. Dogan, E. Gedikli, and M. Ekinci, ‘‘Microscopic image seg-mentation based on ﬁreﬂy algorithm for detection of tuberculosis bacte-ria,’’ in Proc. 23rd Signal Process. Commun. Appl. Conf. (SIU) Malatya,Turkey, May 2015, pp. 851–854, doi: 10.1109/SIU.2015.7129962.[3] P. D. Hollins, P. S. Kettlewell, S. T. Parsons, and M. D. Atkinson, ‘‘Theimpact of supply, demand and grain quality on the UK bread and feedwheat price differential in the UK,’’ J. Agricult. Sci. vol. 144, no. 144,pp. 411–419, Oct. 2006.[4] P. Bognár, A. Kern, S. Pásztor, J. Lichtenberger, D. Koronczay, andC. Ferencz, ‘‘Yield estimation and forecasting for winter wheat in Hungaryusing time series of MODIS data,’’ Int. J. Remote Sens. vol. 38, no. 11,pp. 3394–3414, May 2017.VOLUME 7, 2019 178939D. Wang et al. Combined Use of FCN and Harris Corner Detection for Counting Wheat Ears in Field Conditions[5] G. Desheva and S. Kachakova, ‘‘Correlations between the main structuralelements of yield in common wheat cultivars,’’ Plant Sci. to be published.[6] Y. Zhu, Z. Cao, H. Lu, Y. Li, and Y. Xiao, ‘‘In-ﬁeld automatic observationof wheat heading stage using computer vision,’’ Biosyst. Eng. vol. 143,pp. 28–41, Mar. 2016.[7] J. A. Fernandez-Gallego, S. C. Kefauver, N. A. Gutiérrez,M. T. Nieto-Taladriz, and J. L. Araus, ‘‘Wheat ear counting in-ﬁeldconditions: High throughput and low-cost approach using RGB images,’’Plant Methods vol. 2018, no. 1, p. 22, Mar. 2018.[8] J. Wu, G. Yang, X. Yang, B. Xu, L. Han, and Y. Zhu, ‘‘Automatic countingof in situ rice seedlings from UA images based on deep fully convolu-tional neural network,’’ Remote Sens vol. 11, no. 6, p. 691, Mar. 2019.[9] W. Maldonado and J. C. Barbosa, ‘‘Automatic green fruit counting inorange trees using digital images,’’ Comput. Electron. Agricult. vol. 127,pp. 572–581, Sep. 2016.[10] S. H. Mussavi, K. Alamisaid, G. Fathi, A. Siahpoosh, and M. H. Gharineh,‘‘Effect of seed density and molinit rates on barnyardgrass (Echinochloacrus-galli) control in direct-seeded rice in Ahwaz,’’ Agronomy J. vol. 1,no. 90, pp. 83–92, 2011.[11] H. Fan, F. Xie, Y. Li, Z. Jiang, and J. Liu, ‘‘Automatic segmentationof dermoscopy images using saliency combined with Otsu threshold,’’Comput. Biol. Med. vol. 85, pp. 75–85, Jun. 2017.[12] P. Ganesan, V. Rajini, and R. I. Rajkumar, ‘‘Segmentation and edge detec-tion of color images using CIELAB color space and edge detectors,’’ inProc. INTERACT Dec. 2010, pp. 393–397.[13] C. Zhou, D. Liang, X. Yang, H. Yang, J. Yue, and G. Yang, ‘‘Wheatears counting in ﬁeld conditions based on multi-feature optimization andTWSVM,’’ Frontiers Plant Sci. vol. 9, p. 1024, Jul. 2018.[14] Q. Li, J. Cai, B. Berger, M. Okamoto, and S. J. Miklavcic, ‘‘Detectingspikes of wheat plants using neural networks with laws texture energy,’’Plant Methods vol. 13, no. 1, p. 83, Oct. 2017.[15] Z. Akkus, A. Galimzianova, A. Hoogi, D. L. Rubin, and B. J. Erickson,‘‘Deep learning for brain MRI segmentation: State of the art and futuredirections,’’ J. Digit. Imag. vol. 30, no. 4, pp. 449–459, 2017.[16] S. Bargoti and J. P. Underwood, ‘‘Image segmentation for fruit detectionand yield estimation in apple orchards,’’ J. Field Robot. to be published.[17] H. Noh, S. Hong, and B. Han, ‘‘Learning deconvolution network forsemantic segmentation,’’ in Proc. IEEE Int. Conf. Comput. Vis. (ICCV) ,Dec. 2015, pp. 1520–1528.[18] M. Martin-Abadal, E. Guerrero-Font, F. Bonin-Font, and Y. Gonzalez-Cid,‘‘Deep semantic segmentation in an AUV for Online Posidonia Oceanicameadows identiﬁcation,’’ IEEE Access vol. 6, pp. 60956–60967, 2018.[19] Y. Bai, E. Mas, and S. Koshimura, ‘‘Towards operational satellite-baseddamage-mapping using U-Net convolutional network: case study of2011 Tohoku Earthquake-Tsunami,’’ Remote Sens. vol. 10, no. 10, p. 1626,2018.[20] X. Jiang, Y. Gao, Z. Fang, P. Wang, and B. Huang, ‘‘An end-to-endhuman segmentation by region proposed fully convolutional network,’’IEEE Access vol. 7, pp. 16395–16405, 2019.[21] X. Li, H. Chen, X. Qi, Q. Dou, C.-W. Fu, and P. A. Heng, ‘‘H-DenseUNet:Hybrid densely connected UNet for liver and tumor segmentation fromCT volumes,’’ IEEE Trans. Med. Imag. vol. 37, no. 12, pp. 2663–2674,Dec. 2018.[22] Y. Fang and R. P. Ramasamy, ‘‘Current and prospective methods for plantdisease detection,’’ Biosensors vol. 5, no. 3, pp. 537–561, Aug. 2015.[23] Z. Ning, W. Shen, and C. Xiong, ‘‘Adhesion ore image separation methodbased on concave points matching,’’ Inf. Technol. Intell. Transp. Syst. ,vol. 455, pp. 153–164, Nov. 2016.[24] F. Mokhtarian and R. Suomela, ‘‘Robust image corner detection throughcurvature scale space,’’ IEEE Trans. Pattern Anal. Mach. Intell. vol. 20,no. 12, pp. 1376–1381, Dec. 1998.[25] J. Y. Chen, Y. Liu, N. Li, and K. P. Lim, ‘‘A method for separating adhesivevehicles based on corner detection,’’ in Proc. Int. Conf. Inf. Commun.Technol. Apr. 2015, pp. 1–5.[26] P. Wang, X. Hu, Y. Li, Q. Liu, and X. Zhu, ‘‘Automatic cell nucleisegmentation and classiﬁcation of breast cancer histopathology images,’’Signal Process. vol. 122, pp. 1–13, May 2015.[27] P. Ram and S. Padmavathi, ‘‘Analysis of Harris corner detection for colorimages,’’ in Proc. Int. Conf. Signal Process., Commun., Power EmbeddedSyst. (SCOPES) Oct. 2017.[28] E. Dougherty and R. A. Lotufo, Hands-On Morphological Image Process-ing. Bellingham, WA, USA: SPIE, 2003, doi: 10.1117/3.501104.[29] E. J. Kirkland, ‘‘Bilinear interpolation,’’ in Advanced Computing in Elec-tron Microscopy Boston, MA, USA: Springer, 2010, pp. 261–263.[30] E. R. Dougherty and R. A. Lotufo, ‘‘Gray-scale morphology,’’ Tech. Rep.,2003.[31] T. Y. Zhang and C. Y. Suen, ‘‘A fast parallel algorithm for thin-ning digital patterns,’’ Commun. ACM vol. 27, no. 3, pp. 236–239,1984.[32] O. Ronneberger, P. Fischer, and T. Brox, ‘‘U-Net: Convolutional networksfor biomedical image segmentation,’’ in Proc. Int. Conf. Med. ImageComput. Comput.-Assist. Intervent. Nov. 2015, pp. 234–241.[33] N. Otsu, ‘‘A threshold selection method from gray-level histograms,’’ IEEETrans. Syst., Man, Cybern. vol. 9, no. 1, pp. 62–66, Jan. 1979.[34] X. Xiong, L. Duan, L. Liu, H. Tu, P. Yang, D. Wu, G. Chen, L. Xiong,W. Yang, and Q. Liu, ‘‘Panicle-SEG: robust image segmentation methodfor rice panicles in the ﬁeld based on deep learning and superpixel opti-mization,’’ Plant Methods vol. 13, no. 1, p. 104, Nov. 2017.[35] B. Ma, Z. Liu, F. Jiang, Y. Yan, J. Yuan, and S. Bu, ‘‘Vehicle detectionin aerial images using rotation-invariant cascaded forest,’’ IEEE Access ,vol. 7, pp. 59613–59623, 2019.[36] C. Yu, B. Jin, Y. Lu, X. Chen, Z. Yi, Z. Kai, and S. Wang, ‘‘Multi-thresholdimage segmentation based on ﬁreﬂy algorithm,’’ in Proc. 9th Int. Conf.Intell. Inf. Hiding Multimedia Signal Process. Beijing, China, Oct. 2013,pp. 16–18.[37] Y. Guo, Y. Liu, A. Oerlemans, S. Lao, S. Wu, and M. S. Lew, ‘‘Deeplearning for visual understanding: review,’’ Neurocomputing vol. 187,pp. 27–48, Apr. 2016.[38] K. He, G. Georgia, D. Piotr, and G. Ross, ‘‘Mask R-CNN,’’ in Proc. IEEEInt. Conf. Comput. Vis. (ICCV) Oct. 2017, pp. 2961–6969.[39] L. C. Chen, G. Papandreou, I. Kokkinos, K. Murphy, and A. L. Yuille,‘‘Semantic image segmentation with deep convolutional nets and fullyconnected crfs,’’ Comput. Sci. vol. 2014, no. 4, pp. 357–361, Dec. 2014.[40] Y. Zhang, D. Zhou, S. Chen, S. Gao, and Y. Ma, ‘‘Single-image crowdcounting via multi-column convolutional neural network,’’ in Proc. IEEEConf. Comput. Vis. Pattern Recognit. (CVPR) Las Vegas, NV, USA,Jun. 2016, pp. 589–597.[41] H.-J. Yu and C.-H. Son, ‘‘Apple leaf disease identiﬁcation throughregion-of-interest-aware deep convolutional neural network,’’ 2019,arXiv:1903.10356 [Online]. Available: https://arxiv.org/abs/1903.10356DAOYONG WANG is currently pursuing the mas-ter’s degree with the School of Electronic Infor-mation Engineering, Anhui University, and theBeijing Research Center for Information Technol-ogy in Agriculture. His current research interestsinclude computer vision, image processing, anddeep learning.YUANYUAN FU received the Ph.D. degreefrom the School of Environment and Resources,Zhejiang University, in 2015. Her research inter-ests include remote sensing image processing andagricultural quantitative remote sensing.GUIJUN YANG received the Ph.D. degree in car-tography and geographic information system fromthe State Key Laboratory of Remote Sensing Sci-ence, Institute of Remote Sensing Applications(IRSA), Chinese Academy of Sciences (CAS),Beijing, China, in 2008. He is currently ResearchAssociate with the National Engineering ResearchCenter for Information Technology in Agricul-ture (NERCITA), Beijing. His research interestsinclude radiative transfer modeling, imagery sim-ulation, atmospheric correction, quantitative inversion, big data, and cloudcomputing.178940 VOLUME 7, 2019D. Wang et al. Combined Use of FCN and Harris Corner Detection for Counting Wheat Ears in Field ConditionsXIAODONG YANG received the Ph.D. degreefrom the Institute of Remote Sensing Applica-tions, Chinese Academy of Sciences, in 2008. Heis currently an Associate Research Fellow withthe Beijing Agricultural Information TechnologyResearch Center. His research interests are agricul-tural remote sensing and 3S integration.DONG LIANG received the Ph.D. degree fromAnhui University, in 2004. He is currently theDean of the School of Electronic InformationEngineering, Anhui University. His research inter-ests include computer signal processing, intel-lisense, and processing technology.CHENGQUAN ZHOU received the Ph.D. degreefrom the School of Electronics and Informa-tion Engineering, Anhui University, in 2018. Hisresearch interests include image processing andcrop phenotypic research.NING ZHANG received the Ph.D. degree fromBeijing Forestry University, in 2017. Her researchinterests include agricultural and forestry pestresearch.HONGYA WU is currently Researcher with theAgricultural Institute of Lixiahe, Jiangsu, where heis also the Deputy Director of the Wheat ResearchOfﬁce and the General Secretary of the Commu-nist Youth League. His research interest is wheatgenetic breeding.DONGYAN ZHANG received the Ph.D. degreefrom the School of Environment and Resources,Zhejiang University, in 2002. His research inter-ests include remote sensing information process-ing and analysis, intelligent sensor design anddevelopment, and big data mining and application.VOLUME 7, 2019 178941