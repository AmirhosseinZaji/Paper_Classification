Contents lists available at ScienceDirectRemote Sensing of Environmentjournal homepage: www.elsevier.com/locate/rseDeep learning based winter wheat mapping using statistical data as groundreferences in Kansas and northern Texas, USLiheng Zhonga,/uni204E, Lina Hub, Hang Zhouc, Xin TaodaDescartes Labs, Inc., San Francisco, CA 94107, United StatesbDepartment of Sociology, Tsinghua University, Beijing 100084, ChinacDescartes Labs, Inc., Santa Fe, NM 87501, United StatesdDepartment of Geography, University at Bu /uniFB00alo, The State University of New York, Bu /uniFB00alo, NY 14261, United StatesARTICLE INFOEdited by Emilio ChuviecoKeywords:Crop classi /uniFB01cationDeep learningArti/uniFB01cial neural networkConvolutional neural networkMODISWinter wheatUSDA Quick StatsABSTRACTWinter wheat is major staple crop and it is critical to monitor winter wheat production using /uniFB03cient andautomated means. This study proposed novel approach to produce winter wheat maps using statistics as thetraining targets of supervised classi /uniFB01cation. Deep neural network architectures were built to link remotely sensedimage series to the harvested areas of individual administrative units. After training, the resultant maps weregenerated using the activations on middle layer of the deep model. The direct use of statistical data to someextent alleviates the shortage of ground samples in classi /uniFB01cation tasks and provides an opportunity to utilize awealth of statistical records to improve land use mapping. The experiments were carried out in Kansas andNorthern Texas during 2001 –2017. For each study area the goal was to create winter maps that are consistentwith USDA county-level statistics of harvested areas. The trained deep models automatically identi /uniFB01ed theseasonal pattern of winter wheat pixels without using pixel-level reference data. The winter wheat maps werecompared with the Cropland Data Layer (CDL) for years when the CDL is available. In Kansas where the winterwheat extent of the CDL has high reported accuracy and agrees well with county statistics, the maps producedfrom the deep model was evaluated using the CDL as an independent test set. Northern Texas was selected as anexample where the winter wheat area of the CDL is very di /uniFB00erent from /uniFB03cial statistics, and the maps by thedeep model enabled map-to-map comparison with the CDL to highlight the areas of discrepancy. Visual re-presentation of the deep model behaviors and recognized patterns show that deep learning is an automated androbust means to handle the variability of winter wheat seasonality without the need of manual feature en-gineering and intensive ground data collection. Showing the possibility of generating maps solely from regionalstatistics, the proposed deep learning approach has great potential to /uniFB01ll the historical gaps of conventionalsample-based classi /uniFB01cation and extend applications to areas where only regional statistics are available. The/uniFB02exible deep network architecture can be fused with various statistical datasets to fully employ existing sourcesof data and knowledge.1. IntroductionWhile remote sensing studies provide /uniFB03cient means to map croptype and extent, the availability of ground reference data is one of thecritical limiting factors on the applicability of crop mapping approaches(Song et al., 2017 ). Crop classi /uniFB01cation relies on reference data collectedvia/uniFB01eld work or visual image interpretation to develop classi /uniFB01cationalgorithms and acquire agricultural information. The shortage of high-quality ground samples is major challenge to regular and rapidmonitoring of cropland, as it is time-consuming and expensive to collectreference information to train the classi /uniFB01ers for crop mapping,especially over large areas and long periods Phalke and Özdo ğan,2018 ). Although numerous studies have contributed to the /uniFB01eld of cropclassi /uniFB01cation and variety of map products have been published,training samples are rarely distributed publicly. For example, theUnited States Department of Agriculture (USDA) releases the CroplandData Layer (CDL) on an annual basis Boryan et al., 2011 ), but the farm-level land use in the Farm Service Agency's Common Land Unit datasetcan only be accessed internally by the institute.There are various methods developed to mitigate the dependency onground samples in crop mapping. The general idea is to apply trainingstatistics to an extended spatial-temporal range without severe loss ofhttps://doi.org/10.1016/j.rse.2019.111411Received December 2018; Received in revised form 12 August 2019; Accepted September 2019/uni204ECorresponding author at: Room 233, 1416 9th Street, Sacramento, CA 95814, United States.E-mail address: lihengzhong@berkeley.edu (L. Zhong).5HPRWH6HQVLQJRI(QYLURQPHQW$YDLODEOHRQOLQH6HSWHPEHU(OVHYLHU,QF$OOULJKWVUHVHUYHG7accuracy, or “signature extension ”. The /uniFB01rst method is to train theclassi /uniFB01er with ground samples in one or few years and then apply thetrained classi /uniFB01er to another year, which eliminates the need of repeatedground data collection year by year Zhong et al., 2014 ;Zhong et al.,2016b ;Massey et al., 2017 ). The method requires multi-temporal ob-servations at relatively high frequency to extract images at the samegrowing stage or derive phenological metrics with cross-year con-sistency. Similarly, it is possible to extend trained algorithms spatiallyto regions other than the training area to improve the /uniFB03ciency ofground sample use. Another method is to apply automated algorithmsto all years and study areas Zhong et al., 2012 ;Thenkabail and Wu,2012 ;Zhong et al., 2016a ;Xiong et al., 2017 ). The automated algo-rithms are usually developed by intensive exploratory analysis andfeature engineering based on rules summarized from ground referenceinformation, and the accuracy depends on expert experience and theavailability of local agricultural knowledge. So far, ground samples atpoint or parcel (object) level are still the main data source for all ca-tegories of classi /uniFB01cation approaches (supervised/unsupervised/rule-based). Although some of the existing studies notably reduce the cost ofdata collection in crop mapping, the lack of ground references remainsa challenge. Moreover, for some applications ground reference collec-tion is infeasible, for example, retrospective mapping for historicalperiod.Agricultural statistics collected and distributed by public and pri-vate agencies are rich source of information on crop production withgreat spatial coverage and temporal continuity. Previous studies cre-ated crop maps based on the statistical records at regional or countrylevel Ramankutty et al., 2008 ;Monfreda et al., 2008 ). For major cropproduction areas, statistical data are increasingly available at the levelof/uniFB01ne administrative unit, for example, county-level statistics of var-ious crop types in the US are published by the USDA National Agri-cultural Statistics Service (NASS, WWW1, n.d. ), and municipal-levelstatistics of Brazilian agriculture are published by Brazilian Institute ofGeography and Statistics on an annual basis WWW2, n.d. ). Althoughthe statistical datasets provide information on the general spatial dis-tribution of croplands, agricultural statistics are rarely employed inremote sensing classi /uniFB01cation to produce pixelwise maps. Most classi-/uniFB01ers cannot take statistics directly as input data for training or vali-dation. Even the /uniFB01ne spatial unit of statistics like county or municipalcorresponds to large and varying number of pixels on remotely sensedimages, which is subject to the curse of dimensionality and is likely toresult in an ill-posed problem. Per-pixel crop maps are useful in variousapplications such as crop yield forecast Xin et al., 2013 ;Sakamotoet al., 2014 ), water use estimate Bastiaanssen et al., 1998 ;Allen et al.,2007 ;Tang et al., 2009 ;Fisher et al., 2017 ), carbon cycle modeling(Irwin and Geoghegan, 2001 ;Harou et al., 2009 ), and economic mod-eling Baret et al., 2007 ;Searchinger et al., 2008 ;Marsden et al., 2013 ).Existing statistical datasets may contribute great wealth of informa-tion to crop mapping, but it is still challenging to combine statisticswith remote sensed observations and transfer the knowledge to thepixel level.In this study, we utilized deep learning based approach to jointlyutilize agricultural statistics and 250 pixelwise image data and gen-erate 250 crop maps using only statistical records as the training set.Deep learning is deemed as recent breakthrough technology in ma-chine learning including the research /uniFB01eld of remote sensing classi /uniFB01-cation Zhu et al., 2017 ). Deep neural networks are advantageous forautomated extraction and identi /uniFB01cation of complex patterns in largedatasets Chen et al., 2014a ;Li et al., 2016 ;Wan et al., 2017 ;Mou andZhu, 2018 ;Mou et al., 2018b ). Various specialized architectures havebeen designed in past studies to handle patterns in remotely sensedimages, including spatial patterns in high resolution images Chenet al., 2014b ;Penatti et al., 2015 ;Hu et al., 2015b ;Kamp /uniFB00meyer et al.,2016 ;Sherrah, 2016 ;Audebert et al., 2018 ;Maggiori et al., 2017 ;Liet al., 2017a ;Volpi and Tuia, 2017 ;Kussul et al., 2017 ;Marcos et al.,2018 ;Marmanis et al., 2018 ), spectral patterns in hyperspectral images(Hu et al., 2015a ;Li et al., 2017b ;Guidici and Clark, 2017 ;Lyu et al.,2018 ), and temporal patterns in multi-temporal image series Lyu et al.,2016 ;Rußwurm and Körner, 2017 ;Mou et al., 2018a ;Rußwurm andKörner, 2018 ). Although not tested so far, deep learning may provide aunique opportunity to utilize agricultural statistics directly as trainingdata. By using deep architecture with an ordered combination ofmany specialized layers, deep neural network models can regulate thesolution space with customized model constraints, achieve high algo-rithmic stability and generalization, learn complex patterns from lim-ited data, and to some extent overcome the curse of dimensionality(Zhang et al., 2018 ).Itis new classi /uniFB01cation task to map crop extent using statistics fortraining. The present study aimed to perform the task with county-levelstatistics from the USDA. The experiments were conducted in twowinter wheat production areas where the CDL is available for pixelwiseaccuracy assessment. The rest of the paper is organized as follows.Section describes the input data and the method to develop deeplearning architectures, optimize the models, and evaluate the classi /uniFB01-cation maps. Section presents the results. Section then interprets thebehavior of the optimized model to understand how it works and dis-cusses the feasibility of using statistics as the reference data in classi-/uniFB01cation applications. Section concludes the paper.2. Method and materials2.1. Study areasThe study was carried out in two areas, the whole state of Kansasand the northern region of Texas Fig. ). Kansas is the largest pro-duction state of winter wheat in the U.S. There are 105 counties inKansas, most of which are intensively cultivated by winter wheat, corn,soybean and other crops. Northern Texas includes 67 counties in fouragricultural districts (Northern High Plains, Northern Low Plains,Southern High Plains, and Southern Low Plains) and is the major winterwheat production area of the Texas state. The climate of the study areasis semi-arid in the west and humid subtropical in the east with themajority of precipitation occurring in spring and summer. Annualprecipitation of Kansas ranges from ~400 mm to ~1100 mm, andNorthern Texas from ~400 mm to ~700 mm. Winter wheat is plantedin fall and harvested in early-summer. The start of the growing season isfrom September to October, and the end is from mid-May to mid-July.While Kansas and Northern Texas are both important growing areasof winter wheat in the US, they were selected to conduct independentexperiments as two extreme cases. The CDL of Kansas has high self-reported accuracies for winter wheat (user's accuracy from 92.3% to96.8%, and producer's accuracy from 90.0% to 96.3%), and the totalwinter wheat acreage of the CDL only di /uniFB00ers from USDA NASS statisticsby 3.6% on average. Crop acreage in the NASS statistics has beenwidely used in agricultural applications and is considered as reliablereference. Therefore, the CDL of Kansas can be used as an accurateraster map for pixel-wise accuracy assessment. By contrast, the CDL ofNorthern Texas does not agree well with the NASS statistics. Althoughthe self-reported accuracies of the CDL suggest moderate error rates(user's accuracy of winter wheat varies from 81.9% to 90.6%, andproducer's accuracy from 86.5% to 93.3%), the total winter wheatacreage of the CDL is 155.2% larger than that of the NASS statistics onaverage. In the development of the CDL and also in the crop mappinge/uniFB00orts using the CDL as training data, the classi /uniFB01er trained with pixel-level samples has di /uniFB03culty in ensuring consistency with total croppedareas at the county level. We took Northern Texas as an example togenerate per-pixel maps that are consistent with the statistical data andmade comparison with the CDL.L. Zhong, et al. 5HPRWH6HQVLQJRI(QYLURQPHQW2.2. Data2.2.1. MODIS imageryThe primary input data are MODerate-resolution ImagingSpectroradiometer (MODIS) product MOD13Q1 Collection 6, 16-dayVegetation Index at 250 resolution. The MOD13Q1 product includesNormalized Di /uniFB00erence Vegetation Index (NDVI), Enhanced VegetationIndex, re /uniFB02ectance, quality and information bands since February 2000.The composite interval is 16 days starting from the /uniFB01rst day of eachyear, and each year has 23 images. The product is in the sinusoidalprojection which is equal-area. MODIS observations are subject tosensor degradation issue especially for long-term applications, and theuse of Collection data largely eliminates the negative bias Wanget al., 2012 ;Lyapustin et al., 2014 ;Sayer et al., 2015 ). In this study, weattempted to explore the viability of identifying winter wheat withNDVI. NDVI is one of the most popular vegetation indices to char-acterize seasonal crop growth and is available from many other sensors.The quality band was employed to exclude cloud-covered observationsin the NDVI series. Gaps were /uniFB01lled by per-pixel linear interpolationusing the closest high-quality observations before and after the gapdate. Gaps of the 16-day composite are short and rare thanks to thedaily revisit frequency of the MODIS platform. By visually inspectingthe/uniFB01lled NDVI time series and the frequency of high-quality observa-tions in the study areas, we considered the simple gap- /uniFB01lling method assu/uniFB03cient to depict the seasonality of the NDVI time series Kandasamyet al., 2013 ). Snow may occur in the growing season of winter wheat. Inour approach the algorithm was trained by input time series to learn toreduce the in /uniFB02uence by snow cover, and no speci /uniFB01c snow masks weredeveloped.MOD13Q1 images were clipped using the boundaries of counties inthe study areas. For each county in each year, corresponding datacube with shape of width byheight by 23 was created. Width andheightare spatial dimensions and 23 is the number of observations in theNDVI time series. In our study areas, the maximum width andheight ofall counties are 601 and 296 in Kansas, and 325 and 568 in NorthernTexas. To cover the growing season of winter wheat, the beginning ofthe annual time series was chosen as August 29th (August 28th in leapyears), the start of the 16th image in the calendar year before the yearof harvest. The earliest growing season that the MODIS data couldcompletely cover is 2000 –2001, and MODIS images from August 2000to August 2017 were acquired and processed. Margin pixels outside ofthe county boundary were set to value −1.0 throughout the year. Thedynamic range of NDVI is appropriate for deep learning models andfurther scaling is unnecessary.Fig. 1. One study area is the state of Kansas (105 counties), and the other is the 67 counties in four agricultural districts in northern Texas.L. Zhong, et al. 5HPRWH6HQVLQJRI(QYLURQPHQW2.2.2. USDA statisticsUSDA NASS continuously publishes statistics of various agriculturalcommodities acquired through the survey and the census programs. Thedata item used in this study is harvested acres of winter wheat percounty retrieved from the NASS Quick Stats portal WWW1, n.d. ). Thecensus is complete count of croplands which is taken every /uniFB01ve years.For census years the census data were used and for other years theannual survey data were used to generate an annual statistical record.By the time of this study, census data in 2002, 2007, and 2012 areavailable within the observation period of MOD13Q1. The /uniFB01nal studyyears are from 2001 to 2017, giving 1785 possible data points forKansas (17 years by 105 counties) and 1139 for Northern Texas(17 years by 67 counties). Counties with relatively small harvestedareas may be combined by the NASS in the statistical record and are notuseful for county-level analysis. As result, the county-level statisticsare not available for every county in every year, and the actual numbersof county year combinations are 1641 for Kansas and 956 forNorthern Texas. The harvested acres were converted into the arealpercentage of winter wheat of each county. Then MOD13Q1 data cubesof each county were associated with the corresponding value of thewinter wheat percentage as pair of independent/dependent variables.For example, the 23 MOD13Q1 images from August 28th, 2000 toAugust 28th, 2001 clipped to county's boundary were associated withthe winter wheat percentage of the county in year 2001. The referencepercentage data along with the associated MOD13Q1 images were splitinto training (years 2001 –2016) and validation (year 2017) sets. Modelparameters (weights) were trained by the training set, and the valida-tion set was for network architecture searching and hyper-parameterselection to reduce over- /uniFB01tting. The network model was trained andtuned on per-county basis using the training set and the validation set,while the /uniFB01nal results of per-pixel classi /uniFB01cation maps were extractedfrom middle layer of the network (explained in Section 2.3 on whichevaluation was conducted. Therefore, the test set of this study was notsplit by year but included per-pixel winter wheat coverage of all years.2.2.3. USDA Cropland Data LayerThe Cropland Data Layer (CDL) was used as the reference data forpixelwise assessment. The CDL is raster, georeferenced, crop-speci /uniFB01cland-cover map created using satellite imagery and extensive agri-cultural ground truth by the USDA, NASS on an annual basis. Since2008, the CDL program has provided cropland area estimates and di-gital products of spatial distribution at resolution of 30 for all statesin the continental US. Kansas has two more years of state-level coverageat resolution of 56 prior to the full CDL of the continental US, andthe record of Kansas CDL starts from 2006. The CDL was acquired in theAlbers equal-area conic projection speci /uniFB01ed by the USDA for contiguousUS. Each pixel of the CDL is identi /uniFB01ed as one of the 131 crop-speci /uniFB01cland-cover classes. Beginning in 2008, the CDL also includes per-pixelpredicted con /uniFB01dence of the given classi /uniFB01cation, with being the leastcon/uniFB01dent and 100 the most con /uniFB01dent. The con /uniFB01dence value is percentmeasure of how well the decision to identify pixel as speci /uniFB01c ca-tegory /uniFB01ts the rules in the decision tree classi /uniFB01er that was used toproduce the CDL Boryan et al., 2011 ).All land-cover classes of the CDL containing winter wheat werecombined and extracted: winter wheat (single crop), double crop winterwheat/soybeans, double crop winter wheat/corn, double crop winterwheat/sorghum, and double crop winter wheat/cotton. All the doublecrop classes consist of winter wheat and summer crop. The producer'saccuracy of winter wheat in the Kansas CDL ranges between 88% and96%, and the user's accuracy between 91% and 96% as reported in themetadata of the CDL. Compared to harvested acres of winter wheat inthe statistics from survey or census, the winter wheat area estimated bythe Kansas CDL is larger by ~6% with inter-annual variance. The ac-curacy of winter wheat in the CDL of Texas is lower. The self-reportedproducer's accuracy varies from 87% to 93%, and the user's accuracyfrom 82% to 91%. In Northern Texas the winter wheat area of the CDLis 155% higher on average (from 59% to 249%) than the survey/censusstatistics.The winter wheat pixels of the 30 CDL were re-projected to theprojection of the MOD13Q1 product and aggregated to the 250 mfootprint. During aggregation, the binary raster of winter wheat andother land-cover were converted into the winter wheat coverage of eachMODIS pixel in percentage. When available, the con /uniFB01dence layer wasalso employed to extract high-con /uniFB01dence pixels at 250 resolution byaveraging 30 con /uniFB01dence values of winter wheat within each 250 mfootprint (other land-cover types were set to zero, and more details areinSection 2.4 ). For Kansas the processed CDL is available annually from2006 to 2017, and for Northern Texas from 2008 to 2017. High-con-/uniFB01dence pixels are from 2008 to 2017 for both the study areas. In ourexperiment the CDL was only used to test mapping results. Informationat the pixel level from the CDL was not fed into the classi /uniFB01cation modelsduring the training process.2.3. Classi /uniFB01cationAs one of the most prominent characteristics of crops, the seasonaldynamics of vegetation index are the basis of crop classi /uniFB01cation studiesas well as the driver of temporal representation method development(Zhong et al., 2019 ). Di/uniFB00erent crops exhibit di /uniFB00erent temporal pro /uniFB01lesof phenology as manifested in the NDVI Jakubauskas et al., 2001 ).Winter wheat has distinct crop calendar from other major crops in theCentral US and NDVI values at some point during the growing seasonhave been reported to be separable Wardlow and Egbert, 2008 ). Theshape of the NDVI temporal trajectories can be used to /uniFB00ectivelyidentify winter wheat Shao et al., 2010 ). To quantitatively characterizewinter wheat seasonality, methods have been developed to derivephenological metrics as the input to classi /uniFB01cation algorithms Howardand Wylie, 2014 ). major source of uncertainty in phenology-basedclassi /uniFB01cation is the inter-annual and inter-regional variability of cropprogress and conditions, which is usually addressed by supervisedlearning using training statistics from widely-distributed ground sam-ples or existing land use maps across years and areas.Unlike traditional supervised classi /uniFB01cation /uniFB00orts that use pixel-level or object-level ground reference data for training, our mappingstudy only employed county-level statistics which do not provide de-tailed spatial information at the resolution of the input imagery. Wedesigned deep learning models with specialized architectures to directlyestablish relationship between remotely-sensed images and winterwheat percentage. The model input is an NDVI cube in the shape ofwidth byheight by 23, and the model output is single value. Becausethe input dimension is high, it is infeasible to train traditional algo-rithms with only 1641 (Kansas) or 956 (Northern Texas) samples.The general architecture of our models consists of convolutionallayer(s) and/or other functional layers followed by global averagelayer. Convolution can be along the spatial dimensions (width andheight) and/or the temporal dimension. For /uniFB02exibility the im-plementation of 3-dimensional convolutional layers (Conv3D) wasused. When the kernel sizes of both the spatial dimensions are one,Conv3D is equivalent to one-dimensional convolution in the temporaldomain. When all the three kernel sizes are larger than one, spatio-temporal convolution is applied. The global average layer is the lastlayer of the model which reduces the incoming matrix to scalar bytaking the average. The models were designed in way that the shapeof the incoming matrix is width byheight and values in the matrix arebetween and 1. By such settings, the incoming matrix to the globalaverage layer can be considered as land cover map in which the valueof each pixel represents the percentage of certain type. After themodel is fully trained, the global average layer can be removed, and theremaining sub-model will output land cover maps at the same resolu-tion as the input MODIS images.There are many forms of Conv3D layers and other units as thecandidate components of deep models. Because of the versatility of theL. Zhong, et al. 5HPRWH6HQVLQJRI(QYLURQPHQWspecialized architectures, there is no standard procedure to search forthe optimal combination of hyper-parameters and various types oflayers. In this study, the implementation of Conv3D was combined withpooling layers and dropout. variety of units and techniques weretested but not selected in the /uniFB01nal network, for example, batch nor-malization Io/uniFB00e and Szegedy, 2015 and inception modules Szegedyet al., 2015 ). Various kernel sizes (window widths) of Conv3D layerswere tested. Kernels for the spatial dimension are either 1-by-1 (tem-poral convolution only) or 3-by-3. We did not try larger spatial sizesbecause stacking multiple small-kernel layers is more computationale/uniFB03cient way to enlarge the receptive /uniFB01eld Simonyan and Zisserman,2014 ). Similarly, the kernel size in the temporal domain was /uniFB01xed to 3,except the last Conv3D layer in the model in which the kernel size isexactly the temporal length of the input so that the output length isreduced to one in the temporal dimension. The last Conv3D layer alsoutilizes sigmoid activation function to output values strictly between0 and as the crop cover percentage, unlike other Conv3D layers withReLU (Recti /uniFB01ed Linear Unit) as the activation function. MultipleConv3D layers could be stacked to learn temporal/spatial features in ahierarchical manner. The /uniFB01rst Conv3D layer has 4, 8, or 16 channels//uniFB01lters and the channel number may increase when going deeper.Pooling layers were /uniFB01xed as max-pooling with window size of alongthe temporal dimension. The use of max-pooling is to reduce the sen-sitivity to small shifts in crop phenology. No pooling is performed in thespatial dimensions and the spatial resolution of the input images is keptthroughout the model. Dropout is regularization technique that ran-domly drops some neurons in layer during training so that the outputof the layer does not rely on only few neurons Srivastava et al.,2014 ). The probability of dropping neurons was set to 20%, 30%, 40%,or 50%.As result, there are an extremely large number of potential net-work architectures and it is impossible to try them all. The selection ofhyper-parameters was conducted step by step based on experience andthe performance on the validation set. While the training set (years2001 –2016) was used to train network parameters (weights), the vali-dation set (year 2017) was for the selection of network architecturesand hyper-parameters. We started with small model with only onelayer of convolution along the temporal dimension, which is equivalentto per-pixel linear regression using the 23 values in the NDVI timeseries, the simplest learning approach. Then we generated new modelsby changing one or two hyper-parameters, adding new layer, re-or-dering layers, or replacing part of the network with more complexcomponent. Among the new models, models with promising perfor-mance on the validation set were used as the seeds to begin new roundof searching. In this way, the tested model grew in size and complexityuntil classi /uniFB01cation results did not improve further.All the three types of ANNs were trained using the Adam optimizer(Kingma and Ba, 2014 ). Parameters of Adam were /uniFB01xed as: β1= 0.9,β2= 0.999, ε= 1e −07, and learning rate decay of 0.001. The initiallearning rate was set to 0.001 and the batch size was set to 4. Mean-squared-error was used as the loss function to represent the di /uniFB00erencebetween reference and predicted winter wheat coverage. Modeltraining continued until the loss on the validation set stopped de-creasing. Classi /uniFB01cation models were built and evaluated using the Keraslibrary WWW3, n.d. on top of Tensor /uniFB02ow (WWW4, n.d. ).2.4. EvaluationWhile the training process is at the county level using county sta-tistics as the input data, model evaluation is pixelwise because the mainobjective of this study is to map crop coverage at the resolution of theinput imagery. We /uniFB01rst performed wall-to-wall assessment for each ofthe study areas using the CDL. The CDL was not used as ideal groundreference for both study areas. For Kansas the CDL is considered as areliable reference for accuracy assessment because the self-reportedaccuracy of the Kansas CDL is high and the total winter wheat acreageof the CDL is very close to the NASS statistics. As for Northern Texas,the total winter wheat acreage of the CDL is 155% larger than thestatistics on average and the self-reported accuracy of the Texas CDL isnot as high as Kansas, and so the assessment using the CDL can be seenas pixel-wise comparison between the CDL and the winter wheat mapsderived only from the NASS statistics. Winter wheat coverage was ca-tegorized as “winter wheat ”or“other ”pixels using the majority rule.Metrics including the overall accuracy, the producer's accuracy, theuser's accuracy, and the F1 score were reported. The overall accuracy isin/uniFB02ated as the dataset is very unbalanced with much more non-winter-wheat areas than winter wheat, and it is reported only to provide ageneral measure of areal assessment. The F1 score is the harmonic meanof the producer's accuracy and the user's accuracy:=+=/uni2219+()FAAAA11 2wheatAAprod userprod user 1211prod userwhere F1wheat is the F1 score of the winter wheat class, Aprodis theproducer's accuracy of the class, and Auseris the user's accuracy of theclass.As classi /uniFB01cation product, the CDL is subject to errors especially forthe Northern Texas site where severe overestimation occurs.Furthermore, there is spatial uncertainty when aligning the CDL and theMOD13Q1 footprints to aggregate the CDL pixels into the 250-m re-solution. We tested the sensitivity of classi /uniFB01cation accuracy to footprintalignment by adding half-pixel shift (~115 m) to the MOD13Q1footprints and comparing the shifted 250-m CDL to the same CDL ag-gregated without any shift. In all study years, the overall accuracyranged from 0.917 to 0.956, and the producer's/user's accuracy from0.742 to 0.838. The producer's accuracy is equal to the user's accuracybecause the comparison was between two identical maps with di /uniFB00erentspatial aggregation. The results of the sensitivity test suggest that theimpact of possible spatial uncertainty on accuracy assessment is notnegligible. To reduce the in /uniFB02uence of reference data error and spatialuncertainty during aggregation, we extracted very pure and high-quality pixels to conduct small-set assessment by using the con /uniFB01dence(0 to 100) raster associated with CDLs since 2008. The con /uniFB01dence rasterof each CDL was also aggregated into the 250-m footprints using themean value of winter wheat areas. 250-m pixel is considered as high-con/uniFB01dence winter wheat if pixels in its 3-by-3 neighborhood havewinter wheat con /uniFB01dence values larger than 90, and is considered ashigh-con /uniFB01dence other land covers if the con /uniFB01dence values of its 3-by-3neighborhood pixels are zero. About 10% of the 250 winter wheatpixels were treated as high-con /uniFB01dence pixels. The small set of high-con/uniFB01dence pixels separates other factors from inherent model errorsand provides more reliable measures on the classi /uniFB01cation performanceof the model. The same set of metrics as the wall-to-wall comparisonwas reported for the “high-con /uniFB01dence pixel only ”evaluation.3. Results3.1. Model architectureWe selected two models for each study area according to the bestresults on the validation set: one model with temporal convolution only(which means the kernel sizes of Conv3D layers in the spatial dimensionare always 1-by-1), and the other with convolution in both spatial andtemporal dimensions. The former model only utilizes information in thetemporal dimension or seasonality in the NDVI time series to identifywinter wheat, while the latter considers additional spatial patterns of/uniFB01elds in classi /uniFB01cation. The di /uniFB00erence between the two models was usedto evaluate the contribution of spatial information to classi /uniFB01cation re-sults. The two models are named as “temporal-only ”and “spatio-temporal ”, respectively. The selected model architectures are identicalbetween the study areas. The temporal-only model has two temporalconvolution layers, followed by max-pooling along the temporalL. Zhong, et al. 5HPRWH6HQVLQJRI(QYLURQPHQWFig. 2. Architecture of the temporal-only model. Small cubes represent convolutional kernels with kernel sizes labeled inside. Data dimensions are labeled on the top.Fig. 3. Architecture of the spatiotemporal model. Small cubes represent convolutional kernels with kernel sizes labeled inside. Data dimensions are labeled on the top.L. Zhong, et al. 5HPRWH6HQVLQJRI(QYLURQPHQWdimension, another two temporal convolution layers, dropout, con-volution layer that shrinks the temporal length to one, and /uniFB01nally aglobal average operation Fig. ). The architecture is fully-convolu-tional that reduces the input dimension of width -by-height -by-23to awidth -by-height -by-1map and then scalar regardless of the actualvalues of width and height The activation function of convolutionallayers is ReLU, except the last convolutional layer that uses the sigmoidactivation function so that values in the width -by-height -by-1map arebetween and 1.The spatiotemporal architecture is very similar to the temporal-onlymodel. The types and the order of layers follow the same logic Fig. ).The di /uniFB00erences of the spatiotemporal model are: i) the spatiotemporalconvolutional layers have kernel size of 3-by-3-by-3, ii) padding withthe same values at the edge was applied, so that the input size does notdecrease after convolution, and iii) the number of channels in eachConv3D layer is smaller (4 or 6) than the temporal-only model (8 or16). By using smaller number of channels, replacing temporal-onlyconvolution with spatiotemporal convolution did not considerably in-crease the model complexity or the total number of weights. Thecomplexity of the models is suitable for the size of the dataset, andfurther adding more layers, more channels, or larger kernels worsenedthe training results.3.2. Winter wheat mapsA winter wheat map was produced for each combination of years(2001 –2017), study areas (Kansas and Northern Texas), and models(temporal-only and spatiotemporal). Maps since year 2006 (Kansas) or2008 (Northern Texas) were compared with the CDL. Fig. andFig. 6show the CDL winter wheat percentage at 250 and the resultant mapsfor the whole study areas in year 2016, in which the reported quality ofthe CDL is relatively high. Fig. andFig. provide zoom views of threesub-areas in each of the study area. In general, the spatial distributionsof winter wheat in the resultant maps by both models are consistentwith the CDL. Western and middle Kansas is intensively cultivated bysingle-cropping winter wheat with patterns following the terrain. In thesoutheast region of the state, the double-cropping type of winter wheatand summer soybean is common. Both the single- and double-croppingtypes were well depicted by the resultant maps. In Northern Texas, themajor areas of winter wheat were identi /uniFB01ed by the maps, but themapped coverage of winter wheat was apparently much lower than thatof the CDL. For both the study areas, compared to the winter wheatcover mapped by the temporal-only model, winter wheat pixels by thespatiotemporal model appear to be spatially agglomerated to formsmaller but denser clusters. The possible reason for the discrepancy isfurther discussed in later sections. Winter wheat maps of other yearswere also visually inspected, and the same patterns and issues werefound.3.3. Pixelwise accuracy assessmentTable andTable present the overall accuracy (OA), the produ-cer's accuracy (PA), the user's accuracy (UA), and the F1 score of winterwheat maps in Kansas and Northern Texas, respectively. These metricswere evaluated using the CDL as the reference data. For Kansas, thewinter wheat areas of the CDL are quite reliable as indicated by the highself-reported accuracies and the agreement with statistics from survey/census. In the wall-to-wall assessment (all pixels in the whole area wereused for accuracy assessment), the temporal-only model yielded 91.9%OA, 61.4% PA, 82.3% UA, and 0.702 F1 on average, while the resultsby the spatiotemporal model was poorer with 87.1% OA, 57.1% PA,58.8% UA, and 0.579 F1. When using only high-con /uniFB01dence pixels inassessment, all accuracies were much higher. The temporal-only modelgave 99.6% OA, 93.8% PA, 94.8% UA, and 0.942 F1, and the spatio-temporal model gave 99.3% OA, 92.5% PA, 88.5% UA, and 0.903 F1.As described in Section 2.4 high-con /uniFB01dence pixels were extracted byconsidering the con /uniFB01dence value provided by the CDL, the puritywithin each 250-m pixel, and the spatial neighborhood of the pixel. Themuch better results in the high-con /uniFB01dence-pixel-only assessment sug-gest that the discrepancy in the wall-to-wall assessment may be causedby the inherent uncertainty of the CDL, the mixed-pixel /uniFB00ect at the250-m resolution, and the uncertainty in the alignment of the CDL andthe MOD13Q1 pixel footprints.In general, for the study area of Kansas the winter wheat maps bythe deep models are comparable to the CDL at 250 resolution. Theclassi /uniFB01er of the CDL was trained by extensive ground reference data at30 resolution, and the Kansas CDL was reported to be one of the mostaccurate CDL products. Given that the deep models conducted mappingwithout using any pixel-level training data at much coarser 250 mresolution, the agreement between the CDL and the maps by the deepmodels looks quite promising. The deep learning approach shows agreat potential to produce maps for earlier years that are not covered bythe CDL (in this study, years from 2001 to 2005 or 2007) and for placeswhere there are no pixel-level ground samples available but only sta-tistical data.As for the winter wheat maps of Northern Texas, the UA is generallycomparable to that of Kansas, but the PA is much lower. In the wall-to-wall assessment, the average PA is 28.8% by the temporal-only modeland 34.7% by the spatiotemporal model. Even using high-con /uniFB01dencepixels for assessment, the PA values increased to only 56.7% and56.2%, respectively. The low PA is consistent with the visual inspectionin which apparent omission of winter wheat was found. The mainpurpose of the study in Northern Texas is to generate winter wheatmaps that are consistent with the statistics and compare with the CDL tounderstand the spatial distribution of the large di /uniFB00erences between theNASS statistics and the CDL. The lower accuracies evaluated using theCDL are expected when selecting the study area.The comparison between the two deep models suggests that in bothKansas and Northern Texas the spatiotemporal model is inferior to thetemporal-only model. The use of spatial convolution resulted in parti-cularly lower UA. The spatiotemporal model utilizes textural and con-textual information in addition to the temporal patterns used by thetemporal-only model, but the additional spatial information contributesnegatively to the pixelwise accuracy. In the next section, we will furtherconsider the agreement with statistical data and continue discussing thepossible reason.3.4. Areal comparisonTo further analyze the uncertainty in the mapping process, themapped winter wheat areas were compared with the USDA statistics.The USDA statistics from censuses and surveys are usually recognized asa reliable data source of crop cultivation. Fig. andFig. present thewinter wheat acreage from the USDA statistics, the CDL, the map by thetemporal-only model, and the map from the spatiotemporal model forKansas and Northern Texas, respectively. The winter wheat areas ofmaps were calculated using the winter wheat percentage of 250 mpixels. For Kansas, the total winter wheat acreage of the CDL agreeswell with the statistics. The percentage di /uniFB00erence in most years is lessthan 5.0%, the maximum di /uniFB00erence (in 2013) is 10.1%, and the MeanAbsolute Percentage Error (MAPE) is 3.6%. The temporal-only modelresulted in 13.0% maximum di /uniFB00erence (in 2014) and 6.8% MAPE, andthe spatiotemporal model resulted in 12.1% maximum di /uniFB00erence (in2014) and 6.4% MAPE. The annual trends of winter wheat acreage fromthe results of the deep models are consistent with the statistics and theCDL.In the pixelwise accuracy assessment, the spatiotemporal modelresulted in much lower user's accuracy than the temporal-only model(58.8% vs 82.3% in the wall-to-wall assessment, and 88.5% vs 94.8% inthe high-con /uniFB01dence-pixel-only assessment). However, the total winterwheat acreage mapped by the spatiotemporal model has the same levelof agreement with the statistics as the temporal-only model, if notL. Zhong, et al. 5HPRWH6HQVLQJRI(QYLURQPHQWbetter than. When inspecting the map details like Fig. , we found thatthe parcels mapped by the spatiotemporal model were consistent withthe spatial pattern of the CDL, but the parcel extent did not align wellwith the CDL. The mapped winter wheat pixels show an “agglomer-ated”pattern with small and dense clusters, which is likely to be causedby the use of spatial convolution. The spatiotemporal model includes 4layers of 3-by-3 spatial convolution, and pixel in the /uniFB01nal map has areceptive /uniFB01eld corresponding to 9-by-9 window in the input images.In this study we aimed to explore the possibility of training classi /uniFB01ca-tion models without pixel-level reference data. As result, pixel-levelspatial constraints were not implemented in the loss function of thespatiotemporal model, and the information carried by pixel in theinput images might “drift”to any place within the 9-by-9 receptive /uniFB01eldrather than the middle point of the receptive /uniFB01eld. The spatiotemporalmodel can utilize spatial information to improve the estimate of overallcoverage, but the exact locations of the mapped pixels may be in-accurate. To bene /uniFB01t from the advantage of spatiotemporal convolution,at least small set of pixel-level reference data is still needed to tune themodel to learn the exact locations of the crop pixels and reduce the“pixel drift ”e/uniFB00ect.For Northern Texas, the winter wheat acreage of the CDL is knownto be much larger than that of the NASS statistics. As the maps pro-duced by the deep models are completely trained with statistical datarather than ground samples, they are able to ensure consistency withFig. 4. Winter wheat cover of the CDL aggregated to 250 (a) and winter wheat fuzzy maps produced by the temporal-only model (b) and the spatiotemporal model(c) for Kansas in year 2016. Squares show the extent of the zoom views in Fig. .L. Zhong, et al. 5HPRWH6HQVLQJRI(QYLURQPHQWthe NASS statistics Fig. ). The percentage di /uniFB00erence of the CDL fromthe statistics could be as large as 248.6% (in 2013), and the MAPE is155.2%. The temporal-only model resulted in 12.5% MAPE, the max-imum di /uniFB00erence is 33.2% (in 2008), and all di /uniFB00erences in years otherthan 2008 are around or lower than 15%. The spatiotemporal modelresulted in 14.9% MAPE, and the maximum di /uniFB00erence is 27.0% (in2011). Traditional classi /uniFB01cation algorithms are mostly trained andevaluated with pixel-level reference data (like the CDL using groundFig. 5. Zoom views for the comparison between the CDL and the resultant maps of Kansas in 2016 in three sub-areas. Column (a) includes the CDL winter wheatpercentage aggregated to 250. Columns (b) and (c) are 250 winter wheat percentage maps by the temporal-only and the spatiotemporal models, respectively. Theextents of the three sub-areas are highlighted by the squares in Fig. .Fig. 6. Winter wheat cover of the CDL aggregated to 250 (a) and winter wheat fuzzy maps produced by the temporal-only model (b) and the spatiotemporal model(c) for Northern Texas in year 2016. Squares show the extent of the zoom views in Fig. .L. Zhong, et al. 5HPRWH6HQVLQJRI(QYLURQPHQWtruths reported by farmers), but the classi /uniFB01ers hardly enforce con-straints at regional level. As result, the ground samples used inclassi /uniFB01cation may not fully represent the data distribution of the wholearea and the total area from the classi /uniFB01cation products may di /uniFB00er fromthe regional statistics. By contrast, the proposed deep models are totallytrained with the regional statistics and the resultant maps are supposedto be consistent with the statistical data by nature. The deep modelframework is an /uniFB00ective approach to incorporate regional constraintsinto the classi /uniFB01cation process. The reason for the considerable dis-crepancy between the total acreage values of the CDL and the NASSstatistics in Northern Texas has not been thoroughly investigated, andthe maps produced by the deep models /uniFB00er an opportunity to conductlocal comparisons with the CDL to understand the spatial distribution ofthe di /uniFB00erences.Fig. 7. Zoom views for the comparison between the CDL and the resultant maps of Northern Texas in 2016 in three sub-areas. Column (a) includes the CDL winterwheat percentage aggregated to 250. Columns (b) and (c) are 250 winter wheat percentage maps by the temporal-only and the spatiotemporal models, respec-tively. The extents of the three sub-areas are highlighted by the squares in Fig. .Fig. 8. Winter wheat acreage of Kansas from the USDA statistics compared with mapped acreage by the CDL, the temporal-only model, and the spatiotemporalmodel, in 2006 –2017.L. Zhong, et al. 5HPRWH6HQVLQJRI(QYLURQPHQWIn summary, by conducting visual inspection, pixelwise accuracyassessment, and comparison with regional statistics, we see that thetemporal-only model successfully produced winter wheat maps usingonly county-level statistics as training data. In Kansas where the winterwheat extent of the CDL is relatively accurate, the resultant maps showgreat agreement with the CDL. In Northern Texas where the CDL con-siderably di /uniFB00ers from the NASS statistics, the use of the deep learningframework provides the possibility of generating winter wheat mapswith decent consistency with the statistics. The spatiotemporal modelresulted in reasonable patterns and regional estimates, but pixels in themap were subject to positional errors up to the size of the receptive /uniFB01eldin the current settings.4. Discussion4.1. Interpretation of model behaviorIn our mapping framework, the input of the model is 250-m NDVIimage series directly from the MOD13Q1 product, and the output iscounty-level statistics. There is an extremely large di /uniFB00erence in di-mensionality between the input and the output, which results in largeparameter space in the model, possible ill-posed problem, and achallenge to end-to-end learning. By designing specialized deep ar-chitecture consisting of multiple fully-convolutional layers, constraintson feature representation are placed to reduce the negative /uniFB00ect ofmodel complexity on generalization and overcome the problem of highdimensionality Zhang et al., 2018 ). The deep model in this study au-tomatically extracts features and builds pathway to connect each ofthewidth- by-height -by-date data cubes directly to scaler value in thestatistics. It is critical to examine the model details and investigate iffeatures are learnt reasonably along the pathway.One way to understand how multi-layer convolutional modelworks is to inspect the activation patterns on each convolutional layerby di /uniFB00erent inputs. The temporal-only model is used as the example todemonstrate the internal model behavior because i) the model resultedin good pixelwise accuracy, and ii) visualization of only temporalconvolution operations is relatively clear and straightforward withoutbeing /uniFB00ected by high-dimensional data structures and graphs. We vi-sualized the activation of input NDVI series on various layers usingdeconvolution and guided back-propagation Zeiler and Fergus, 2014 ),and the visualization of three pixels in 2017 is presented as an example(Fig. 10 ). Two of the NDVI pro /uniFB01les are from winter wheat pixels, andthe third one is canola (Column “input series ”,Fig. 10 ). The land usetypes are from the CDL in 2017, which were correctly classi /uniFB01ed by thetemporal-only model as winter wheat or non-winter-wheat. The seriesof the two winter wheat pixels are di /uniFB00erent, and their average (thedashed line in the third plot of input series) is very close to the canolaseries (solid line). Such intra-class heterogeneity and inter-classsimilarity are often the sources of mis-classi /uniFB01cation, so we chose thethree pixels as an example to investigate how the deep model distin-guishes varying temporal patterns.By using the approach of guided back-propagation, the activation oneach channel can be attributed to individual time steps in the inputseries to highlight which part of the series activates the channel. In thecolumns of convolutional layers in Fig. 10 the activations are shown bythe brightness of the time steps. bright dot means the channel isstrongly activated by the time step, and dark one means weak acti-vation. In the /uniFB01rst convolutional layer, all the three series activate outof the channels, and all the time steps contribute almost equally to thestrength of the activation. This is expected because earlier layers in adeep model are used to capture local and basic patterns that might bepresent throughout the whole input. The activation pattern on thesecond convolutional layer is similar, except that the contributions bydi/uniFB00erent dates start to vary and the three series start to show disparateactivations (like Channel #6). In the third and the fourth convolutionallayers, each channel responds to more complex patterns. Some channelsare only activated by one series but not others, for example, Channels#3, #13, and #15 in the fourth layer. By recognizing complex patterns,the model starts to have the ability to distinguish the three series, butthe activations by the same type are not necessarily similar. The lastconvolutional layer summarizes patterns learnt in the previous layerusing single channel. The increasing slope in the /uniFB01rst series and thetwo peaks and one slope in the second series strongly activate thechannel, and then the two series are identi /uniFB01ed as winter wheat. Theactivation by the third series is much weaker, and thus the canola pixelis not classi /uniFB01ed as winter wheat. Although the dual-peak pro /uniFB01le of thecanola pixel is very close to the average of the two winter wheat series,the activation pattern in some channels of later convolutional layers iscompletely di /uniFB00erent. By inspecting the activations on later layers, wesee that similar series may follow distinct paths of channel activationthrough the model, which /uniFB00ers the ability to fully utilize complexpatterns to capture seasonality information in the NDVI series. Thepatterns learnt by the deep architecture provide su /uniFB03cient degree ofmodel variance to account for the complexity in winter wheat growth,and all the patterns are completely trained by only county-level sta-tistics.When using the deep model for mapping, it is essential to under-stand whether the trained network recognizes di /uniFB00erent winter wheatpatterns across years, or just relies on constant temporal patterns acrossyears and captures inter-annual variability by coincidence underchanging conditions like traditional manual approaches. We exploredthe model capability of recognizing varying patterns using the Kansasresults by the temporal-only model, for which reliable CDL data areavailable for assessment and the pixelwise accuracy is high. The tem-poral NDVI pro /uniFB01les of classi /uniFB01ed winter wheat pixels could be quitedi/uniFB00erent across years. For example, Fig. 11 presents the median timeFig. 9. Winter wheat acreage of Northern Texas from the USDA statistics compared with mapped acreage by the CDL, the temporal-only model, and the spatio-temporal model, in 2008 –2017.L. Zhong, et al. 5HPRWH6HQVLQJRI(QYLURQPHQWFig. 10. Three NDVI series in solid lines and their activation patterns on all the convolutional layers of the temporal-only model. The /uniFB01rst two NDVI pro /uniFB01les are from winter wheat pixels, and the third one is canola but isvery similar to the average of the /uniFB01rst two which is plotted in dashed line. The x-axis (date axis) is consistent with Fig. 11 andFig. 12 The /uniFB01ve convolutional layers can be found in the architecture of the temporal-onlymodel Fig. ), with 8, 8, 16, 16, and channel(s), respectively. Channel numbers starting from zero are labeled on the upper left corner of each channel. The activation by individual time steps on the /uniFB01ve layers wascalculated by deconvolution and guided back-propagation. NDVI values at di /uniFB00erent time steps are shown by dots, and the brightness of dots represent the strength of the activation by the current time step. Classi /uniFB01eradaptation for inter-annual variability.L. Zhong, et al. 5HPRWH6HQVLQJRI(QYLURQPHQWseries (blue and orange lines) and the 20% –80% ranges (blue and or-ange shaded areas) of winter wheat pixels mapped for years 2012 and2013, respectively. According to the USDA weekly crop progress reports(WWW5, n.d. ), in Kansas the year 2012 has the earliest winter wheatprogress, and 2013 is one of the latest among recent years. The dif-ference in the “headed ”stage between the two years is as large as aboutone month, and the NDVI ranges have small overlaps. The dates of theNDVI peaks in Fig. 11 are consistent with the reports, showing that thedistinct temporal patterns of the two years were /uniFB00ectively learnt bythe statistics-based classi /uniFB01er. Similarly, Fig. 12 demonstrates the inter-annual variability resulted by crop conditions. NDVI in 2010 is muchhigher than 2006 during the peak season and lower in winter. Ac-cording to the USDA weekly reports, the percentage of Kansas winterwheat that was in “good ”or“excellent ”conditions was over 55% at theharvest time in 2010, but only about 20% in 2006. Compared to thetraditional approach of manually building and selecting features orrules to account for possible changes under various circumstances, end-to-end learning with deep models is more /uniFB03cient way to generalizethe variability in phenology, crop conditions, and agricultural practicesin the study area across years.4.2. Applicability of the statistics-based mapping approachThe main objective of our study is to show the possibility of gen-erating maps solely from regional statistics using deep neural networks.The method would be useful when ground samples are unavailable, forexample, to /uniFB01ll the historical gaps of the CDL or to create maps forcountries using published statistical data. While ground references areFig. 11. Time series plots of winter wheat pixelsclassi /uniFB01ed by the temporal-only model in Kansas,2012 and 2013. The winter wheat progress in 2012was earlier than average while 2013 was later. Solidlines represent the median NDVI values of winterwheat pixels. Shaded areas show the ranges betweenthe 80% and the 20% percentiles. (For interpretationof the references to color in this /uniFB01gure, the reader isreferred to the web version of this article.)Fig. 12. Time series plots of winter wheat pixelsclassi /uniFB01ed by the temporal-only model in Kansas,2006 and 2010. The crop condition around the har-vest time in 2010 was much better than 2006. Solidlines represent the median NDVI values of winterwheat pixels. Shaded areas show the ranges betweenthe 80% and the 20% percentiles.L. Zhong, et al. 5HPRWH6HQVLQJRI(QYLURQPHQWTable 1Evaluation metrics of winter wheat maps in Kansas.Wall-to-wall assessment High-con /uniFB01dence-pixel-only assessmentTemporal-only model Spatiotemporal model Temporal-only model Spatiotemporal modelOverallaccuracyProducer'saccuracyUser'saccuracyF1 score OverallaccuracyProducer'saccuracyUser'saccuracyF1 score OverallaccuracyProducer'saccuracyUser'saccuracyF1 score OverallaccuracyProducer'saccuracyUser'saccuracyF1 score2006 92.2% 65.6% 81.9% 0.729 87.8% 61.0% 61.9% 0.6142007 91.7% 61.6% 81.9% 0.703 86.3% 55.7% 57.2% 0.5642008 90.9% 54.2% 84.9% 0.661 87.0% 57.0% 61.1% 0.590 99.4% 92.1% 98.2% 0.950 99.3% 92.6% 95.7% 0.9412009 91.3% 61.0% 79.8% 0.691 87.1% 58.8% 60.0% 0.594 99.6% 94.9% 98.5% 0.966 99.5% 94.4% 97.6% 0.9602010 93.2% 63.9% 86.6% 0.735 88.6% 59.8% 62.0% 0.609 99.9% 96.0% 95.6% 0.958 99.8% 97.0% 88.3% 0.9242011 92.2% 59.1% 84.7% 0.696 87.4% 54.2% 59.5% 0.567 99.6% 94.5% 97.6% 0.960 99.3% 92.1% 91.8% 0.9202012 91.6% 65.4% 80.2% 0.720 86.0% 58.8% 57.5% 0.581 99.3% 87.7% 93.3% 0.904 98.5% 86.3% 77.4% 0.8162013 90.8% 56.1% 83.4% 0.671 84.9% 50.5% 55.0% 0.527 99.6% 92.0% 96.9% 0.944 99.2% 90.2% 90.4% 0.9032014 91.1% 54.0% 80.5% 0.646 87.4% 56.7% 58.6% 0.576 99.7% 92.4% 79.7% 0.856 99.7% 88.2% 78.9% 0.8332015 90.9% 58.7% 79.9% 0.677 86.7% 55.8% 59.5% 0.576 99.5% 94.1% 96.7% 0.954 99.4% 92.9% 95.2% 0.9412016 93.0% 67.6% 82.6% 0.743 87.4% 58.0% 58.0% 0.580 99.8% 97.3% 97.0% 0.972 99.4% 95.4% 89.4% 0.9232017 93.9% 70.0% 80.6% 0.749 88.5% 59.3% 55.3% 0.572 99.8% 96.7% 94.3% 0.955 99.4% 95.9% 79.7% 0.870Average 91.9% 61.4% 82.3% 0.702 87.1% 57.1% 58.8% 0.579 99.6% 93.8% 94.8% 0.942 99.3% 92.5% 88.5% 0.903Table 2Evaluation metrics of winter wheat maps in Northern Texas.Wall-to-wall assessment High-con /uniFB01dence-pixel-only assessmentTemporal-only model Spatiotemporal model Temporal-only model Spatiotemporal modelOverallaccuracyProducer'saccuracyUser'saccuracyF1 score OverallaccuracyProducer'saccuracyUser'saccuracyF1 score OverallaccuracyProducer'saccuracyUser'saccuracyF1 score OverallaccuracyProducer'saccuracyUser'saccuracyF1 score2008 91.7% 29.1% 88.3% 0.437 91.6% 35.8% 75.6% 0.486 98.2% 68.9% 99.8% 0.815 97.8% 61.9% 99.6% 0.7632009 89.8% 23.4% 88.3% 0.370 89.7% 27.6% 75.8% 0.404 95.5% 54.8% 99.9% 0.708 95.4% 54.3% 99.8% 0.7032010 93.4% 46.9% 83.7% 0.601 92.6% 53.8% 70.2% 0.609 99.0% 85.5% 99.1% 0.918 98.7% 81.6% 98.6% 0.8932011 92.7% 20.1% 80.0% 0.322 92.6% 28.1% 66.4% 0.395 99.3% 43.7% 91.5% 0.592 99.3% 47.5% 88.1% 0.6172012 91.4% 26.4% 70.3% 0.384 91.3% 35.9% 62.7% 0.457 98.2% 33.1% 95.9% 0.492 98.6% 50.4% 91.6% 0.6512013 90.7% 22.0% 83.4% 0.348 90.4% 25.9% 70.8% 0.379 98.9% 48.5% 97.4% 0.648 98.8% 43.0% 95.9% 0.5942014 90.7% 17.4% 82.9% 0.287 90.6% 22.8% 68.7% 0.342 98.7% 41.5% 98.9% 0.585 98.5% 39.4% 93.2% 0.5542015 91.9% 35.2% 77.7% 0.484 91.4% 40.9% 67.0% 0.508 96.5% 68.2% 99.6% 0.810 96.1% 64.4% 99.6% 0.7822016 93.1% 39.4% 80.9% 0.530 92.3% 45.0% 67.1% 0.539 99.0% 73.5% 96.4% 0.834 98.8% 67.5% 96.3% 0.7942017 91.8% 28.3% 72.6% 0.407 91.5% 31.4% 64.5% 0.423 98.7% 49.8% 93.2% 0.649 98.7% 51.8% 95.0% 0.671Average 91.7% 28.8% 80.8% 0.417 91.4% 34.7% 68.9% 0.454 98.2% 56.7% 97.2% 0.705 98.1% 56.2% 95.8% 0.702L. Zhong, et al. 5HPRWH6HQVLQJRI(QYLURQPHQWlimited by the di /uniFB03culty and the cost of data collection, statistics pub-lished by many institutes have long record length and broad spatialcoverage. Although there are far fewer details in the county statisticsthan in the ground samples, in the experiment the maps generated fromcounty statistics are consistent with the crop coverage developed bypixel-level supervised classi /uniFB01cation and many ground samples as longas the statistics agree well with the pixel-based classi /uniFB01cation map.When the statistics disagree with the existing crop maps as in the case ofNorthern Texas, it is often hard to locate and understand the source ofdiscrepancy because the two datasets cannot be directly compared at adetailed spatial level. The training samples of the pixel-based classi /uniFB01-cation maps may not represent the overall distribution of the wholeregion of statistics. The proposed method can produce maps consistentwith the statistics without being /uniFB00ected by the disparate distributionof ground samples or existing classi /uniFB01cation maps, which provides aunique opportunity to inspect the di /uniFB00erences between existing statisticsand classi /uniFB01cation maps using the statistics-derived map as bridge.As an initial experiment based on MODIS imagery, the resultantmaps are subject to the limitation of 250 resolution and other factors,as indicated by existing MODIS-based crop classi /uniFB01cation /uniFB00orts(Doraiswamy et al., 2007 ;Wardlow and Egbert, 2008 ;Shao et al.,2010 ). To simplify the model architecture and reduce the computa-tional cost, only the time series of one index (NDVI) was used, whichlimited the multi-spectral information for crop classi /uniFB01cation. The sta-tistics-based approach is applicable only when the input time series andbands can also identify the crop type of interest with pixel-level re-ference data.The use of the global average pooling layer in the proposed modelfocuses on the estimation accuracy at the county level but not for eachindividual pixel. By training the model with many combinations ofcounties and years, the model has to successfully predict the crop coverat the pixel level to always agree with the statistics for all combinationsrather than just manufacturing coincidences at the county level.Furthermore, we visualize the activations on di /uniFB00erent layers of the deepmodel to show how the proposed architecture captures seasonality in ahierarchical manner. The use of sigmoid activation between and onthe last convolutional layer and the global average pooling layer en-sures that the values in the resultant maps are physically reasonable.The mapping and inspection results suggest that the model trained withstatistics really learns how to recognize the time series of winter wheat.4.3. tunable and extensible deep learning framework for mappingThe deep learning based approach proposed in this study creates anew type of mapping tasks that directly utilize statistics in supervisedclassi /uniFB01cation. The framework is highly /uniFB02exible, which can be extendedto incorporate more types of statistical data in crop mapping and otherremote sensing applications. To improve crop mapping, commodityproduction and trade data from agricultural commissioners of in-dividual counties can be linked to the fully convolutional network. Datarelated to agricultural activities such as water use (like delivery to ir-rigation districts) and pesticide use (an example is California PesticideInformation Portal, WWW6, n.d. can formulate additional constraintson the network. Furthermore, the framework is potentially useful in avariety of mapping tasks for combined use of regional statistics andpixelwise data, as long as the variable of interest is relevant to remotesensing observations to some extent. For example, the study that dis-aggregates population from administrative districts to pixels Stevenset al., 2015 may bene /uniFB01t from the automated deep learning based so-lution.When applying the deep network framework, regional statisticsmight be used as the sole source of training set, just like the presentstudy, or as supplementary data to enforce additional constraints on thenetwork. In the latter case, statistical data are combined with conven-tional pixelwise training samples to fully utilize all available datasources for model tuning. The framework is /uniFB02exible to have multiplesets of regional and pixel-level information simultaneously contributingto the loss function of the neural network model, which accounts forvarious factors in uniform way Jia et al., 2018 ). Conventional clas-si/uniFB01cation /uniFB00orts are often limited by the availability of ground samples,as ground data collection is expensive, time-consuming, or impossibleretrospectively for historical periods. Meanwhile, statistical records area rich source of accumulated domain knowledge, but it is pity thatstatistics have rarely been employed /uniFB00ectively in classi /uniFB01cation. Theuse of statistics in the deep learning framework provides an opportunityto reduce the dependency on ground reference samples and extendmapping studies to larger area, longer period, or broader scope ofapplications.5. ConclusionThis study used per-county statistics in 2001 –2017 to train deepmodels to produce winter wheat maps at the 250 resolution ofMODIS imagery. The training of the deep models did not require pixel-level reference data. The end-to-end framework of the fully-convolu-tional neural networks built data pathway from NDVI image series towinter wheat coverage at the county level, and winter wheat maps wereobtained from middle layer of the network. The proposed mappingapproach is highly automated and /uniFB03cient because i) the approachdoes not rely on pixel-level references from ground data collection, andii) the approach does not require manual feature engineering and se-lection but incorporates all inputs into deep model to recognizecomplex and changing patterns. The model architecture that employedpatterns in the temporal dimension successfully identi /uniFB01ed the seasonaldynamics of winter wheat. As the approach is able to produce mapsusing only statistical data as the training reference, the resultant mapspossess high consistency with the statistics compared to classi /uniFB01cationmaps trained by pixel-wise reference data. While this approach is va-luable for areas or periods without pixel-wise ground samples, the re-sultant maps can also be employed to inspect the possible discrepancybetween existing classi /uniFB01cation maps and regional statistics.Land use mapping using statistics as reference data is new type ofremote sensing classi /uniFB01cation task. With the development of deeplearning technology, it is possible to employ highly-specialized deepnetwork architecture to implement constraints from statistical data toregulate patterns learnt by the model and complete the task. This deeplearning based classi /uniFB01cation framework is very extensible thanks to the/uniFB02exibility of network architectures. The trained model can be tunedwith more statistical data in the future or from other areas to improvegeneralization, reduce the need of ground sample collection, and alle-viate the shortage of reference data in many tasks like historical map-ping. Disparate data sources including pixelwise references and statis-tics of various human activities can be incorporated into uniformframework to fully utilize all existing data. The new classi /uniFB01cation taskand the deep learning based solution are worth further exploration.AcknowledgementWe thank the anonymous reviewers for their careful reading of ourmanuscript and their insightful comments.ReferencesAllen, R.G., Tasumi, M., Trezza, R., 2007. Satellite-based energy balance for mappingevapotranspiration with internalized calibration (METRIC) —model. Journal ofIrrigation and Drainage Engineering-Asce 133, 380 –394.Audebert, N., Le Saux, B., Lefèvre, S., 2018. Beyond RGB: very high resolution urbanremote sensing with multimodal deep networks. ISPRS J. Photogramm. Remote Sens.140, 20 –32.Baret, F., Hagolle, O., Geiger, B., Bicheron, P., Miras, B., Huc, M., et al., 2007. LAI, fAPARand fCover CYCLOPES global products derived from VEGETATION: part 1: principlesof the algorithm. Remote Sens. Environ. 110, 275 –286.Bastiaanssen, W.G.M., Menenti, M., Feddes, R.A., Holtslag, A.A.M., 1998. remote sen-sing surface energy balance algorithm for land (SEBAL) —1. Formulation. J. Hydrol.L. Zhong, et al. 5HPRWH6HQVLQJRI(QYLURQPHQW213, 198 –212.Boryan, C., Yang, Z., Mueller, R., Craig, M., 2011. Monitoring US agriculture: the USDepartment of Agriculture, National Agricultural Statistics Service, cropland datalayer program. Geocarto International 26, 341 –358.Chen, X., Xiang, S., Liu, C.-, Pan, C.-, 2014b. Vehicle detection in satellite images byhybrid deep convolutional neural networks. IEEE Geosci. Remote Sens. Lett. 11,1797 –1801 .Chen, Y., Lin, Z., Zhao, X., Wang, G., Gu, Y., 2014a. Deep learning-based classi /uniFB01cation ofhyperspectral data. IEEE Journal of Selected Topics in Applied Earth Observationsand Remote Sensing 7, 2094 –2107 .Doraiswamy, P.C., Stern, A.J., Akhmedov, B. (2007). Crop classi /uniFB01cation in the U.S.Corn Belt using MODIS imagery, 809 –812.Fisher, J.B., Melton, F., Middleton, E., Hain, C., Anderson, M., Allen, R., et al., 2017. Thefuture of evapotranspiration: global requirements for ecosystem functioning, carbonand climate feedbacks, agricultural management, and water resources. Water Resour.Res. 53, 2618 –2626 .Guidici, D., Clark, M.L., 2017. One-dimensional convolutional neural network land-coverclassi /uniFB01cation of multi-seasonal hyperspectral imagery in the San Francisco Bay Area,California. Remote Sens. 9, 629 .Harou, J.J., Pulido-Velazquez, M., Rosenberg, D.E., Medellín-Azuara, J., Lund, J.R.,Howitt, R.E., 2009. Hydro-economic models: concepts, design, applications, and fu-ture prospects. J. Hydrol. 375, 627 –643.Howard, D.M., Wylie, B.K., 2014. Annual crop type classi /uniFB01cation of the US Great Plainsfor 2000 to 2011. Photogramm. Eng. Remote. Sens. 80, 537 –549.Hu, F., Xia, G., Hu, J., Zhang, L., 2015b. Transferring deep convolutional neural networksfor the scene classi /uniFB01cation of high-resolution remote sensing imagery. Remote Sens.7, 14680 –14707 .Hu, W., Huang, Y., Wei, L., Zhang, F., Li, H., 2015a. Deep convolutional neural networksfor hyperspectral image classi /uniFB01cation. Journal of Sensors 2015 .Io/uniFB00e, S., Szegedy, C., 2015. Batch Normalization: Accelerating Deep Network Training byReducing Internal Covariate Shift. arXiv preprint arXiv:1502.03167 .Irwin, E.G., Geoghegan, J., 2001. Theory, data, methods: developing spatially expliciteconomic models of land use change. Agric. Ecosyst. Environ. 85, –24.Jakubauskas, M.E., Legates, D.R., Kastens, J.H., 2001. Harmonic analysis of time-seriesAVHRR NDVI data. Photogramm. Eng. Remote. Sens. 67, 461 –470.Jia, X., Karpatne, A., Willard, J., Steinbach, M., Read, J., Hanson, P.C., et al., 2018.Physics Guided Recurrent Neural Networks for Modeling Dynamical Systems:Application to Monitoring Water Temperature and Quality in Lakes. arXiv preprintarXiv:1810.02880 .Kamp /uniFB00meyer, M., Salberg, A., Jenssen, R., 2016. Semantic Segmentation of Small Objectsand Modeling of Uncertainty in Urban Remote Sensing Images Using DeepConvolutional Neural Networks. pp. –9.Kandasamy, S., Baret, F., Verger, A., Neveux, P., Weiss, M., 2013. comparison ofmethods for smoothing and gap /uniFB01lling time series of remote sensing ob-servations —application to MODIS LAI products. Biogeosciences 10, 4055 –4071 .Kingma, D.P., Ba, J., 2014. Adam: Method for Stochastic Optimization. arXiv preprintarXiv:1412.6980 .Kussul, N., Lavreniuk, M., Skakun, S., Shelestov, A., 2017. Deep learning classi /uniFB01cation ofland cover and crop types using remote sensing data. IEEE Geosci. Remote Sens. Lett.14, 778 –782.Li, W., Fu, H., Yu, L., Gong, P., Feng, D., Li, C., et al., 2016. Stacked Autoencoder-baseddeep learning for remote-sensing image classi /uniFB01cation: case study of African land-cover mapping. Int. J. Remote Sens. 37, 5632 –5646 .Li, W., Fu, H., Yu, L., Cracknell, A., 2017a. Deep learning based oil palm tree detectionand counting for high-resolution remote sensing images. Remote Sens. .Li, Y., Zhang, H., Shen, Q., 2017b. Spectral –spatial classi /uniFB01cation of hyperspectral imagerywith 3D convolutional neural network. Remote Sens. 9, 67 .Lyapustin, A., Wang, Y., Xiong, X., Meister, G., Platnick, S., Levy, R., et al., 2014.Scienti /uniFB01c impact of MODIS C5 calibration degradation and C6 improvements.Atmospheric Measurement Techniques 7, 4353 –4365 .Lyu, H., Lu, H., Mou, L., 2016. Learning transferable change rule from recurrent neuralnetwork for land cover change detection. Remote Sens. 8, 506 .Lyu, H., Lu, H., Mou, L., Li, W., Wright, J., Li, X., et al., 2018. Long-term annual mappingof four cities on di /uniFB00erent continents by applying deep information learning methodto landsat data. Remote Sens. 10, 471 .Maggiori, E., Tarabalka, Y., Charpiat, G., Alliez, P., 2017. High-resolution aerial imagelabeling with convolutional neural networks. IEEE Trans. Geosci. Remote Sens. 55,7092 –7103 .Marcos, D., Volpi, M., Kellenberger, B., Tuia, D., 2018. Land cover mapping at very highresolution with rotation equivariant CNNs: towards small yet accurate models. ISPRSJ. Photogramm. Remote Sens. 145, 96 –107.Marmanis, D., Schindler, K., Wegner, J.D., Galliani, S., Datcu, M., Stilla, U., 2018.Classi /uniFB01cation with an edge: improving semantic image segmentation with boundarydetection. ISPRS J. Photogramm. Remote Sens. 135, 158 –172.Marsden, C., Nouvellon, Y., Laclau, J., Corbeels, M., McMurtrie, R.E., Stape, J.L., et al.,2013. Modifying the ′DAY process-based model to simulate the spatial variability ofEucalyptus plantation growth on deep tropical soils. For. Ecol. Manag. 301, 112 –128.Massey, R., Sankey, T.T., Congalton, R.G., Yadav, K., Thenkabail, P.S., Ozdogan, M., et al.,2017. MODIS phenology-derived, multi-year distribution of conterminous US croptypes. Remote Sens. Environ. 198, 490 –503.Monfreda, C., Ramankutty, N., Foley, J.A., 2008. Farming the planet: 2. Geographicdistribution of crop areas, yields, physiological types, and net primary production inthe year 2000. Glob. Biogeochem. Cycles 22, GB1022 .Mou, L., Zhu, X.X., 2018. RiFCN: Recurrent Network in Fully Convolutional Network forSemantic Segmentation of High Resolution Remote Sensing Images. arXiv preprintarXiv:1805.02091 .Mou, L., Bruzzone, L., Zhu, X.X., 2018a. Learning Spectral-Spatial-Temporal Features Viaa Recurrent Convolutional Neural Network for Change Detection in MultispectralImagery. arXiv preprint arXiv:1803.02642 .Mou, L., Ghamisi, P., Zhu, X.X., 2018b. Unsupervised spectral-spatial feature learning viadeep residual conv-deconv network for hyperspectral image classi /uniFB01cation. IEEETrans. Geosci. Remote Sens. 56, 391 –406.Penatti, O.A.B., Nogueira, K., Dos Santos, J.A., 2015. Do deep features generalize fromeveryday objects to remote sensing and aerial scenes domains? In: IEEE ComputerSociety Conference on Computer Vision and Pattern Recognition Workshops, 2015-October, pp. 44 –51.Phalke, A.R., Özdo ğan, M., 2018. Large area cropland extent mapping with Landsat dataand generalized classi /uniFB01er. Remote Sens. Environ. 219, 180 –195.Ramankutty, N., Evan, A.T., Monfreda, C., Foley, J.A., 2008. Farming the planet: 1.Geographic distribution of global agricultural lands in the year 2000. Glob.Biogeochem. Cycles 22, GB1003 .Rußwurm, M., Körner, M., 2017. Temporal vegetation modelling using long short-termmemory networks for crop identi /uniFB01cation from medium-resolution multi-spectral sa-tellite images. In: Proceedings of the IEEE Conference on Computer Vision andPattern Recognition (CVPR) Workshops .Rußwurm, M., Körner, M., 2018. Multi-temporal land cover classi /uniFB01cation with sequentialrecurrent encoders. ISPRS Int. J. Geo Inf. 7, 129 .Sakamoto, T., Gitelson, A.A., Arkebauer, T.J., 2014. Near real-time prediction of U.S. cornyields based on time-series MODIS data. Remote Sens. Environ. 147, 219 –231.Sayer, A., Hsu, N., Bettenhausen, C., Jeong, M., Meister, G., 2015. /uniFB00ect of MODIS Terraradiometric calibration improvements on Collection Deep Blue aerosol products:Validation and Terra/Aqua consistency. Journal of Geophysical Research:Atmospheres 120, 12,157 –12,174 .Searchinger, T., Heimlich, R., Houghton, R.A., Dong, F., Elobeid, A., Fabiosa, J., et al.,2008. Use of U.S. croplands for biofuels increases greenhouse gases through emis-sions from land-use change. Science (New York, N.Y.) 319, 1238 –1240 .Shao, Y., Lunetta, R.S., Ediriwickrema, J., Liames, J., 2010. Mapping cropland and majorcrop types across the Great Lakes Basin using MODIS-NDVI data. Photogramm. Eng.Remote. Sens. 76, 73 –84.Sherrah, J., 2016. Fully Convolutional Networks for Dense Semantic Labelling of High-Resolution Aerial Imagery. arXiv preprint arXiv:1606.02585 .Simonyan, K., Zisserman, A., 2014. Very Deep Convolutional Networks for Large-scaleImage Recognition. arXiv preprint arXiv:1409.1556 .Song, X., Potapov, P.V., Krylov, A., King, L., Di Bella, C.M., Hudson, A., et al., 2017.National-scale soybean mapping and area estimation in the United States usingmedium resolution satellite imagery and /uniFB01eld survey. Remote Sens. Environ. 190,383–395.Srivastava, N., Hinton, G., Krizhevsky, A., Sutskever, I., Salakhutdinov, R., 2014. Dropout:a simple way to prevent neural networks from over /uniFB01tting. The Journal of MachineLearning Research 15, 1929 –1958 .Stevens, F.R., Gaughan, A.E., Linard, C., Tatem, A.J., 2015. Disaggregating census data forpopulation mapping using random forests with remotely-sensed and ancillary data.PLoS One 10, e0107042 .Szegedy, C., Liu, W., Jia, Y., Sermanet, P., Reed, S., Anguelov, D., et al., 2015. Goingdeeper with convolutions. Proc. IEEE Conf. Comput. Vis. Pattern Recognit. –9.Tang, Q., Peterson, S., Cuenca, R.H., Hagimoto, Y., Lettenmaier, D.P., 2009. Satellite-based near-real-time estimation of irrigated crop water consumption. J. Geophys.Res.-Atmos. 114, D05114 .Thenkabail, P.S., Wu, Z., 2012. An automated cropland classi /uniFB01cation algorithm (ACCA)for Tajikistan by combining Landsat, MODIS, and secondary data. Remote Sens. .Volpi, M., Tuia, D., 2017. Dense semantic labeling of subdecimeter resolution images withconvolutional neural networks. IEEE Trans. Geosci. Remote Sens. 55, 881 –893.Wan, X., Zhao, C., Wang, Y., Liu, W., 2017. Stacked sparse autoencoder in hyperspectraldata classi /uniFB01cation using spectral-spatial, higher order statistics and multifractalspectrum features. Infrared Physics and Technology 86, 77 –89.Wang, D., Morton, D., Masek, J., Wu, A., Nagol, J., Xiong, X., et al., 2012. Impact ofsensor degradation on the MODIS NDVI time series. Remote Sens. Environ. 119,55–61.Wardlow, B.D., Egbert, S.L., 2008. Large-area crop mapping using time-series MODIS250 NDVI data: an assessment for the US Central Great Plains. Remote Sens.Environ. 112, 1096 –1116 .WWW1 United States Department of Agriculture (USDA) National Agricultural StatisticsService (NASS) Quick Stats. https://www.nass.usda.gov/Quick_Stats/ Accessed date:26 November 2018.WWW2 Brazilian Institute of Geography and Statistics Data Download. https://downloads.ibge.gov.br/downloads_estatisticas.htm .WWW3 Keras: The Python Deep Learning Library. https://keras.io/ .WWW4 Tensor /uniFB02ow: An Open Source Software Library for High Performance NumericalComputation. https://www.tensor /uniFB02ow.org .WWW5 USDA NASS Crop Progress. http://usda.mannlib.cornell.edu/MannUsda/viewDocumentInfo.do?documentID=1048 Accessed date: 26 November 2018.WWW6 California Pesticide Information Portal. https://calpip.cdpr.ca.gov/main.cfm .Xin, Q., Gong, P., Yu, C., Yu, L., Broich, M., Suyker, A.E., et al., 2013. productione/uniFB03ciency model-based method for satellite estimates of corn and soybean yields inthe Midwestern US. Remote Sens. 5, 5926 –5943 .Xiong, J., Thenkabail, P.S., Gumma, M.K., Teluguntla, P., Poehnelt, J., Congalton, R.G.,et al., 2017. Automated cropland mapping of continental Africa using Google EarthEngine cloud computing. ISPRS J. Photogramm. Remote Sens. 126, 225 –244.Zeiler, M.D., Fergus, R., 2014. Visualizing and understanding convolutional networks. In:European Conference on Computer Vision, pp. 818 –833.Zhang, J., Liu, T., Tao, D., 2018. An Information-Theoretic View for Deep Learning. arXivpreprint arXiv:1804.09060 .L. Zhong, et al. 5HPRWH6HQVLQJRI(QYLURQPHQWZhong, L., Gong, P., Biging, G.S., 2012. Phenology-based crop classi /uniFB01cation algorithm andits implications on agricultural water use assessments in California ’s Central Valley.Photogramm. Eng. Remote. Sens. 78, 799 –813.Zhong, L., Gong, P., Biging, G.S., 2014. /uniFB03cient corn and soybean mapping with tem-poral extendability: multi-year experiment using Landsat imagery. Remote Sens.Environ. 140, –13.Zhong, L., Hu, L., Yu, L., Gong, P., Biging, G.S., 2016a. Automated mapping of soybeanand corn using phenology. ISPRS J. Photogramm. Remote Sens. 119, 151 –164.Zhong, L., Yu, L., Li, X., Hu, L., Gong, P., 2016b. Rapid corn and soybean mapping in USCorn Belt and neighboring areas. Sci. Rep. 6, 36240 .Zhong, L., Hu, L., Zhou, H., 2019. Deep learning based multi-temporal crop classi /uniFB01cation.Remote Sens. Environ. 221, 430 –443.Zhu, X.X., Tuia, D., Mou, L., Xia, G., Zhang, L., Xu, F., et al., 2017. Deep learning inremote sensing: comprehensive review and list of resources. IEEE Geoscience andRemote Sensing Magazine 5, –36.L. Zhong, et al. 5HPRWH6HQVLQJRI(QYLURQPHQW