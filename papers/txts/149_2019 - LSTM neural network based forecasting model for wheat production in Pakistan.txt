agronomyArticleLSTM Neural Network Based Forecasting Model forWheat Production in PakistanSajjad Ali Haider1, Syed Rameez Naqvi1, Tallha Akram1,*, Gulfam Ahmad Umar2,Aamir Shahzad3, Muhammad Raﬁq Sial4, Shoaib Khaliq3and Muhammad Kamran11Department of Electrical Computer Engineering, COMSATS University Islamabad, G.T. Road,Wah Cantonment 47040, Pakistan; sajjadali@ciitwah.edu.pk (S.A.H.); rameeznaqvi@ciitwah.edu.pk (S.R.N.);dr_m_kamran@ciitwah.edu.pk (M.K.)2Department of Computer Science Information Technology, Ghazi University, D.G. Khan 32200, Pakistan;gulfambise@hotmail.com3Department of Electrical Computer Engineering, COMSATS University Islamabad, College Road,Tobe Camp, Abbottabad 22060, Pakistan; aamirsardar@gmail.com (A.S.); shoaibkhaliq@gmail.com (S.K.)4Department of Mathematics, COMSATS University Islamabad, G.T. Road, Wah Cantonment 47040, Pakistan;raﬁq@ciitwah.edu.pk*Correspondence: tallha@ciitwah.edu.pk; Tel.: +92-333-546-0670Received: 11 January 2019; Accepted: 29 January 2019; Published: February 2019/gid00030/gid00035/gid00032/gid00030/gid00038/gid00001/gid00033/gid00042/gid00045/gid00001/gid00048/gid00043/gid00031/gid00028/gid00047/gid00032/gid00046Abstract:Pakistan’s economy is largely driven by agriculture, and wheat, mostly, stands out asits second most produced crop every year. On the other hand, the average consumption of wheatis steadily increasing as well, due to which its exports are not proportionally growing, thereby,threatening the country’s economy in the years to come. This work focuses on developing an accuratewheat production forecasting model using the Long Short Term Memory (LSTM) neural networks,which are considered to be highly accurate for time series prediction. data pre-processing smoothingmechanism, in conjunction with the LSTM based model, is used to further improve the predictionaccuracy. comparison of the proposed mechanism with few existing models in literature isalso given. The results verify that the proposed model achieves better performance in terms offorecasting, and reveal that while the wheat production will gradually increase in the next ten years,the production to consumption ratio will continue to fall and pose threats to the overall economy.Our proposed framework, therefore, may be used as guidelines for wheat production in particular,and is amenable to other crops as well, leading to sustainable agriculture development in general.Keywords:wheat production; time series forecasting; long short term memory neural networks;smoothing function1. IntroductionAgriculture sector, being the backbone of Pakistan’s economy, accounted for 19.5 percent ofGDP and 42.5 percent of employment in the ﬁnancial year 2016–2017 [1]. Wheat stood out as thesecond largest crop; alone responsible for 1.9 percent in the GDP, and 3.4 percent in the employmentduring the said year. Considering the fact that domestic consumption of wheat continues to increasesteadily, its exports are expected to be affected signiﬁcantly in the coming years, which will be majorsetback for the country’s economy. Wheat production forecasting for many years to come is one wayof alleviating this predicament; an analysis of its production to consumption ratio will not just bemeans of estimating the expected amount of export, but will motivate certain measures to be takenat state level to ensure its escalated cultivation, and to minimize losses due to diseases by moderntechnological methods [2].Agronomy2019,9, 72; doi:10.3390/agronomy9020072www.mdpi.com/journal/agronomyAgronomy 2019,9, 72 of 12The primary objective of forecasting method is to use several parameters to formulate amathematical model that predicts the production in future. One such method was presented 3],in which the used parameters included rainfall, temperature, fertilizer, area, and most importantlyhistory of the production. However, the data used in that work was for years 1979–2006, due tounavailability of several parameters until 1979, and the results were veriﬁed for only two years.Therefore, the limited dataset comprised wheat production for only 39 years. Moreover, someparameters had to be interpolated to overcome the deﬁciency in their dataset, which must havecontributed to the constrained accuracy they had achieved. We believed that the amount ofdata available to the authors of 3] was not sufﬁcient for an effective training of any regressionmodel available, therefore, elevating the accuracy to an acceptable level, required differenttechnique altogether.It is very difﬁcult to know complete details of these parameters, however, realistic designapproach in this regard is to developing time series based prediction model, such as auto regressiveintegrated moving average (ARIMA) model, which is very popular and has shown good results.Several studies have been conducted in the past for wheat forecasting, keeping in view the ﬂuctuationsin its production that Pakistan has seen over the years. The most notable studies amongst thosewere carried out by Amin et al. 4] and Iqbal et al. 5]. In the former, the authors made use of twocommercially available software; namely JMP and Statgraphics, and they used time series ARIMAmodel. They established that the ARIMA (1,2,2) was the best model according to two important modelselection criteria, i.e., Akaike’s information criteria (AIC) and Schwarz Bayesian Information criteria(SBIC). The forecasting results showed root mean squared error (RMSE) of 1145 thousand tons, whichreﬂects very high prediction error. Due to their linear behavior, ARIMA models prove unsuitable formany real-world nonlinear problems.The emergence of artiﬁcial neural networks (ANN), however, has lightened up the predictionand forecasting ﬁelds. ANN have been widely used for prediction of various complex systems 6–9].They have capabilities of identifying and learning complex nonlinear relationships between differentsystems’ parameters, and mostly yield more accurate results when compared with linear regressiontechniques 10,11]. Amongst various known for long, one recently proposed deep learning architectureof ANN, called Long Short Term Memory Neural Networks (LSTM-NN), has caught attention for timeseries forecasting 12]. The predictions by this class are inﬂuenced by the past behavior of the system,and it can be used for both regression and classiﬁcation purposes. Compared to other deep models,such as deep Boltzman machine, graph structured recurrent neural network, and convolutional neuralnetworks, the LSTM-NN based deep learning models perform signiﬁcantly better 13] for time-seriesforecasting due to set of reasons. It has natural tendency to extract robust patterns for an input featurespace, and can handle MIMO systems effectively by offering lot of system’s ﬂexibility. Additionally,LSTM systems are capable of handling nonlinear systems due to their specialized LSTM nodes thatperform better after learning.LSTM-NN have shown improved modeling capabilities in various time series applications,including stock returns in China 14], trafﬁc dynamics 15], and rent payment delays by tenants 16].Despite having excellent forecasting capabilities, ANN and LSTM-NN have had limitedapplication in the ﬁeld of agriculture and crop production forecasting. In 17,18], recurrent neuralnetwork (RNN) based forecasting models were presented for crop yield prediction. In our work,we have used MATLAB 2018Rwith deep learning toolbox to develop the wheat production forecastingmodel. We have adopted the historical data of wheat production for years 1902–2018, and comparedthe results with existing literature. We have also devised mechanism, using smoothing function,to pre-process the dataset prior to training the LSTM-NN model. Our results suggest better forecastingwith smaller prediction error. The contribution of this work, therefore, is the recommendation of datapre-processing using suitable smoothing function in conjunction with the LSTM-NN model, with aimof providing better wheat production forecast.Agronomy 2019,9, 72 of 12The rest of the paper is organized as follows: brief introduction of the ANN and LSTM-NN isgiven in Section 2. The pre-processing methodology, and training of the LSTM-NN are explained inSection 3. Section 4presents our simulation results and comparisons. Section 5concludes the paper.2. Artiﬁcial Neural Networks and Long Short Term Memory Neural NetworksThe basic concept of ANN is inspired from the neural system of humans 19], where neurons areconnected to each other forming layered structure from inputs to outputs via few hidden layers.The interconnections between neurons are assigned some weights and biases, together called network’scoefﬁcients. Figure 1presents an abstract level diagram of ANN, having set of inputs (x1,x2, ...,xR),an output (yo), and two hidden layers. diandd0iin the hidden layers are called threshold or quantizationfunctions. Several options are available for thresholding in literature; we have selected log-sigmoid inboth hidden layersd(x)=11+ex), and purlin in the output layer (d(x)= x). ANN have been widelyadopted for system modeling, where they are ﬁrst trained by means of learning algorithm, in whichthe network’s coefﬁcients are updated iteratively. The trained model is then used for achieving thedesired behavior. One of the most common learning algorithm is back propagation, in which the erroris propagated backward.Figure 1. Basic structure of fully connected artiﬁcial neural network 20,21].There are various kinds of ANN architectures; the most common of them are feed-forward,cascaded and recurrent. RNN are widely used for time series forecasting, in which each layer posessome recurrent connections having some unit delays. This results in inﬂuence of the current outputby previous states. The basic architecture of RNN is shown in Figure 2, where feedback path existsbetween second and ﬁrst hidden layer, (RVUs). One special type of RNN is the LSTM-NN. LSTM-NNare capable of learning long term dependencies in data. The basic concept of LSTM-NN was proposedin [12], and they are now widely applied in various applications. Although RNN are also capable oflearning long term dependencies in data, but they suffer from the vanishing gradient issue. LSTM-NNarchitecture is based on gates, whose function is to choose the data to keep and to discard. Due togradient control, it can remember more data than RNN. An LSTM-NN cell consists of three gates:input gate, output gate and forget gate. The input gate gives new inputs to the cell. The output gatespeciﬁes the output of the cell, and forget gate is responsible for specifying the prior values that needto be retained for future reference. typical LSTM-NN cell structure is shown in Figure 3.Agronomy 2019,9, 72 of 12Figure 2. Basic structure of recurrent neural network 20,22].Figure 3. Basic structure of LSTM-NN cell 13].The gates in the LSTM-NN cell structure are represented by circles in Figure 3. Here g,i,oandfrepresent modulation gate, input gate, output gate and forget gate respectively. In the modulation gate,the input is updated at the present time instant. All gates work on current input x(t)) and previousvalues of states h(t1)). The outputs of gates are calculated as follows:i(t)= f(Wixc(t)+Uihc(t1)+bi) (1)g(t)= tanh(Wcxc(t)+Uchc(t1)+bc) (2)g(t)= f(Wfxc(t)+Ufhc(t1)+bf) (3)where, WandUare the weights for input and previous state respectively. The biases are representedwith b, subscript is used to represent the speciﬁc gate. The updated cell value is calculated as:c(t)= f(Wo+xc(t)+Uohc(t1)+Voc(t)+bo) (4)The current cell state, current input and previous state of the cell are used to control the outputgate. The updated cell state is given as follows:O(t)= f(Woxc(t)+Uohc(t1)+Voc(t)+bo) (5)h(t)=O(t)tanh(c(t)) (6)Agronomy 2019,9, 72 of 12Generally, if hidden layers are more than one the network architecture could be categorized asdeep network. In the proposed work, we have evaluated various hidden layers structures in theLSTM-NN to get the best results.3. Materials and MethodsThe proposed research methodology is depicted in Figure 4. Pakistan’s wheat production historyfor the years 1902–2018, constituting our dataset, was obtained from the Federal Bureau of Statistics,Pakistan, and the Economic Survey of Pakistan, 2017 1]. The dataset is divided into two subsets:The ﬁrst subset, comprising data from 1902–2008, is used for training the three forecasting models,namely, ARIMA, RNN and LSTM-NN. The second subset consists of data from 2009–2018, and is usedfor the validation purpose.Figure 4. Flow diagram of the model selection process.Agronomy 2019,9, 72 of 12Since, the raw data included ﬂuctuations that might affect the forecasting results, smoothingfunction is used to smooth out the curve values prior to training the models. One of the most widelyused smoothing functions is Robust-LOWESS 23]. It uses local regression using linear recursiveleast squares (RLS). The presence of outliers in the data degrades its modeling accuracy. Using thelocal regression, it decreases the effects of outliers and results in improved modeling. This algorithmassigns very low weights to the outliers. The smoothing function with polynomial of degree two,and window size of four years, is used for data pre-processing. Algorithm 1presents our proposedmethodology.Algorithm 1: Proposed MethodologyInput: Training data dF={(x1,y1),(x2,y2)...(xN,yN)}Parameters Gp autoregressive order, Gd nonseasonal differences, Gq lagged forecasterrors, [dfd] feedback delays, [dhu] hidden layers/units, learning rate, [dtf] training function/solver, adp Learning rate drop period, [dhn] neurons in each hiddenlayer, dtr training percentage, d0vd validation percentage, Starc structure ofarchitecture’s parameters.Output Performance parameters [Opp][dvd,dtr]= U(dF)(d0tr,d0vd)for(i=1toM)dodpts:=Robust-LOWESS( dts,a,biter)endEnd foriStarc (difd,ditf,dihu,didp,dihn,a,divd,ditr)for(i=1toK)dofor(j=1toM)do[Kipp]:=F(Siarc)endEnd forjendEnd fori[Oipp] calculate MAE using Equation (7)[O(i+1)pp] calculate RMSE using Equation (8)[O(i+2)pp] calculate R-value using Equation (9)All the three models, ARIMA, RNN and LSTM-NN, are then developed using both the rawand the pre-processed data, resulting in total of six models. The latter are then compared with theactual values in the validation step. We use mean absolute error (MAE), root mean squared error(RMSE) and correlation coefﬁcient value R-value) as the three performance metrics for comparison.TheR-value determines correlation between actual and predicted values. Its value is between and 1,where means no correlation while means perfect match. Considering xto be the actual values, yrepresenting the predicted values, ¯xrepresenting mean of x,¯yrepresenting mean of yandnis numberof samples, these metrics are calculated by their standard formulas as given in Equations (7)–(9).MAE =Âni=1|xiyi|n(7)RMSE =sÂni=1(xiyi)2n(8)R=Âni=1(xi¯x)(yi¯y)qÂni=1(xi¯x)2qÂni=1(yi¯y)2(9)Agronomy 2019,9, 72 of 12The benchmark model for wheat production forecasting is the ARIMA model 4], denoted asARIMA (p,d,q) model, where p,d,q are orders of auto regressive, differencing, and moving averagemodels respectively. 4] used the ARIMA models with parameters (1,2,2). There are various variants ofRNN in literature 19]; we have selected nonlinear auto-regressive model (NAR). In ANN there areno speciﬁc steps to achieve the best models; instead there are some guidelines that may be followed,such as, increasing the number of hidden layers, and using different training functions to tune ourmodel accuracy 19]. In the development of RNN model having NAR architecture, various tuningparameters were tested. These parameters are given in Table 1. The results of each conﬁguration werecompared with the actual values and were evaluated on same metrics deﬁned in Equations (7)–(9).MATLAB software’s ANN toolbox is used for all the simulations.Table 1. Parameters used for developing RNN forecasting model.Parameter Range Parameter RangeFeedback delays to No. of neurons in each hidden layer to 40No. of Hidden layers to Training functionsBayesian regularization 19],Levenberg–Marquardt 19]Similarly, set of tuning parameters was used to build the forecasting model for LSTM-NN; givenin Table 2. As far as selection of the solver is concerned, Adam Optimizer 24] and SGDM 25] haveshown excellent suitability for LSTM-NN, which have gradient control property. However, the betteramong the two can only be determined for given dataset, since each of them largely depends uponsize of the dataset, and whether the problem has non-stationary objectives and sparse gradients 26].The accuracy of each solver may differ depending upon the application.The results of each conﬁguration were compared with the actual values and were evaluated onsame metrics deﬁned in Equations (7)–(9). MATLAB software’s Deep learning toolbox is used for allthe simulations of LSTM-NN.Table 2. Parameters used for developing LSTM-NN forecasting model.Parameter Range Parameter RangeHidden Units to 2000 Learn drop rate period to 100Initial learning rate 0.001 to 0.009 SolverAdam optimizer 24],stochastic gradient descent withmomentum (SGDM) 25]4. Results and DiscussionThe original time series plot for the wheat production in Pakistan from the year 1902 to 2018 isshown in Figure 5. After applying the smoothing function, smooth time series curve is achieved asshown in Figure 6. The best values of various tuning parameters of RNN and LSTM-NN are given inTable 3. These parameters values resulted in achieving minimum MAE, minimum RMSE and highestR-value for each model category. These values were result of rigorous testing of various parametervalues for each model.Agronomy 2019,9, 72 of 12Table 3. Best parameters for RNN and LSTM-NN forecasting models.RNNRNNpre-processedParameter Value Parameter Value Parameter Value Parameter ValueFeedback delays 2No. of neurons ineach hidden layer28,6 Feedback delays 4No. of neurons ineach hidden layer28,10No. ofHidden layers2 Training functionBayesianregularizationNo. ofHidden layers2 Training functionBayesianregularizationLSTM-NNLSTM-NNpre-processedParameter Value Parameter Value Parameter Value Parameter ValueHidden units 2000Learn ratedrop period120 Hidden units 200Learn ratedrop period20Initiallearning rate0.009 Solver SGDMInitiallearning rate0.0032 Solver SGDMFigure 5. Historical wheat production of Pakistan from 1902–2018.Figure 6. Wheat production curve after applying smoothing function.Agronomy 2019,9, 72 of 12All the models are trained using the data from year 1902–2008, whereas, the data from 2009–2018was used for validation. The comparison between step-ahead forecast using the proposed modelsand that by the existing benchmark model 4], for period 2009–2018, are given in Table 4. The resultsshows signiﬁcant improvement in terms of wheat production forecasting. The error terms MAEand RMSE, which are widely used to represent the model error, shows that LSTM-NN developedusing pre-processed data is the most accurate model. LSTM-NN model developed on pre-processeddata has the MAE value of 729 thousand tons, which shows an improvement of about 14% againstthe existing benchmark model 4]. Similarly, RMSE shows an improvement of 25%. The results of thesix models are also compared in term of R-value: the higher the R-Value the higher is the correlationbetween the actual and the predicted values. The regression plots of all six models along with theirR-Values are shown in Figure 7. The dotted line represent the best ﬁt and continuous line is the actualﬁt between actual and predicted values. ARIMA model based on pre-processed data, LSTM-NN modeland LSTM-NN model model developed on pre-processed data have the highest R-value of 0.81. Thisshows strong correlation between actual and predicted values. The best results for each model aresummarized in Table 5. Both LSTM-NN models gave accurate results due to better learning capabilitiesof LSTM-NN. The results clearly shows that LSTM-NN model developed on pre-processed data givesbest results.Table 4. The difference between actual and forecast wheat production (in thousand tons) for years2009–2018 using various models.Year Actual ARIMA(1,2,2)ARIMA(1,2,2)Pre-ProcessedRNNRNNPre-ProcessedLSTM-NNLSTM-NNPre-Processed2009 24,033 1688.6 197.7 430.06 2683.32 1382.40 802.892010 23,311 434 1042.1 4213.38 1405.02 304.46 400.792011 25,214 1941.2 349.8 60.18 2620.00 1824.97 1025.452012 23,473 173.7 1899.5 761.99 138.64 284.71 1180.162013 24,211 194 1668.6 382.72 176.09 96.99 893.752014 25,979 1592.2 407.3 1540.87 1337.55 1521.19 436.382015 25,086 329.5 1806.8 581.68 47.94 296.87 880.032016 25,633 506.8 1766.2 1156.40 141.09 525.06 741.322017 26,674 1178.1 1231.6 2185.48 959.31 1259.67 92.832018 26,300 434.4 2112 1816.46 465.38 591.66 843.05Table 5. Comparison of various forecasting models.Model RMSE MAE R-ValueARIMA (1,2,2) 4] 1065 847 0.80ARIMA (1,2,2) pre-processed 1420 1248 0.81RNN 1754 1313 0.58RNN pre-processed 1379 997 0.79LSTM-NN 1002 808 0.81LSTM-NN pre-processed 792 729 0.81The wheat production values using the LSTM-NN model with pre-processed data for future yearsare given in Table 6. It is forecasted that in 2028, Pakistan annual wheat production will be about29,096 thousand tons considering consistent social, environmental and economic conditions.Agronomy 2019,9, 72 10 of 12Table 6. Ten years ahead wheat production forecasting (in thousand tons) of Pakistan.Year Wheat Production Forecast2019 27,1032020 27,3882021 27,6572022 27,9082023 28,1432024 28,3622025 28,5662026 28,7562027 28,9332028 29,096Figure 7. Regression plot of the forecasting models along with the correlation coefﬁcient.5. ConclusionsIn this work we have proposed to use Robust-LOWESS as smoothing function in conjunctionwith LSTM-NN model to predict wheat production in Pakistan for years 2019–2028. We demonstratethat removing the outliers from the original data, prior to performing the actual prediction, helps inimproving the accuracy by signiﬁcant amount. We have used MATLAB as the simulation tool, andRMSE, MAE and correlation coefﬁcient as the comparison metrics. Our study reveals signiﬁcantimprovement of in terms of model accuracy in comparison to the existing works. Our study is crucialsince Pakistan’s economy immensely depends upon agriculture, and wheat usually stands out as thesecond most important crop.Agronomy 2019,9, 72 11 of 12Author Contributions: Conceptualization, M.K.; Data curation, S.K.; Investigation, S.A.H.; Methodology, T.A.;Project administration, M.R.S.; Validation, A.S.; Writing original draft, S.R.N.; Writing review and editing,G.A.U.Funding: This research received no external fundingConﬂicts of Interest: The authors declare no conﬂict of interest.References1. Ministry of Food Agriculture. Livestock, Islamabad G.o.P. Economic Survey of Pakistan. 2011. Availableonline: http://www.ﬁnance.gov.pk/survey/chapter_12/02-Agriculture.pdf (accessed on 31 January 2019).2. Akram, T.; Naqvi, S.R.; Haider, S.A.; Kamran, M. Towards real-time crops surveillance for diseaseclassiﬁcation: exploiting parallelism in computer vision. Comput. Electr. Eng. 2017,59, 15–26. CrossRef ]3. Sher, F.; Ahmad, E. Forecasting Wheat Production in Pakistan. Lahore J. Econ. 2008,13, 57–85.4. Amin, M.; Amanullah, M.; Akbar, A. Time Series Modeling for forecasting wheat production of Pakistan.Plant Sci. 2014,24, 1444–1451.5. Iqbal, N.; Bakhsh, K.; Maqbool, A.; Ahmad, A.S. Use of the ARIMA model for forecasting wheat area andproduction in Pakistan. J. Agric. Soc. Sci. 2005,1, 120–122.6. Naqvi, S.; Akram, T.; Haider, S.; Kamran, M.; Shahzad, A.; Khan, W.; Iqbal, T.; Umer, H. Precision Modeling:Application of Metaheuristics on Current–Voltage Curves of Superconducting Films. Electronics 2018,7, 138.[CrossRef ]7. Haider, S.A.; Naqvi, S.R.; Akram, T.; Kamran, M. Prediction of critical currents for diluted square latticeusing Artiﬁcial Neural Networks. Appl. Sci. 2017,7, 238. CrossRef ]8. Naqvi, S.R.; Akram, T.; Haider, S.A.; Kamran, M. Artiﬁcial neural networks based dynamic priorityarbitration for asynchronous ﬂow control. Neural Comput. Appl. 2018,29, 627–637. CrossRef ]9. Naqvi, S.R.; Akram, T.; Iqbal, S.; Haider, S.A.; Kamran, M.; Muhammad, N. dynamically reconﬁgurablelogic cell: From artiﬁcial neural networks to quantum-dot cellular automata. Appl. Nanosci. 2018,8, 89–103.[CrossRef ]10. Rather, A.M.; Agarwal, A.; Sastry, V. Recurrent neural network and hybrid model for prediction of stockreturns. Expert Syst. Appl. 2015,42, 3234–3241. CrossRef ]11. Bengio, S.; Vinyals, O.; Jaitly, N.; Shazeer, N. Scheduled sampling for sequence prediction with recurrentneural networks. In Proceedings of the Advances in Neural Information Processing Systems, Montreal, QC,Canada, 7–12 December 2015; pp. 1171–1179.12. Hochreiter, S.; Schmidhuber, J. Long short-term memory. Neural Comput. 1997,9, 1735–1780. CrossRef ][PubMed ]13. Tan, M.; Santos, C.D.; Xiang, B.; Zhou, B. LSTM-based deep learning models for non-factoid answer selection.arXiv 2015, arXiv:1511.04108.14. Chen, K.; Zhou, Y.; Dai, F. LSTM-based method for stock returns prediction: case study of China stockmarket. In Proceedings of the 2015 IEEE International Conference on Big Data (Big Data), Santa Clara, CA,USA, 29 October–1 November 2015; pp. 2823–2824.15. Ma, X.; Tao, Z.; Wang, Y.; Yu, H.; Wang, Y. Long short-term memory neural network for trafﬁc speedprediction using remote microwave sensor data. Transp. Res. Part Emerg. Technol. 2015,54, 187–197.[CrossRef ]16. Garn, W.; Hu, Y.; Nicholson, P.; Jones, B.; Tang, H. LSTM network time series predicts high-risktenants. In Proceedings of the Euro 2018–29th European Conference on Operational Research, EURO2018, Valencia, Spain, 8–11 July 2018.17. Guo, W.W.; Xue, H. Crop yield forecasting using artiﬁcial neural networks: comparison between spatialand temporal models. Math. Probl. Eng. 2014,2014 857865. CrossRef ]18. Meena, M.; Singh, P.K. Crop Yield Forecasting Using Neural Networks. In International Conference on Swarm,Evolutionary, and Memetic Computing Springer: Cham, Switzerland, 2013; pp. 319–331.19. Schalkoff, R.J. Artiﬁcial Neural Networks McGraw-Hill: New York, NY, USA, 1997; Volume 1.20. Hagan, M.T.; Demuth, H.B.; Beale, M.H.; De Jesús, O. Neural Network Design Pws Pub.: Boston, MA, USA,1996; Volume 20.Agronomy 2019,9, 72 12 of 1221. Kamran, M.; Haider, S.; Akram, T.; Naqvi, S.; He, S. Prediction of IV curves for superconducting thin ﬁlmusing artiﬁcial neural networks. Superlattices Microstruct. 2016,95, 88–94. CrossRef ]22. Haider, S.A.; Naqvi, S.R.; Akram, T.; Kamran, M.; Qadri, N.N. Modeling electrical properties for variousgeometries of antidots on superconducting ﬁlm. Appl. Nanosci. 2017,7, 933–945. CrossRef ]23. Cleveland, W.S. LOWESS: program for smoothing scatterplots by robust locally weighted regression.Am. Stat. 1981,35, 54. CrossRef ]24. Kingma, D.P.; Ba, J. Adam: method for stochastic optimization. arXiv 2014, arXiv:1412.6980.25. Mandt, S.; Hoffman, M.D.; Blei, D.M. Stochastic gradient descent as approximate Bayesian inference. J. Mach.Learn. Res. 2017,18, 4873–4907.26. Wilson, A.C.; Roelofs, R.; Stern, M.; Srebro, N.; Recht, B. The marginal value of adaptive gradient methods inmachine learning. In Proceedings of the Advances in Neural Information Processing Systems, Long Beach,CA, USA, 4–9 December 2017; pp. 4148–4158.c2019 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open accessarticle distributed under the terms and conditions of the Creative Commons Attribution(CC BY) license http://creativecommons.org/licenses/by/4.0/ ).