Contents lists available at ScienceDirectComputers and Electronics in Agriculturejournal homepage: www.elsevier.com/locate/compagAerialhyperspectralimageryanddeepneuralnetworksforhigh-throughputyield phenotyping in wheatAli Moghimia,1, Ce Yanga,⁎, James A. AndersonbaDepartment of Bioproducts and Biosystems Engineering, University of Minnesota, 1390 Eckles Ave, St. Paul, MN 55108, USAbDepartment of Agronomy Plant Genetics, University of Minnesota, 991 Upper Buford Circle, St. Paul, MN 55108, USAARTICLE INFOKeywords:Deep learningEndmemberHyperspectral imagingNeural networkPhenotypingUAVUnmixingYieldABSTRACTCrop production needs to increase in sustainable manner to meet the growing global demand for food. Toidentify crop varieties with high yield potential, plant scientists and breeders evaluate the performance ofhundreds of lines in multiple locations over several years. To facilitate the process of selecting advanced vari-eties, an automated framework was developed in this study. hyperspectral camera was mounted on an un-mannedaerialvehicletocollectaerialimagerywithhighspatialandspectralresolutioninafast,cost-effectivemanner. Aerial images were captured in two consecutive growing seasons from three experimental yield fieldscomposedofhundredsexperimentalwheatlines.Thegrainofmorethanthousandwheatplotswasharvestedbyacombine, weighed, andrecordedastheground truthdata.To investigatetheyield variationatsub-plotscaleand leverage the high spatial resolution, plots were divided into sub-plots using image processing techniquesintegrated by domain knowledge. Subsequent to extracting features from each sub-plot, deep neural networkswere trained for yield estimation. The coefficient of determination for predicting the yield was 0.79 and 0.41with normalized root mean square error of 0.24 and 0.14 at sub-plot and plot scale, respectively. The resultsrevealed that the proposed framework, as valuable decision support tool, can facilitate the process of high-throughput yield phenotyping by offering the possibility of remote visual inspection of the plots as well asoptimizing plot size to investigate more lines in dedicated field each year.1. IntroductionConsidering the increasing world population and subsequent de-mand for food, crop production should double by 2050 (Tilman et al.,2011), indicating the average rate of yield increase of crops should be2.4%annually–thecurrentaveragerateofincreaseisonly1.3%(Rayet al., 2013). These statistics noticeably indicate an urgent need forfurther efficiency improvement in crop production to alleviate theglobal concern of food security. Nevertheless, genetic gain in yield ofwheat, one of the major crops, was reported to be less than 1%, farbehindthenecessaryyieldincrease(i.e.,2.4%)(Crainetal.,2018;Rayetal.,2013).Otherstudiesevenclaimedwheatyieldshaveplateauedinsome regions of the world (Araus et al., 2018), indicating the im-portance of high-throughput phenotyping for developing wheat vari-etieswithhighyieldpotentialinamoreefficientandeffectivemanner.Toidentifywheatvarietieswithhighyieldpotential,plantscientistsand breeders examine hundreds to thousands of new candidate lines,developed through breeding and genotyping, in experimental plotseachyearandmeasuretheiryieldperformance.Theyieldmeasurementof wheat plots is performed through conventional methods which relyon demanding, extremely laborious, and time-consuming tasks. Forinstance, in an experimental yield nursery composed of hundreds ofwheat plots, the steps of yield measurement include harvesting thegrains of eachplot, manualpackaging, labeling,and sealing –allstepsare repetitively performed for each plot to avoid blending grains ofplots. These exhausting tasks escalate even more since breeders haveyield nurseries in multiple locations to account for non-uniform cli-mate, soil, and environmental conditions. Furthermore, in rathershortharvestingtime,conventionalmeasurementforyieldphenotypingis restricted by the availability of machinery, labor and weather con-ditions.Eachofthesefactorscouldpotentiallypostponeharvestingtimefor several days during which yield loss can occur because of animals’attack (e.g. birds and rodents) and/or severe weather (e.g. hail andwinds). Any of these challenges could deteriorate the quality and re-liability of the data, thus wasting the enormous efforts made thoroughthe entire growing season.https://doi.org/10.1016/j.compag.2020.105299Received 17 October 2019; Received in revised form 22 January 2020; Accepted 17 February 2020⁎Corresponding author.E-mail addresses: moghi005@umn.edu (A. Moghimi), ceyang@umn.edu (C. Yang), ander319@umn.edu (J.A. Anderson).1Present address: Department of Biological and Agricultural Engineering, University of California-Davis, One Shields Avenue, Davis, CA 95616, USA.Computers and Electronics in Agriculture 172 (2020) 105299Available online 02 April 20200168-1699/ 2020 Elsevier B.V. All rights reserved.T01Amirhossein ZajiThe other limitation associated with the conventional yield pheno-typing methods is that it ignores the spatial variability of yield withinthe experimental plots. Various regions in single plot contribute un-equally to the measured yield for the plot (i.e., yield is non-uniformlydistributed within an experimental plot). Therefore, breeders are un-able to study the effect of crop density on yield potential for variousvarieties.Moreover,ignoringthevariabilityofyieldwithinplotsentailsan enormous loss of information regarding the marginal effects onyield. This is valuable information to identify the lines whose plantslocated in the middle of plot can compete for nutrition and thereforecan contribute to yield as much as the plants located at the margin oftheplot.Consideringtheimportanceofselectinghigh-yieldingvarietiesand limitations associated with conventional phenotyping methods,there is compelling need to predict yield, preferably with high-re-solution, using robotics equipped with advanced sensing technologies.Inseveralstudiesfocusingonhigh-throughputfieldphenotypingforyield estimation of wheat, researchers have utilized various sensorsmounted on unmanned aerial vehicles (UAVs). Madec et al. (2017)attempted to predict the yield of various wheat genotypes based onmaximum plant height estimation using RGB images and LiDAR datacollectedbyaUAV.TheyreportedalowcorrelationbetweenyieldandmaximumplantheightderivedfromLiDARdata(R2=0.22)andRGBimages (R2= 0.13).Duan et al. (2017) computed normalized differ-ence vegetation index (NDVI) derived from multispectral images cap-tured by UAV to predict the yield of wheat in 12 plots including threecultivars with four treatments. To address the issue of mixed pixelscausedbytheattainedlowspatialresolution(2–5cm),theyproposedanaïve solution in which pixels with NDVI less than predefinedthresholdweremaskedforfurtheranalysis.Theysuggestedthatthereisa high correlation (R2= 0.87) between the adjusted NDVI, computedaround flowering time, and the final yield.To predict the yield of particular winter wheat, Du and Noguchi(2017)deployed stepwise regression to analyze five color vegetationindices derived from multi-temporal color images captured by UAVfromheadingstagetoripeningstage.Theirresults,obtainedfromonlynine samples of wheat yield, demonstrated strong correlation(R2= 0.94 and RMSE 0.02) between four color vegetation indicesand yield for this limited number of samples. In another study, aerialimagesacquiredfromUAVwereutilizedtoestimatetheyieldoftwentywheat varieties under water limited and heat stressed environment(Kyratzisetal.,2017).Theyconcludedthatgreennormalizeddifferencevegetation index (GNDVI), compared to NDVI, performed better inexplainingvariabilityofgrainyieldwithR2=0.31andR2=0.21forthe first and second year of experiment, respectively.Withtheavailabilityofmorecompact,lightweight,andinexpensivehyperspectral sensors, aerial hyperspectral imagery has become an ac-tive research area among agricultural scientists to leverage the uniqueadvantages of integrating imaging with high-resolution spectroscopy.Various studies have demonstrated the substantial potential of hyper-spectral imaging in wide range of applications in agriculture such ascrop health monitoring (Nigam et al., 2019), salt stress phenotyping(Moghimi et al., 2018b), aboveground biomass estimation (Yue et al.,2017),estimationofgrainelementsconcentration(Herzigetal.,2019),and grain yield prediction (Krause et al., 2019).Nowadays, with the commercialization of UAVs and increasingavailability of compact, inexpensive, and sophisticated sensing tech-nologies, the challenge in high-throughput phenotyping shifted fromdata collection to data analysis extracting significant features andrecognizingunderlyingpatternsfromlargedatasetscapturedwithhightemporal, spatial, and spectral resolution by autonomous platformsequipped with non-contact sensing technologies. The common ap-proach foranalysis of image-based data(RGB, multi- or hyper-spectralimages) is to calculate spectral vegetation indices derived by simplearithmetic equation (e.g. ratio) among few spectral bands.Nevertheless,therearepotentialdrawbacksinusingspectralvegetationindicesforanalysisofspectralimages.Forinstance,ithasbeenprovedthat NDVI, the most widely used index, suffers from saturation issueover vegetation canopy with moderate-to-high level of density(Gitelson, 2004; Gitelson et al., 1996). Therefore, more advancedanalyticalapproachesarerequiredtoextractvaluableinformationfromlarge image-based phenotyping datasets rather than simple vegetationindices which entail several limitations.Recently, machine learning and deep learning algorithms haveshown considerablepromise in developingmore efficientand effectivepipelinesforanalysisoflargephenotypingdatasets(Singhetal.,2016,2018). Several research studies have utilized machine learning anddeep learning for various phenotyping applications such as spike de-tection (Qiu et al., 2019), disease resistance of crops (Mahlein et al.,2019), robotic plant phenotyping (Wu et al., 2019), informative bandselection for plant phenotyping (Moghimi et al., 2019, 2018a), plantstress tolerance ranking (Naik et al., 2017), real–time phenotypingframework, yield estimation of tomato (Ashapure et al., 2019), detec-tion andlocalization of rootand shootfeatures in wheat(Pound et al.,2017),cornyieldprediction(KhakiandWang,2019),andleafcounting(Ubbens and Stavness, 2017).Yield is the most fundamental trait in plant breeding since almostevery other characteristic of crops, treatments, and management deci-sionsareevaluatedthroughthelensofwhethertheypromoteorhindertheyieldpotential.Theprimaryobjectiveofthisstudywastodevelopasensor-based, automated framework for high-throughput yield pheno-typingofwheatinthefield.Thedatafromhundredsofwheatvarietieswere collected by hyperspectral camera mounted on UAV flyingover three experimental wheat plots during two consecutive growingseasons. To analyze high-dimensional hyperspectral images capturedwith high spatial and spectral resolution, deep neural network wastrained to predict the yield of wheat plots. In addition to yield predic-tion at plot scale, the feasibility of yield estimation at finer spatialresolution(i.e.,sub-plotscale)wasinvestigatedtodeterminetheabilityofwheatlinesinproducingauniformyieldacrosstheplot–avaluablenew index in breeding programs to nominate advanced cultivars forcommercialization.2. Materials and methods2.1. Field site and experimental setupField experiments were conducted in three experimental yield trialfields (C3, C4, and C9) during two consecutive growing seasons 2017(C3andC9)and2018(C4).FieldsiteswerelocatedatSt.PaulCampusResearch Facility, University of Minnesota, MN (44°59′28.15″N and93°10′48.34″W)(pleaseseethegraphicalabstractshowingthelayoutofthe tree experimental yield trials). Yield trials were composed of hun-dreds experimental new wheat lines developed at University ofMinnesota,severalchecklines,andadvancedlinesfromotherbreedingprograms. Each wheat line was planted in seven rows which formed aplot with about one-meter width and 2.4-meter length. The plots wereharvested with combine designed for harvesting small plots. Afterharvest, the grains of each wheat plot were individually weighed.Therefore, the unit of yield was gram per plot area (2.4 m2). Since theplotsizewasidenticalforallplotsinthethreefields,yieldispresentedin terms of gram hereinafter.2.2. Platform for aerial imageryTheUAVusedinthisstudywasDJIMatrice600ProequippedwithA3 Pro flight controller (Fig. 1). Flight missions were created andexecutedinagridmodewithDJIGroundStationPro. Table1presentsthedetailoftheflightmission.Forimagecollection,theentiremissionwas executed in autonomous mode except the take-off and landingwhichwereperformedmanually.Onthesamedayofimagecollection,a manual flight was performed at very low altitude (~5 m) to collectimagesforendmembers extractionwhichis describedin Section2.5.1.A. Moghimi, et al. Computers and Electronics in Agriculture 172 (2020) 1052992A gimbal (DJI Ronin-MX) was used to carry the airborne hyper-spectralimagingcomponentsandautomaticallymaintainthecameraatnadir position regardless of the UAV movements (Fig. 1B).2.3. Airborne hyperspectral imaging setupThe camera used in this study was push-broom hyperspectralcamera (PIKA II, Resonon, Inc., Bozeman, MT 59715, USA) with thespecifications presented in Table 2. The components of the airbornehyperspectralimagingsystemincludetheimager,flightcomputer,GPSantenna, inertial measurement unit (IMU), and solid-state hard disk(Fig. 1C).Imageacquisitionwasperformedinautoexposemodeinwhichgainand exposure time were automatically adjusted based on the ambientlightingconditionsandthebrightnessofthetarget.Inthisstudy,alowflightaltitude,20-meterabovegroundlevel(AGL)wasdefinedtoattaina high spatial resolution while avoiding the potential turbulence overcanopy caused by the propellers of UAV. The aircraft speed was set2m/stocovertheentirefieldinoneflight.Oncetheflightaltitudeandspeedwereset,aframerateof108framepersecondwascalculatedasdescribed by (Moghimi et al., 2017) to maintain the spatial integrity(square pixels with aspect ratio of 1:1 in cross and across track).The hyperspectral pixel lines captured by PIKA II were transferredto the flightcomputer viaan Ethernet cable, synchronizedby GPS andIMU data, and then saved as hyperspectral image cube to the harddrivethroughaUSB-3connection.With2000hyperspectralpixellinescollectedpereachimage,thesizeofeachhyperspectralimagecubewas2000 640 240, requiring about 640 megabytes space for saving.2.4. Pre-processing of hyperspectral images2.4.1. Radiometric calibrationRadiometric calibration of spectral images is key step beforequantitative image analysis to assure the repeatability and general-ization of the proposed methodology across various image acquisitionconditions such as imaging in various dates, locations, and weatherconditions using different imagers or using one imager but with dif-ferent exposure and gain settings. The importance and procedure ofradiometriccalibrationhasbeendescribedby Peddleetal.(2003);andthevarioustypesofradiometriccalibrationwiththeirconstraintshavebeen reviewed by Dinguirard and Slater (1999).The hyperspectral images were collected as raw digital numbers(DNs) which is the least useful format with no units or physicalmeaning. Therefore, raw images were converted to radiance (Wm−2sr−1nm−1) usingthe lab-derivedradiometric calibrationfileprovidedby the manufacturer of imager. This conversion is key step requiredfor the radiometric calibration of hyperspectral images to compensatefor the non-uniform spectral and spatial responses of the instrument(Moghimi et al., 2018b).To account for potential variation in solar illumination, hyper-spectral images in radiance were then converted to reflectance usingreference panels (60 60 cm) placed in the field before image col-lection. The panels were pained with gray paint mixed with BariumSulfate to diffuse the incoming solar irradiance in various directions(i.e., no specular reflection). In laboratory setup, the actual re-flectance of gray panels were measured by ASD FieldSpec spectro-radiometer(AnalyticalSpectralDevices,Inc.,Longmont,CO,USA)withrespect to the reflection of Spectralon panel (Labsphere, Inc., NorthSutton,NH,USA)asastandardreferencepanelwithhighlyLambertiansurface. Radiance and reflectance conversion were performed usingSpectrononPro software (Resonon, Inc., Bozeman, MT 59715, USA).The gray panels were placed in alleys based on sensor footprint tomaximizetheprobabilityofcapturingatleastonesetofreferencepanelin each image. The unique IDof the plots located at both sides of graypanels were recorded in an inventory for further processing to re-cognize the ID of all plots across the image.2.4.2. Noisy band removalPrior to any further analysis, the first and last few bands were dis-regarded because of high noise (any bands before 430 nm and after870 nm). In addition, spectral bands near the absorption region of O2and H2O were removed from the hyperspectral data cube (Moghimiet al., 2018b). In total, 190 spectral bands out of 240 bands were keptfor further analyses. The number of noisy bands depends on the sen-sitivity of the sensor and the abundance of atmospheric aerosols, suchas O2and H2O, that absorb certain spectral bands across the electro-magnetic spectrum.Fig.1.(A)Unmannedaerialvehicle:DJIMatrice600ProequippedwithA3Proflight controller. (B) Gimbal: DJI Ronin-MX. (C) Components of airborne hy-perspectral imaging system. (D) Airborne hyperspectral imaging systemmounted on the gimbal. (E) Remote controller and DJI Ground Station Pro forcreating flight missions.Table 1Flight information for the two flight missions in this study.Flight mission for: Flight mode Altitude (m) Speed (m/s) Sidelap Spatial resolution (cm)Yield prediction Autonomous 20 50% <2Endmember extraction Manual ~5 0.5 <0.5A. Moghimi, et al. Computers and Electronics in Agriculture 172 (2020) 10529932.4.3. Plot segmentation and identification2.4.3.1. Segmentation of plots from background. When aerial imageswere collected, wheat plots were at the senescence stage. Whilechlorophyll aand chlorophyll bin green, healthy leaf of wheatplant absorb high extent of light at blue and red regions ofelectromagnetic spectrum for photosynthesis, senescent leaf tends toabsorb less light at these two regions this is because of significantdeclineinchlorophyllcontent(Luetal.,2001).However,theextentofenhancementinreflectionfromsenescentleavesofwheatatredregionis higher than the reflection at blue region. The reason for this changeinreflectancepatternisthatcarotenoid,withahighabsorptionatblueregion (Lichtenthaler, 1987), is much less affected compared tochlorophyll and bduring leaf senescence, meaning the illuminatedlight is still highly absorbed at the blue region during senescence(Biswal, 1995; Grover et al., 1986). Based on this knowledge, avegetation index referred to as normalized difference plant senescenceindex(NDPSI) was proposed in this study to segment wheat plots frombackground. NDPSI is essentially vegetation index derived from twobroad bands: red (670 5 nm) and blue (450 5), as follows (Eq.(1)):=+=+= == =NDPSIRed BlueRed Bluen i j jn i j j1665675 14454551665675 1445455(1)wheredenotesreflectanceatparticularwavelength,n andmrefer tothenumberofbandsusedtogeneratebroadredandbluespectralbands(= =n 5 ),respectively.Whilesinglebandsat670and450nmcanbealso used to calculate NDPSI, consolidating five bands as broader redand blue bands rendered NDSPI gray-scale image with effectivelyreduced salt-and-pepper noise.PixelsrepresentingwheatplotsdisplayedatendencytoexhibitlargevaluesofNDPSIcomparedtothebackgroundpixels,whichweremainlyreferencepanels,greenwinterwheatplantedinalleys,soil,andshadowcaused by plants. threshold was defined for pixel values of NDPSI tosegmentwheatplotsfrom thebackground(Fig.2).Afterwards,severalmorphological operations were applied on this binary image. First, aflood-filloperationwasconductedtofilltheholesgeneratedinsidetheobjects. The second mathematical morphology was opening operation,an erosion followed by dilation with rectangle structuring element(10 5), to remove small objects and break the potential connectionbetween adjacent plots due to the lodging of plants. To assure smallobjects are disregarded, threshold was defined for the area of theobjects in terms of pixels. The obtained binary mask was then used tosegment the plots and fit bounding boxes enclosing the plots (Fig. 2).2.4.3.2. Recognizing plots ID. The geo-rectification process ofhyperspectral images failed largely because the IMU data was notaccurate enough due to the magnetic interference. Therefore, semi-automatic pipeline was developed to identify the plot ID of segmentedplotsineachimage.TheproposedpipelineforplotIDidentificationandsegmentation is described in section 5.2.5 in Moghimi (2019) withdetailed information.Subsequent to plot segmentation and identification, plots werecroppedfromthehyperspectralimagesusingthefittedboundingboxesandsavedas3-Dmatrices(× ×x )topreservethespatial(×x )andspectral ) integrity of plots for further workflow. These 3-D matriceswill be referred to as plots hyperspectral cube (P-HSC) hereinafter.2.5. Hyperspectral image analysis2.5.1. Endmember selectionTo address the issue of mixed pixels in analysis of hyperspectralimages, spectral unmixing is an imperative practice composed of twomain steps. The first step is to identify endmembers which are thespectral of distinct materials in the image, and the second step is todecompose the measured spectrum of mixed pixels into set of end-members and their fractional abundance in the mixed pixels (Keshavaand Mustard, 2002).Despitethehigh-spatialresolution(~2cm)attainedbyflyingat20-meter altitude, each pixel might exhibit spectral characteristics of amixed pixel, largely due to properties of the objects of interest (spikesand leaves) such as size, angle, and curvature. For instance, with thespatial resolution of cm, it was rather infeasible to find pixel thatcontains only spike because of the spike geometry from the sensorTable 2Specifications of PIKA II hyperspectral camera.Hyperspectral imager Spectral range(nm)Spectral resolution(nm)SpectralchannelsSpatialchannels Maximum frame rate (frame persecond)Bit depth Field of view(degree)PIKA II 400–900 2.1 240 640 145 12 33Fig. 2.(A) RGB representation of hyperspectral image. (B) Gray scale imageof normalized difference plant senescence index (NDPSI). (C) Binary imageobtained by thresholding NDPSI. (D) Binary mask obtained by morphologicaloperations including flood-fill, opening, and area thresholding. (E) RGB re-presentationofhyperspectralimageofplotssegmentedfrombackgroundusingthe binary mask. (F) Fitting bounding boxes enclosing the segmented wheatplots.A. Moghimi, et al. Computers and Electronics in Agriculture 172 (2020) 1052994perspective.Toobtainasufficientresolutionforcapturingpurespectralsignatures, called endmember, representing the objects in the hyper-spectral image dataset, low altitude flight (5-meter AGL) was per-formed in manual mode the attained spatial resolution was ap-proximately 0.5 cm.It should be noted that the notion of endmember existence in theform of perfectly pure pixel is for conceptual convenience because ofuncertainty caused by sensor noise and spectral signature variabilitywithin class (Schowengerdt, 2012). In practice, each pixel is essen-tiallyamixedpixeltoacertainextentinremotesensing.Therefore,themost pure pixels in the scene with the most distinct spectral responsewere considered as the endmembers.In hyperspectral image datasets, there were six distinct classes, in-cluding spikes, wheat leaves, soil, shadow, winter wheat, and graypanel. Therefore, the spectral response of pixel can be composed ofthese six classes, each contributing with various extent and with adistinct spectral signature. To distinguish the abundance of theseclasses in each pixel of the images collected at 20-meter altitude, sixendmembers,eachrepresentingasingleclass,wereidentifiedfromtheimages collected at 5-meter altitude.Oneofthewidely-usedtechniquestoidentifytheendmembersisN-FINDRalgorithm,inwhichn endmembersareselectedasthen verticesof an( 1) -simplex with maximum volume encompassing the ma-jorityofpixelsinthefeaturespacespannedbyallpixels(Winter,2004,1999). However, the N-FINDR algorithm suffers from issues such aslong processing time, and inconsistency in selecting the final set ofendmembers due to the random initial endmember selection. Variousautomated techniques, all inspired by N-FINDR, were proposed toameliorate the process of endmember extraction (Chan et al., 2011;Chang et al., 2011; Zortea and Plaza, 2009). In the present study,successive volume maximization (SVMAX), proposed by Chan et al.(2011), was utilized to identify the endmembers through successiveoptimization problem. The number of endmembers in SVMAX was setto six, as there were six distinct classes.2.5.2. Spectral mixture analysisOnce the endmembers were identified from the images captured atlow altitude, each pixel of P-HSC can be represented as convexcombination of the endmembers. Since P-HSCs mainly containedspikes, wheat leaves, soil, and shadow, only four endmembers re-presenting these four classes were used for the un-mixing process. Inthisstudy,todeterminethefractionalabundanceoftheendmembersinthe pixels of P-HSCs, matrix factorization problem with two con-straints was defined as per Thurau et al. (2010) in which Frobeniusnorm is minimized as follows (Eq. (2)):=min WHs thh. .1 10 1FTjij(2)where× d N( is the matrix of data obtained by reshaping P-HSC(i.e.,3Dmatrix)toa2-dimenionsalmatrixsuchthatpixels(N :numberof pixels) were extracted in column-wise order and were placed as thecolumns of matrixX and bands (d number of bands) were placed asthe rows.× d e( and× e N( are the endmembers matrix (e :numberofendmembers),andtheabundancematrix,respectively.Eachcolumn (hj) of matrixH was calculated by resolving quadratic opti-mization problem (Moghimi et al., 2018b) iterativelyN times withconstraints similar to Eq. (2)as follows (Eq. (3)):+ ==h Qh h Ns thhmin 1, ,. .1 10 1hjTjTjTjij12j(3)where (Eq. (4))==Q Wc x22TTj(4)2.5.3. Sub-plot image analysisThe distribution of the measured yield for plot was not homo-geneousovertheplotbecauseofthefactorssuchasspatialvariabilityofsoil, available nutrient, and marginal effects. While studying the yieldvariation within plot can provide valuable insights into the breedingprogram for selecting advanced wheat lines, harvesting the wheatgrains at sub-plot resolution in large yield trial is tedious, un-realistic,andimpracticaltask.Inthisstudythehighspectralandspatialresolutions of aerial hyperspectral images were leveraged to examinethe yield variation within plot.Each plot was divided into square sub-plots (15 15 pixel). ToassurethatP-HSCcanbedividedinto15×15grids,zero-paddingwasapplied at the margins of P-HSC, meaning each pixel can be fitted in a15×15grid.Onceaplotwasdividedintosub-plots,ayieldshouldbeassignedtoeachsub-plot.Basedontheideathatyieldisproportionaltoabove-ground biomass (HAY, 1995; Reynolds et al., 2017; Wheeleret al., 1996), we hypothesized that the yield of sub-plot is propor-tional to the number of spikes and leaves (SL) pixels which representthe above-ground biomass in that subplot (i.e., subplot with higherdensityofspikesandleavescontributesmoreintheplotyield).Infact,theratiobetweenthegainyieldandtheabove-groundbiomassiscalledharvestindexthatreferstotheallocationofbiomasstograinyieldandvariesfromonevarietytoanother(Daietal.,2016;SinghandStoskopf,1971).Toestimatetheabove-groundbiomassforsub-plots,thenumberof SL pixels were counted within each sub-plot by classifying the sub-plot pixels into two classes: SL class or soil-shadow (SS) class. givenpixelwasclassifiedtoSLclassifthesummationofabundanceforspikesand leaves endmembers in that pixel was more than 0.5; otherwise, itwas assigned to SS class (background). Afterwards, we calculated theharvest index (HI) for each wheat line as follows (Eq. (5)):= ==HIgrian yieldaboveground biomassyNynimi1(5)whereyisthemeasuredgrainyieldforagivenwheatline,N isthetotalnumber of SL pixels representing biomass in the plot,ni denotes thenumberofSLpixelsini thsub-plot,andm isthenumberofsub-plotsinthe plot. Once the harvest index was computed for given wheat line,the yield for the sub-plots were calculated as follows (Eq. (6)):= = = ×y HI nyNnnNyi ii(6)whereyiisthecalculatedyieldforthei thsub-plot,andHI istheharvestindex calculated in Eq. (5). Since the yield assigned to sub-plot wasnormalized based on the total number of SL pixels in the plot, thesummation of yield for all sub-plots within the plot was equal to themeasured yield for the plot (==y yimi1 ).2.5.4. Extracting input features from sub-plotsEachsub-plotwascomposedofseveralSLpixelssegmentedfromSSpixels.TheseSLpixelswereconsideredasoneobjectpereachsub-plotwindow. Object-based image analysis (OBIA) approach was then usedto leverage extracting features (such as size, area, texture, mean andstandarddeviationperband)associatedwithasetofpixelsasopposedto per-pixel analysis (Blaschke, 2010).Inthepresentstudy,meanandstandarddeviation(std)perband(intotal 190 bands) were extracted as the input features because they of-fered adequate information to estimate the distribution of pixels’ re-flectance per band per each subplot. The other input feature extractedfromthesub-plotswastheareaoftheSLobjectintermsofpixels(i.e.,the number of SL pixels). This refers to the number of samples used tocalculate the mean and std of the distribution. In total, the number ofinput features per sub-plot was 381 (190 190 1).A. Moghimi, et al. Computers and Electronics in Agriculture 172 (2020) 10529952.6. DatasetThere were three sets of data from adjacent fields C3 and C9 col-lectedin 2017,and C4collectedin 2018.After removingthedamagedplots, set of 50 plots was selected as the test dataset using stratifiedsamplingtoassurethatthetestdatasethasanakinyielddistributiontothe training and validation datasets (Table 3; Figure 5.5 in Moghimi(2019)).Thesub-plotsofthese50plotswereheldoutasthetestdatasetforanunbiasedevaluationofthefinaltrainedmodel.Subsequenttothetest dataset selection, other plots of the three fields were divided intosub-plots and merged together to form dataset for training and vali-dation of the model. Using stratified sampling, these sub-plots weresplit into training (90%) and validation (10%) datasets to train andvalidate the model during the training process (Table 3).Inanotherexperiment,anindividualmodelwasdevelopedpereachfield.Withasimilarapproachdescribedabove,thedatasetofeachfieldwas separately divided into training (85%), validation (15%) afterkeeping aside the sub-plots of 50 plots selected for test datasets.Aftersplittingthedata,thetrainingdatasetwasnormalizedtomakeeach feature have zero-mean and unit-variance. Subsequently, valida-tion and test datasets were standardized using the mean and varianceobtained from training dataset.2.7. Deep neural networkAmong various type of deep learning architectures, convolutionalneural network (CNN) (Krizhevsky et al., 2012; LeCun et al., 1990,1989)iswellsuitedfordatawithspatialstructuresuchasimage-baseddatasets. However, the spatial information within sub-plots was lostbecausetheyieldassignedtothesub-plotswasbasedonthenumberofSL pixels, regardless of the spatial location of SL pixels with respect toeach other in the sub-plot window. Consequently, vector of featuresfor each sub-plot was considered as the input layer for deep neuralnetwork (DNN) with fully connected layers in preference to CNN. Inthisstudy, thenetwork wasafeedforwardneuralnetwork,alsoknownasmultilayerperceptron(MLP)(Goodfellowetal.,2016),composedofan input layer, an output layer, and four hidden layers.The input layer represented the input features. Since 381 featureswere extracted from the sub-plots, the input layer had 381 units(Fig. 3). The output layer was single unit representing the predictedyield.Thenumberofhiddenlayersandtheirunitsweretwoimportanthyper-parametersofthenetworkdefinedthroughanempiricalprocessin which the performance of various network architectures, selectedbasedonthedomainknowledge,wereevaluated.Sincealargeportionof wavelengths scanned by the hyperspectral camera are redundant orirrelevanttothedesiredphenotypingtrait(Moghimietal.,2018a),theTable 3Numberofplotsandsub-plotsineachfieldandsizeoftraining,validation,andtestdatasetsforthreeindividualmodelsdevelopedforeachfieldaswellasthemodeltrained on the large training dataset obtained by merging all three fields.Year Field Number of plots Number of sub-plotsNumber of plots for testdatasetNumber of sub-plots fortest datasetNumber of sub-plots fortraining datasetNumber of sub-plots forvalidation dataset2017 C3 422 19,287 50 2239 14,491 2557C9 345 19,650 50 2776 14,343 25312018 C4 254 12,773 50 2507 8726 1540All fields 1021 51,710 50 2530 44,261 4919Fig. 3.The architecture of deep neural network with fully connected layers.A. Moghimi, et al. Computers and Electronics in Agriculture 172 (2020) 1052996number of units in the hidden layer was selected among set of smallnumbers compared to the input layer. Alternatively, the number ofhiddenlayerswaslimitedbythesizeofthetrainingdatasetbecauseanadditional hidden layer increased the required number of data to trainthe model parameters (weights and biases). Please refer to Moghimi(2019)pages 113–115, for detailed descriptions.2.8. Computational environmentThe DNN model was developed and tested in Keras 2.2.2 (Cholletand others, 2015) with TensorFlow 1.9.0 (Abadi et al., 2015) backendrunning on an NVIDIA (GeForce GTX 750 Ti) GPU. All other compu-tations and image analysis were performed by MATLAB R2017b(MathWorks, Inc., Natick, MA, USA).Fig. 4.Location of the endmembers in the feature space spanned by the first wo principal components (PC) (A), and the first three PCs (B). (C) Projecting theendmembers on the PC1 and PC2 plane. (D) Projecting the endmembers on the PC1 and PC3 plane. (E) Projecting the endmembers on the PC2 and PC3 plane.Depending on the projection, different set of endmembers become the vertices.A. Moghimi, et al. Computers and Electronics in Agriculture 172 (2020) 10529973. Results3.1. Endmember extractionPixelsidentifiedbySVMAXastheendmembersweretheverticesofa simplex with the maximum volume compared to any other possiblesimplexformedbypixelsinthefeaturespacespannedbyallpixels.Toaccount for uncertainty caused by factors such as sensor noise, the re-flectanceofpixelswithinaspecifiedEuclideandistanceoftheidentifiedendmembers were averaged as the new set of endmembers. For visua-lizationoftheendmemberslocationwithrespecttotheotherpixels,allpixels were projected onto 2- and 3-dimensional feature space, re-spectivelyspannedbythefirsttwoandthreeprincipalcomponents(PC)obtained by principal components analysis (Fig. 4). It should be notedthat the location of endmembers might not be the vertices in the newfeature space because of projection onto lower dimension. For in-stance,ina2-dimensionalfeaturespace,theendmembersofgraypanel,winter wheat, and shadow were the vertices of triangle while theendmembers of spike, leaves, and soil were placed inside the estab-lishedtriangle.Alternatively,ina3-dimensionalfeaturespacespannedby the first three PCs, different set of endmembers might be thevertices depending on the viewing angle (Fig. 4).Fig.5illustratesthespectralsignatureoftheendmembers.Basedonthe spectral signature of endmembers and configuration of end-members’locationinthe3-dimensionalfeaturespace,itcanbeinferredthatspectralresponseofspikesandsenescenceleavesaswellassoilandshadowtendtobesimilar,whereas,winterwheathadthemostdistinctspectral signature among all six endmembers.3.2. Spectral un-mixingThespectralresponseoffourendmembers,includingspikes,leaves,soil, and shadow, were used for un-mixing analysis of P-HSC becausethepixelsrepresentingwinterwheatandgray panelswere maskedoutduring the segmentation process (Fig. 6). The quadratic optimizationproblem, defined to minimize the Frobenius norm, returned four grayscaleimages,eachofwhichrepresentingtheabundanceofaparticularendmember (Fig. 6B). Therefore, for given pixel in P-HSC, therewerefourvaluesdenotingtheabundanceofendmemberssuchthatthesummation of these four values was equal to one due to the appliedconstraints in solving the optimization problem. To segment pixels re-presenting biomass (i.e., SL class), the abundance of spikes and leaveswereaddedpixel-wise.AbinarymaskwascreatedtosegmentSLpixels(Fig. 6C). pixel was assigned to SL class if the summation of spikesand leaves abundances was more than the summation of soil andshadow abundances.3.3. Yield allocation to sub-plotsThe measured yield for plot was distributed among the sub-plotsbased on the ratio between the number of SL pixels in sub-plots to thetotal number of SL pixels in the plot. Each sub-plot represents an areaabout 30 30 cm on the ground because the size of sub-plot was15 15 pixels and the size of pixels were about cm.Severalsub-plotwindowsizeswereevaluatedtofindanappropriatewindowsize.Whileasmallwindowsizeallowedinvestigatingtheyieldvariation at higher spatial resolution, the allocated yield to the sub-plotsbecameverysmallasthenumberofSLpixelsinsub-plotwindowsdecreased. In addition, the probability of having sub-plots with thesame number of SL pixels increased, meaning an identical yield wasassigned to significant portion of sub-plots within given plot. Thiscould deteriorate the process of training the model since significantportion of sub-plots had identical target variables. Alternatively, for alarger windowsize, the assignedyieldto sub-plotsvaried substantiallyatthecostofsacrificingthespatialresolutionforinvestigatingtheyieldvariation within plot. To maintain the possibility of investigatingyield variation at higher spatial resolution and avoid numerous sub-plotswithidenticalyield,thesizeofwindowwassetto15×15.Pleaserefer to Figures 5.10 and 5.11 in Moghimi (2019), which respectivelyrepresenttheresultsofusingvariouswindowsizesandyieldhistogramof sub-plots generated by using these window sizes.Fig. 5.Spectral response of the six endmembers.A. Moghimi, et al. Computers and Electronics in Agriculture 172 (2020) 10529983.4. Deep neural network3.4.1. Yield prediction at sub-plot scaleThetrainingdatasetofsub-plotswasusedtotrainaDNNmodel.Intraining the model, the main goal was to identify set of model para-meters (weights and biases) that minimize the cost function’s value(i.e., RMSE). As training continued, model parameters were updated.Toachieveaninterpretableunit(gram)asthetargetvalue(yield),rootmean square error (RMSE) was calculated for presenting the variationofcostfunctionoverepochs. Fig.7illustrateshowRMSEchangedovertrainingepochsforthreeindividualmodelsdevelopedforeachfieldaswell as the model trained on the large training dataset obtained bymerging all three fields. For all four models, RMSE decreased rapidlyover the first training epochs for both training and validation datasetsand, subsequently, reached plateau where RMSE remained ratherunchanged. However, for the merged dataset, there was sharp de-crease in RMSE within the first few epochs, meaning that the con-vergenceoccurredfasterthanothermodels.Amongthe100epochs,theweights and biases returning the lowest RMSE for validation datasetweresavedasthemodelparameterstopredicttheyieldoftestdataset.Fig. 8demonstrates the performance of the trained models inpredicting the yield of the sub-plots in the test datasets. The modeltrained on the C9 dataset had the largest coefficient of determination(R2) and lowest RMSE in predicting the yield. Alternatively, the C3model had the lowest R2and largest RMSE, indicating the general-ization of the trained model on an unseen dataset was not as satisfac-tory as the C9 model. This could be anticipated because the train andvalidation cost for the C3 model during the training process was thelargest among the models (Fig. 7). One reason that might explain thedifferenceinperformanceofmodels(R2andRMSE)amongthefieldsisthedifferencebetweenthedatesthatimageswerecapturedfromthesetwo fields in 2017. The time interval between imagery and harvestingofC3wasoneweekmorethanC9.Thissuggeststhattheaerialimageryperformedclosertotheharvestingtimemighthaveabettercorrelationto the actual yield.The model trained on the merged dataset had promising R2(R2=0.79)andlowRMSEof5.90g,indicatingtheDNNmodel couldexplain 79 percent of the yield variation among the 2530 subplots inthe test dataset. The DNN model was able to predict the yield of asignificantportionofthetestsub-plotswithalowerrorastheylocatednearby the 1:1 line (the black dashed line in Fig. 8). However, themodeldemonstratedatendencytounderestimatetheyieldofsub-plotsFig.6.(A)Hyperspectralcubeofaplot(P-HSC).(B)Abundanceofendmembersineachpixelshownasgrayscaleimages.(C)Binarymaskofspikesandleavesclass.A threshold of 0.5 was applied on the summation of spikes and leaves abundances. (D) Summation of spikes and leaves abundances for each pixel shown as acolormap. (E) Summation of soil and shadow abundances for each pixel shown as colormap. (F) Spikes and leaves pixels (SL class) were masked from thebackground.A. Moghimi, et al. Computers and Electronics in Agriculture 172 (2020) 1052999withthelargeyieldvalue(morethan40g).Thismightbebecausethenumber of sub-plots having yield of more than 40 in the trainingdataset was substantially lower than the number of sub-plots with theyield less than 40 (Figure 5.5, Moghimi (2019)). Therefore, the net-work was moderately successful to learn the yield estimation based onthe input data with large sub-plot yield. similar pattern was ob-served in yield prediction of the individual fields (Fig. 8).3.4.2. Yield production in the middle one-third of the plotAspatialanalysiswasperformedtodeterminethepotentialofeachwheat variety in producing yield in the middle one-third of the plot.Theskewedimagescausedbythegimbalmalfunctioninrestrictingtheamplitude of vibrations were removed to avoid the negative impact ofskewed plots on the spatial analysis. The results suggest that about 90percentoftheplotsproducedmoreyieldatonesideoftheplot(Fig.9).Lower productivity in the middle one-third can be result of the highcompetition between the plants in the middle of the plot and/or re-ceiving less light compared to the plants at the border of the plots.Investigating the yield production capability of wheat lines in themiddleone-thirdoftheplotsisofgreatinteresttobreedersasanextravaluableinformation.Breederscanusethisasadecision-makingtooltodetermine wheat lines incapable of producing sufficient yield in themiddle one-third of the plot, where there is more competition, andeliminate them from their breeding program.3.4.3. Yield prediction at plot scaleAs described before, the test sub-plots were obtained from the 50test plots selected from the three fields using stratified sampling. Toobservetheperformanceofthetrainedmodelinpredictingtheyieldatplot scale, the summation of the predicted yield for the sub-plots be-longingtoatestplotwerecomparedtothemeasuredyieldforthatplot.TheobtainedR2forthesub-plotscaleimpliesthatabout 79percentofvariance in yield of sub-plots was predictable from the input features.Therefore, due to the potential accumulated error in predicting theyield of the sub-plots within plot, the R2could drop at plot scale.Alternatively, due to the potential cancelation of errors over the sum-mation of the predicted sub-plot yield, the R2could improve at plotscale.In this study, R2for yield prediction at plot scale dropped to 0.41comparedtotheR2of0.79forthesub-plotsscale(Fig.10).Tocomparethepredictionerrorobtainedforplotandsub-plotanalysisandaccountfor the difference in the scale of yield variation, the normalized RMSE(NRMSE)wascalculatedbydividingtheRMSEofplotandsub-plotstotheir mean of yield. The NRMSE for predicting the yield at plot levelwas0.14,whileitwas0.24foryieldpredictionofsub-plots,indicatingtheerrorinyieldpredictionofplotsimprovedalthoughR2deterioratedcompared to the sub-plot scale.Among the test plots, there were plots that the network could ac-curately predict the yield of their sub-plots. Fig. 11illustrates an ex-ampleofsuchaplotthatthenetworkcouldexplainabout96percentofyieldvariationamongits62sub-plotswithRMSEof1.90g.Inaddition,Fig. 7.Variation of root mean squared error over epochs for C3, C9, C4, and merged dataset.A. Moghimi, et al. Computers and Electronics in Agriculture 172 (2020) 10529910Fig. 11shows test plot that the network overestimated the yield of asubstantial number of its sub-plots, and an example of test plot thatthe network underestimated the yield of the majority of its sub-plots.Fig. 8.Performance of deep neural network models on yield prediction of sub-plot test datasets. The model trained on the C9 training dataset had the bestperformance (R2= 0.81 and RMSE 5.5 g), while the model trained on the C3 dataset had the lowest R2and largest RMSE.Fig. 9.Analysis of yield production in the middle one-third of the plots in C3andC9fields.About90(64+26)percentoftheplotsproducedmoreyieldatone side of the plot because of receiving appropriate extent of light and lesscompetition for water and nutrient.Fig. 10.Performance of the model on yield prediction at plot scale.A. Moghimi, et al. Computers and Electronics in Agriculture 172 (2020) 105299113.4.4. Yield prediction at large scaleTo evaluate the feasibility of yield prediction at large scale, themeasuredyieldforall50testplotswereaddedasayieldofalargefieldcomposedof50wheatplots.Alternatively,thepredictedyieldforthese50plotswerealsoaddedtogetherasthepredictedyieldforsuchalargefield.Thetotalactualyieldofthetestplotswas59.36kg,andthetotalpredicted yield of these plots was 59.49 kg. Such an impressive result(i.e., about 0.2% error in yield prediction) indicates the capability ofthe proposed pipeline for yield prediction at large field scale.4. DiscussionVariousmethodscouldbeusedtoanalyzehyperspectralimagesforyieldprediction.Oneofthewidelyusedapproachesistoutilizespectralindices, mostly NDVI. While yield prediction would be more accuratetoward the end of growing season and prior to harvesting when thedensity of crop canopy is moderate to high, method based on NDVIsuffers from saturation issues at this stage of crop growth (Gitelson,2004; Gitelson et al., 1996). Therefore, this method is not suitable foryield prediction while it is extensively used by agricultural researchcommunity.Theotherpossiblemethodistotrainamodeltodirectlypredicttheyield at plot scale. For such model, the spectral response of pixelsrepresentingspikesandleavesinasingleplotareaveragedtohaveonefeature vector since there was single target value (i.e., measuredyield)pereachplot.Onemaindrawbackofthisnaïveapproachisthatsubstantial spectral information is suppressed by taking the spectralaverage over hundreds of SL pixels in plot. Moreover, the spatial in-formation attained with high resolution is diminished through theaveragingprocess.TheotherdisadvantageoftakingtheaverageacrossFig. 11.Examples of test plots that the network accurately estimated (A), overestimated (B), and underestimated (C) the yield of their sub-plots. Wheat plots arewavy because the gimbal could not restrict the amplitude of vibrations caused by UAV.A. Moghimi, et al. Computers and Electronics in Agriculture 172 (2020) 10529912theplotpixelsisthatthenumberofsamplesislimitedtothenumberofplots whichwas about1000 inthisstudy. Thislownumberof samplesmight be insufficient to recognize the complex pattern from high di-mensionaldatasetwith190features(i.e.,numberofbands)todeveloparobustmodelforyieldprediction.Lastly,investigatingyieldvariationwithin plots would not be possible with this approach.This study proposed an innovative method for analysis of high-di-mensional hyperspectral images captured at high spatial and spectralresolution to estimate the yield of hundreds of wheat lines. Aerial hy-perspectral images were captured in less than 10 min from each fieldusing an autonomous platform. Several image processing techniquesand an optimization algorithm were integrated with the domainknowledgetosegmenttheplotsfrombackground,dividethemintosub-plots, unmix the plot pixels, and assign yield value to each sub-plot.Subsequent to these analyses, the OBIA approach was deployed to ex-tract features from each sub-plots. Finally, deep neural networks wereused to estimate the yield at sub-plot and plot scale. The resultsachieved by the proposed analysis framework are discussed in thissection.4.1. Spectral mixture analysisWiththespatialresolutionof2cm,eachpixelcouldpotentiallybeamixedpixel,aspectralmixtureofmorethanoneparticularendmember.Oncethespectralsignatureoftheendmemberswasdiscoveredfromthehyperspectralimagewith0.5cmspatialresolution,thespectralmixtureanalysiswasperformedtoidentifytheabundanceoftheendmembersina given pixel. The benefits of un-mixing the pixels can be summarizedinto twofold. First, it allowed segmenting the plot pixels with highabundance of wheat leaves and spikes and disregarding the pixels re-presenting background for further processing. Second, this approachprovided the opportunity of deploying more advanced techniques forfurtherinvestigationofyieldplotsbyassigningayieldvaluetoagivensub-plotbasedonthenumberofSLpixelsinthatsub-plot.Asaresult,italleviated the curse of dimensionality by increasing the number ofsamples (i.e., 51,710) compared to the number of features (i.e., 381).4.2. Yield analysis at sub-plot scaleBesidestheyieldpotentialofawheatvariety,theabilitytoproducea uniform yield across the plot is valuable factor that could assistbreedersinselectingadvancedlines.However,harvestingthegrainsatsub-plotscaletostudytheyieldvariationwithinplotsforvariouswheatvarieties is not practical, particularly in large nursery.Inthisstudy,anovelapproachwasproposedtoinvestigatetheyieldvariationatsub-plotscale(15×15pixelequatesto30cmby30cm).First, plots were divided into sub-plots, and then yield value was as-signedtoeachsub-plotbyintegratingimageprocessingtechniquesandexpertdomainknowledge(sub-plotyieldisproportiontothenumberofspikesandleavespixelsrepresentingtheplantbiomass).Thisapproachoffered the chance to investigate the feasibility of yield estimation atsub-plotscalewithveryhighspatialresolution,andfurtherevaluatetheperformance of various wheat lines in terms of producing yield uni-formly distributed across the plot.The results of the yield analysis at sub-plot scale revealed the sig-nificanceofmarginaleffectsonthedistributionofspikesandleavesforvarious wheatvarieties.While aparticularvarietymightbe capableofproducing uniform yield across the plot as the plants were able tocompetewiththeirneighbors,anothervarietymightbesensitivetotheplant density, causing non-uniform yield production. uniform yieldproduction is fundamentaltrait because plantsshouldmaintain theirpotential yield in competitive environment at field scale.Fig. 12shows two wheat lines (presented in and C) that sufferfrommarginaleffects,andtwowheatlines(presentedinBandD)thatproduce less yield but in more uniform manner with less marginaleffects. According to the colormaps showing the distribution of thespikesandleavesin Fig.12,linesAandCproducedlessyieldinsideofthe plot and more yieldat the marginsof the plot. Therefore, breedersprefer line and because of their potential in producing moreuniform yield.This new insight about yield variation within plots casts doubts ontheassumptionthattheperformanceofwheatlinesinthesesmallplotsequatestoperformanceinfarmers’fieldsthatmaybeuptohundredsofhectares in size. However, testing hundreds to thousands of lines forgrain yield necessarily requires them to be grown in small plots (e.g.1–10m−2)duetospacelimitations.Therefore,theproposedmethodisof great interest to breeders to eliminate the lines with non-uniformyield production from the breeding program because their yield per-formance would be significantly deteriorated in farmers’ large fieldswhere the plant density and competition is more similar to the middlerows in these small experimental plots.4.3. Practical applications of the proposed frameworkThe proposed framework including aerial imagery and hyperspec-tralimageanalysiscanbedeployedasavaluabledecisionsupporttoolin breeding programs. In following sections, it is explained how thisgame changer framework can facilitate the process of high-throughputyield phenotyping.4.3.1. Remote visual inspection of the plotsBreeders visually inspect the nursery multiple times during thegrowing season to record any incidents that might affect theirscreening, such as damages caused by animal or severe weather con-dition. Noticeably, this is an extremely demanding, time-consuming,and subjective task. Aerial imaging followed by the proposedFig.12.(A)Exampleoftwowheatlinesthatproducemoreyieldatthemarginsofplots.(B)Exampleoftwowheatlinesthatproducelessyieldbutwithamoreuniformdistribution.Despitethelessyieldproduction,breedersprefertheplotspresented in (B) because of uniform yield production. Please note that wheatplots might seem wavy because the gimbal could not restrict the amplitude ofvibrations caused by UAV.A. Moghimi, et al. Computers and Electronics in Agriculture 172 (2020) 10529913automated analysis pipeline can facilitate the visual inspection to beperformed remotely with high temporal resolution and across all nur-seriesinmultiplelocations. Fig.13showstheSLcolormapobtainedbyanalysisofaerialhyperspectralimagesconformedtothenotestakenbyanexpertinthefield.TheexistenceofmoreSSpixels(presentedinbluecolor)implieslessyieldregardlessofthevarietybecauseitindicatesthepixels representing soil and shadow, which do not contribute to theyield.Thispresentedframeworkcanserveasatooltoremotelyinspectthestatus of plots and accordingly make an appropriate decision. For in-stance, based on the SL colormap, breeder would disregard the plotshown in Fig. 13A because the measured yield value for the corre-sponding wheat line is not reliable indicator due to the severe da-mage. In addition, this method can assist breeders in identifying low-yielding plots prior to harvesting.4.3.2. Investigating more lines by optimizing plot sizeCurrently, several factors dictate the plot size for yield trials, in-cluding seed availability (primarily concern for first year yield trialsonly), cost and availability of land, size of available small plot equip-ment, minimizing experimental error, and overall cost of labor andresources. All of these factors become even more restricting since abreeder often manages yield trials in multiple locations to account fornon-uniform climate, soil, and environmental conditions. Therefore,thesefactorsrestrainthenumberoffirstyearyieldplotsthatabreedingprogram can manage, and subsequently, they affect the size of thesucceeding yield trials.The ability of aerial imagery in remote inspection and yield pre-diction of the plots can reduce the required labor and equipment forscouting and harvesting. In addition, the unique advantage of theproposed framework in yield estimation with high spatial resolutionenables plant scientists and breeders to optimize the plot size and in-vestigate more wheat lines in dedicated field each year. During thefirst few years, wheat lines can be planted in smaller plots, and theproposed frameworkcan be utilized toperform afast binaryscreeningbased on their yield performance (Fig. 14). Low-yielding lines will bediscarded,andonlyhigh-yieldingplotsareharvestedtoobtainseedsforthe next trial. This allows breeders to manage their labor, equipment,Fig.13.Remotevisualinspectionoftheplotsbyanalyzing the aerial hyperspectral images. Theresultsoftheimageanalysisconformedwiththenotes made by an expert in the field. The notesmadefortheseplotswere:(A)½oftheplotwasdamaged, (B) weak plot, (C) strong plot. Pleasenote that wheat plots might seem wavy becausethe gimbal could not restrict the amplitude ofvibrations caused by UAV.Fig.14.Nominatingadvancedlinesforcommercializationoverseveralyearsofyieldtrialsusingtheproposedframework.Ineachyear,aerialhyperspectralimageryfollowed by the proposed analysis pipeline is utilized to classify the wheat lines into low- and high-yielding lines based on their yield performance. While low-yieldinglinesarediscarded,high-yieldinglinesareadvancedtothenextyears’yieldtrialwithlargerplotsizetoevaluateyieldperformanceinenvironmentsmoresimilar to grower’s field conditions.A. Moghimi, et al. Computers and Electronics in Agriculture 172 (2020) 10529914andlandinamoreeffectivemanner.Afterward,thehigh-yieldinglinesareevaluatedwithlargerplotsizeinmorelocationsoverthefollowingyears. While number of lines decreases over time, the size of the plotincreases to evaluate the yield performance of advanced lines in en-vironments more similar to growers’ field conditions.4.3.3. Other potential applicationsIn addition to yield estimation, breeders can utilize the proposedframework to: (i) study the effect of plant density on yield with highspatialresolution,(ii)studytheimpactofsidetrimmingonyieldacrossvarious varieties, and (iii) investigate multiple desired traits, such asdiseaseresistance,attheearlystagesofselectingadvancedwheatlines.5. ConclusionDeveloping crop varieties with high yield potential through plantbreeding and genetics is crucial in promoting sustainable crop pro-duction to meet the projected demand for food. Innovative technolo-gies, automation, and artificial intelligence appeared to be imperativefor making appropriate decisions in the process of selecting high-yieldingvarietiesinanefficientandeffectivemanner.Inthisstudy,wedeveloped sensor-based, intelligent framework for high-throughputyield phenotyping in wheat. The proposed method could successfullypredicttheyieldoftestplots= (R 0.41 and NRMSE 0.14)2 aswellassub-plots (= R 0.79 and NRMSE 0.24)2 In addition to yield estimation, thisstudy can benefit plant scientist and breeders in various ways by pro-viding the ability for: (i) remote visual inspection of the plots in mul-tiple times during the growing season, (ii) optimizing the plot size toinvestigate more lines ina dedicatedfieldeach year,(iii) investigatingthe impact of plant density and side trimming on yield, and (iv) in-vestigating multiple desired traits, such as crop disease resistance orstresstolerance.Infuturework,thedimensionofhyperspectralimagescan be reduced to avoid the issues associated with the high di-mensionality of data. Once the dimensionality is reduced, deepernetwork canbetrainedwiththesame samplesizebecausethenumberof weights in network will be significantly reduced due to the reduceddimension of the input features at the first layer of the network.Author statementYangsupportedthisstudybytheUniversityofMinnesotaMNDrivestartup fund, administered the project and provided supervision.Anderson provided the field trial and yield data, and provided super-vision.Moghimianalyzedthedata,decidedthemethodologyandwrotetheoriginaldraft.Allauthorscontributedtotheconceptualization,datacuration, investigation, methodology and editing.Data availability statementThe UAV-based hyperspectral images required for the analysisconducted in this study are available in the Data Repository forUniversity of Minnesota at https://doi.org/10.13020/0ch0-vb18. Thedataset entails hyperspectral cubes of 1021 wheat plots from threeexperimentalyieldtrialfieldsandthecorrespondinggrainyieldofplotsharvested by combine in two consecutive years.Declaration of Competing InterestThe authors declare that they have no known competing financialinterests or personal relationships that could have appeared to influ-ence the work reported in this paper.AcknowledgmentTheauthorswouldliketogratefullyacknowledgethefundingfromthe Minnesota’s Discovery, Research, and InnoVation Economy(MnDRIVE) program through the research area of Robotics, Sensors,andAdvancedManufacturing.WethankMs.SusanK.Reynoldsforhervaluablesupportinmanagingthefieldsandcollectingthegroundtruthdata,andMrs.ParisaKafashforherassistanceinpreparingthefigures.We would also like to acknowledge the graduate student fellowshipsprovided by MnDRIVE Global Food Ventures and the department ofBioproducts and Biosystems Engineering.Appendix A. Supplementary dataSupplementary data to this article can be found online at https://doi.org/10.1016/j.compag.2020.105299.ReferencesAbadi, M., Ashish Agarwal, Paul Barham, E.B., Zhifeng Chen, Craig Citro, Greg S.Corrado, Andy Davis, Jeffrey Dean, Matthieu Devin, Sanjay Ghemawat, IanGoodfellow, Andrew Harp, Geoffrey Irving, Michael Isard, Rafal Jozefowicz,Yangqing Jia, Lukasz Kaiser, Manjunath Kudlur, Josh Levenberg, Dan Mané, MikeSchuster, Rajat Monga, Sherry Moore, Derek Murray, Chris Olah, Jonathon Shlens,BenoitSteiner,IlyaSutskever,KunalTalwar,PaulTucker,VincentVanhoucke,VijayVasudevan,FernandaViégas,OriolVinyals,PeteWarden,MartinWattenberg,MartinWicke, Yuan Yu, and X.Z., 2015. TensorFlow: Large-scale machine learning on het-erogeneous systems.Araus, J.L., Kefauver, S.C., Zaman-Allah, M., Olsen, M.S., Cairns, J.E., 2018. TranslatingHigh-Throughput Phenotyping into Genetic Gain. Trends Plant Sci. 23, 451–466.https://doi.org/10.1016/J.TPLANTS.2018.02.001.Ashapure, A., Oh, S., Marconi, T.G., Chang, A., Jung, J., Landivar, J., Enciso, J., 2019.Unmanned aerial system based tomato yield estimation using machine learning 22.Doi: http://doi.org/10.1117/12.2519129.Biswal,B.,1995.Carotenoidcatabolismduringleafsenescenceanditscontrolbylight.J.Photochem. Photobiol. - Biol. 30, 3–13.Blaschke, T., 2010. Object based image analysis for remote sensing. ISPRS J.Photogramm. Remote Sens. 65, 2–16. https://doi.org/10.1016/J.ISPRSJPRS.2009.06.004.Chan,T.H.,Ma,W.K.,Ambikapathi,A.,Chi,C.Y.,2011.Asimplexvolumemaximizationframework for hyperspectral endmember extraction. IEEE Trans. Geosci. RemoteSens. 49, 4177–4193. https://doi.org/10.1109/TGRS.2011.2141672.Chang, C.I., Wu, C.C., Tsai, C.T., 2011. Random N-finder (N-FINDR) endmember ex-traction algorithms for hyperspectral imagery. IEEE Trans. Image Process. 20,641–656.https://doi.org/10.1109/TIP.2010.2071310.Chollet, F., others, 2015. Keras.Crain, J., Mondal, S., Rutkoski, J., Singh, R.P., Poland, J., 2018. Combining High-Throughput Phenotyping and Genomic Information to Increase Prediction andSelection Accuracy in Wheat Breeding. Plant Genome 11. https://doi.org/10.3835/plantgenome2017.05.0043.Dai, J., Bean, B., Brown, B., Bruening, W., Edwards, J., Flowers, M., Karow, R., Lee, C.,Morgan, G., Ottman, M., Ransom, J., Wiersma, J., 2016. Harvest index and strawyield of five classes of wheat. Biomass Bioenergy 85, 223–227. https://doi.org/10.1016/j.biombioe.2015.12.023.Dinguirard, M., Slater, P.N., 1999. Calibration of space-multispectral imaging sensors: Areview. Remote Sens. Environ. 68, 194–205. https://doi.org/10.1016/S0034-4257(98)00111-4.Du, M., Noguchi, N., 2017. Monitoring of wheat growth status and mapping of wheatyield’s within-field spatial variations using color images acquired from UAV-cameraSystem. Remote Sens. 9. https://doi.org/10.3390/rs9030289.Duan,T.,Chapman,S.C.,Guo,Y.,Zheng,B.,2017.DynamicmonitoringofNDVIinwheatagronomy and breeding trials using an unmanned aerial vehicle. F. Crop. Res. 210,71–80.https://doi.org/10.1016/j.fcr.2017.05.025.Gitelson, A.A., 2004. Wide dynamic range vegetation index for remote quantification ofbiophysicalcharacteristicsofvegetation.J.PlantPhysiol.161,165–173. https://doi.org/10.1078/0176-1617-01176.Gitelson, A.A., Kaufman, Y.J., Merzlyak, M.N., 1996. Use of Green Channel in RemoteSensing of Global Vegetation from EOS-MODIS.pdf. Remote Sens. Environ. 58,289–298.https://doi.org/10.1016/S0034-4257(96)00072-7.Goodfellow, I., Bengio, Y., Courville, A., 2016. Deep Learning. The. MIT Press.Grover,A.,Sabat,S.C.,Mohanty,P.,1986.Relativesensitivityofvariousspectralformsofphotosynthetic pigments to leaf senescence in wheat (Triticum aestivum L.).Photosynth. Res. 10, 223–231. https://doi.org/10.1007/BF00118287.Hay, R.K.M., 1995. Harvest index: review of its use in plant breeding and crop phy-siology. Ann. Appl. Biol. 126, 197–216. https://doi.org/10.1111/j.1744-7348.1995.tb05015.x.Herzig,P.,Backhaus,A.,Seiffert,U.,vonWirén,N.,Pillen,K.,Maurer,A.,2019.Geneticdissection of grain elements predicted by hyperspectral imaging associated withyield-related traits in wild barley NAM population. Plant Sci. https://doi.org/10.1016/j.plantsci.2019.05.008.Keshava,N.,Mustard,J.F.,2002.Spectralunmixing.IEEESignalProcess.Mag.19,44–57.https://doi.org/10.1109/79.974727.Khaki,S.,Wang,L.,2019.Cropyieldpredictionusingdeepneuralnetworks.Front.PlantSci. 10, 1–10. https://doi.org/10.3389/fpls.2019.00621.A. Moghimi, et al.Computers and Electronics in Agriculture 172 (2020) 10529915Krause, M.R., González-Pérez, L., Crossa, J., Pérez-Rodríguez, P., Montesinos-López, O.,Singh, R.P., Dreisigacker, S., Poland, J., Rutkoski, J., Sorrells, M., Gore, M.A.,Mondal, S., 2019. Hyperspectral reflectance-derived relationship matrices forgenomicpredictionofgrainyieldinwheat.G3GenesGenomesGenet.9,1231–1247.https://doi.org/10.1534/g3.118.200856.Krizhevsky, A., Sutskever, I., Hinton, G.E., 2012. ImageNet Classification with DeepConvolutional Neural Networks, in: Pereira, F., Burges, C.J.C., Bottou, L.,Weinberger, K.Q. (Eds.), Advances in Neural Information Processing Systems 25.Curran Associates, Inc., pp. 1097–1105.Kyratzis, A.C., Skarlatos, D.P., Menexes, G.C., Vamvakousis, V.F., Katsiotis, A., 2017.Assessment of vegetation indices derived by UAV imagery for durum wheat pheno-typing under water limited and heat stressed mediterranean environment. Front.Plant Sci. 8, 1–14. https://doi.org/10.3389/fpls.2017.01114.LeCun, Y., Boser, B., Denker, J.S., Henderson, D., Howard, R.E., Hubbard, W., Jackel,L.D., 1989. Backpropagation Applied to Handwritten Zip Code Recognition. NeuralComput. 1, 541–551. https://doi.org/10.1162/neco.1989.1.4.541.LeCun,Y.,Boser,B.E.,Denker,J.S.,Henderson,D.,Howard,R.E.,Hubbard,W.E.,Jackel,L.D., 1990. Handwritten Digit Recognition with Back-Propagation Network, in:Touretzky,D.S.(Ed.),AdvancesinNeuralInformationProcessingSystems2.Morgan-Kaufmann, pp. 396–404.Lichtenthaler,H.K.,1987.[34]Chlorophyllsandcarotenoids:Pigmentsofphotosyntheticbiomembranes. Methods Enzymol. 148, 350–382. https://doi.org/10.1016/0076-6879(87)48036-1.Lu, C., Lu, Q., Zhang, J., Kuang, T., 2001. Characterization of photosynthetic pigmentcomposition, photosystem II photochemistry and thermal energy dissipation duringleaf senescence of wheat plants grown in the field. J. Exp. Bot. 52, 1805–1810.https://doi.org/10.1016/0893-6080(88)90069-X.Madec, S., Baret, F., de Solan, B., Thomas, S., Dutartre, D., Jezequel, S., Hemmerlé, M.,Colombeau, G., Comar, A., 2017. High-throughput phenotyping of plant height:comparingunmannedaerialvehiclesandgroundLiDARestimates.Front.PlantSci.8,1–14.https://doi.org/10.3389/fpls.2017.02002.Mahlein, A.-K., Kuska, M.T., Thomas, S., Wahabzada, M., Behmann, J., Rascher, U.,Kersting, K.,2019. Quantitativeand qualitativephenotypingofdiseaseresistance ofcropsbyhyperspectralsensors:seamlessinterlockingofphytopathology,sensors,andmachine learning is needed!. Opin. Plant Biol. https://doi.org/10.1016/j.pbi.2019.06.007.Moghimi, A., 2019. Integrating Hyperspectral Imaging and Artificial Intelligence toDevelop Automated Frameworks for High-throughput Phenotyping in Wheat.Retrievedfromthe.UniversityofMinnesotaDigitalConservancy. http://hdl.handle.net/11299/202435.Moghimi, A., Yang, C., Anderson, J.A., Reynolds, S.K., 2019. Selecting informativespectral bands using machine learning techniques to detect Fusarium head blight inwheat.In:ASABEAnnualInternationalMeeting.Boston,MA.Doi:http://doi.org/10.13031/aim.201900815.Moghimi, A., Yang, C., Marchetto, P.M., 2018a. Ensemble feature selection for plantphenotyping: journey from hyperspectral to multispectral imaging. IEEE Access 6,56870–56884. https://doi.org/10.1109/ACCESS.2018.2872801.Moghimi, A., Yang, C., Miller, M.E., Kianian, S., Marchetto, P., 2017. Hyperspectralimaging to identify salt-tolerant wheat lines. In: SPIE. Autonomous Air and GroundSensing Systems for Agricultural Optimization and Phenotyping II 2017. Anaheim,California, United States. Doi: http://doi.org/10.1117/12.2262388.Moghimi, A., Yang, C., Miller, M.E., Kianian, S.F., Marchetto, P.M., 2018b. novel ap-proach to assess salt stress tolerance in wheat using hyperspectral imaging. Front.Plant Sci. 9, 1182. https://doi.org/10.3389/fpls.2018.01182.Naik, H.S., Zhang, J., Lofquist, A., Assefa, T., Sarkar, S., Ackerman, D., Singh, A., Singh,A.K., Ganapathysubramanian, B., 2017. real-time phenotyping framework usingmachine learning for plant stress severityrating in soybean.Plant Methods. https://doi.org/10.1186/s13007-017-0173-7.Nigam, R., Tripathy, R., Dutta, S., Bhagia, N., Nagori, R., Chandrasekar, K., Kot, R.,Bhattacharya, B.K., Ustin, S., 2019. Crop type discrimination and health assessmentusing hyperspectral imaging. Curr. Sci. 116, 1108–1123. https://doi.org/10.18520/cs/v116/i7/1108-1123.Peddle, D.R., Teillet, P.M., Wulder, M.A., 2003. Radiometric Image Processing. In:Wulder,M.A.,Franklin,S.E.(Eds.),RemoteSensingofForestEnvironments:Conceptsand Case Studies. Springer US, Boston, MA, pp. 181–208. Doi: http://doi.org/10.1007/978-1-4615-0306-4_7.Pound, M.P., Atkinson, J.A., Townsend, A.J., Wilson, M.H., Griffiths, M., Jackson, A.S.,Bulat,A.,Tzimiropoulos,G.,Wells,D.M.,Murchie,E.H.,Pridmore,T.P.,French,A.P.,2017. Deep machine learning provides state-of-the-art performance in image-basedplant phenotyping. Gigascience 6, 1–10. https://doi.org/10.1093/gigascience/gix083.Qiu, R., Yang, C., Moghimi, A., Zhang, M., Steffenson, B., 2019. Detection of FusariumHead Blight in Wheat Using Deep Neural Network and Color Imaging 1–19. Doi:http://doi.org/10.20944/preprints201910.0056.v1.Ray, D.K., Mueller, N.D., West, P.C., Foley, J.A., 2013. yield trends are insufficient todouble global crop production by 2050. PLoS One 8. https://doi.org/10.1371/journal.pone.0066428.Reynolds, M.P., Pask, A.J.D., Hoppitt, W.J.E., Sonder, K., Sukumaran, S., Molero, G.,Pierre, C. Saint, Payne, T., Singh, R.P., Braun, H.J., Gonzalez, F.G., Terrile, I.I.,Barma, N.C.D., Hakim, A., He, Z., Fan, Z., Novoselovic, D., Maghraby, M., Gad,K.I.M., Galal, E.H.G.,Hagras, A., Mohamed, M.M., Morad,A.F.A., Kumar, U., Singh,G.P.,Naik,R.,Kalappanavar,I.K.,Biradar,S.,SaiPrasad,S.V.,Chatrath,R.,Sharma,I., Panchabhai, K., Sohu, V.S., Mavi, G.S., Mishra, V.K., Balasubramaniam, A., Jalal-Kamali,M.R.,Khodarahmi,M.,Dastfal,M.,Tabib-Ghaffari,S.M.,Jafarby,J.,Nikzad,A.R.,Moghaddam,H.A.,Ghojogh,H.,Mehraban,A.,Solís-Moya,E.,Camacho-Casas,M.A., Figueroa-López, P., Ireta-Moreno, J., Alvarado-Padilla, J.I., Borbón-Gracia, A.,Torres, A., Quiche, Y.N., Upadhyay, S.R., Pandey, D., Imtiaz, M., Rehman, M.U.,Hussain,Manzoor,Hussain,Makhdoom,Ud-Din,R.,Qamar,M.,Kundi,M.,Mujahid,M.Y., Ahmad, G., Khan, A.J., Sial, M.A., Mustatea, P., von Well, E., Ncala, M., deGroot, S., Hussein, A.H.A., Tahir, I.S.A., Idris, A.A.M., Elamein, H.M.M., Manes, Y.,Joshi, A.K., 2017. Strategic crossing of biomass and harvest index—source and sin-k—achievesgeneticgainsinwheat.Euphytica213. https://doi.org/10.1007/s10681-017-2040-z.Schowengerdt, R.A., 2012. Remote sensing: Models and methods for image processing:Second edition, Remote Sensing: Models and Methods for Image Processing: SecondEdition. Doi: http://doi.org/10.1016/C2009-0-21902-7.Singh,A.,Ganapathysubramanian,B.,Singh,A.K.,Sarkar,S.,2016.Machinelearningforhigh-throughputstressphenotypinginplants.TrendsPlantSci.21,110–124. https://doi.org/10.1016/j.tplants.2015.10.015.Singh, A.K., Ganapathysubramanian, B., Sarkar, S., Singh, A., 2018. Deep learning forplant stress phenotyping: trends and future perspectives. Trends Plant Sci. 23,883–898.https://doi.org/10.1016/J.TPLANTS.2018.07.004.Singh, I.D., Stoskopf, N.C., 1971. Harvest index in Cereals1. Agron. J. 63, 224. https://doi.org/10.2134/agronj1971.00021962006300020008x.Thurau,C.,Kersting,K.,Bauckhage,C.,Iais,F.,Augustin,S.,2010.YesWeCan–SimplexVolumeMaximizationforDescriptiveWeb-ScaleMatrixFactorizationCategoriesandSubjectDescriptors,in:Proceedingsofthe19thACMConferenceonInformationandKnowledge Management, CIKM, Toronto, Ontario, Canada, pp. 1785–1788.Tilman,D.,Balzer,C.,Hill,J.,Befort,B.L.,2011.Globalfooddemandandthesustainableintensificationofagriculture.Proc.Natl.Acad.Sci.USA108,20260–20264. https://doi.org/10.1073/pnas.1116437108.Ubbens, J.R., Stavness, I., 2017. Deep plant phenomics: deep learning platform forcomplex plant phenotyping tasks. Front. Plant Sci. 8. https://doi.org/10.3389/fpls.2017.01190.Wheeler, T.R., Hong, T.D., Ellis, R.H., Batts, G.R., Morison, J.I.L., Hadley, P., 1996. Thedurationandrateofgraingrowth,andharvestindex,ofwheat(TriticumaestivumL.)in response to temperature and CO 2. J. Exp. Bot. 47, 623–630. https://doi.org/10.1093/jxb/47.5.623.Winter, M.E., 2004. proof of the N-FINDR algorithm for the automated detection ofendmembers in hyperspectral image. In: Proc. SPIE 5425, Algorithms andTechnologiesforMultispectral,Hyperspectral,andUltraspectralImageryX.Orlando,Florida, United States, p. 31. Doi: http://doi.org/10.1117/12.542854.Winter, M.E., 1999. N-FINDR: an algorithm for fast autonomous spectral end-memberdetermination in hyperspectral data, in: Proc. SPIE 3753, Imaging Spectrometry V.Denver, CO, United States. Doi: http://doi.org/10.1117/12.366289.Wu, C., Zeng, R., Pan, J., Wang, C.C.L., Liu, Y.-J., 2019. Plant Phenotyping by Deep-Learning-Based Planner for Multi-Robots. IEEE Robot. Autom. Lett. 4, 3113–3120.https://doi.org/10.1109/lra.2019.2924125.Yue, J., Yang, G., Li, C., Li, Z., Wang, Y., Feng, H., Xu, B., 2017. Estimation of winterwheat above-ground biomass using unmanned aerial vehicle-based snapshot hyper-spectral sensor and crop height improved models. Remote Sens. 9. https://doi.org/10.3390/rs9070708.Zortea, M., Plaza, A., 2009. quantitative and comparative analysis of different im-plementations of N-FINDR: fast endmember extraction algorithm. IEEE Geosci.Remote Sens. Lett. 6, 787–791. https://doi.org/10.1109/LGRS.2009.2025520.A. Moghimi, et al.Computers and Electronics in Agriculture 172 (2020) 10529916AnnotationsAerial hyperspectral imagery and deep neural networks for high-throughput yield phenotyping in wheatMoghimi, Ali; Yang, Ce; Anderson, James A.01 Amirhossein Zaji Page 121/7/2020 8:23